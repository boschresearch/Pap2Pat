# DESCRIPTION

## RELATED APPLICATION INFORMATION

- claim priority to provisional applications

## BACKGROUND

### Technical Field

- define technical field

### Description of the Related Art

- motivate multitask learning
- limitations of multitask models

## SUMMARY

- introduce dynamic multi-task network method
- introduce dynamic multi-task network system
- outline system components

## DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS

- introduce multi-task model based on deep neural network
- motivate dynamic control of task accuracy trade-off and computational cost
- describe limitations of conventional multi-task models
- define architecture and weights of multi-task model
- explain dynamic choice of task preference and computational cost
- describe architecture representation as sequence of modules
- explain role of weights in determining module behavior
- illustrate example of surveillance system with varying task importance
- describe deployment of single solution to multiple customers
- motivate simultaneous optimization of all tasks
- describe main model and extra network for architecture optimization
- explain input of target computational cost and task preference vector
- describe enlarged search space for model
- motivate multi-task learning for simultaneous task solution
- describe hypernetwork for learning context-dependent parameters
- explain dynamic resource allocation
- describe dynamic neural networks for adapting structure during inference
- explain dynamic depth and width
- describe dynamic routing with controllers
- motivate explicit control of total computational cost and task trade-offs
- describe weight sharing for neural architecture search
- illustrate system/method for multi-task predictions
- describe neural network architecture and weights
- explain model behavior defined by architecture and weights
- illustrate system/method for building model for multi-task predictions
- describe hypernetwork for learning context-dependent parameters
- explain dynamic resource allocation
- describe architectural search space for block with N parent and child nodes
- illustrate anchor network training
- describe tree-structured network topology for task-specific features
- explain control of trade-off between tasks by changing branching locations
- describe search space as directed acyclic graph
- formulate stochastic branching operation at layer l
- introduce optimization problem
- disentangle training of hypernetworks
- describe edge hypernet training
- describe weight hypernet training
- introduce two-stage training scheme
- illustrate system for architectural search space
- specify initial task preference and computational cost
- refine anchor network
- define active and inactive tasks
- define active loss
- define inactive loss
- define branching regularizer
- describe Gumbel-Softmax reparameterization trick
- illustrate sampled tree structure
- describe modulation of anchor net weights
- illustrate computer system for multi-task predictions
- describe computer system components
- describe model building process
- describe hypernetwork for generating models
- describe model storage
- describe software implementation
- describe computer program product
- describe machine-readable storage media
- describe data processing system
- describe input/output devices
- describe network adapters
- describe hardware processor subsystem
- describe software elements
- describe dedicated circuitry
- describe variations of hardware processor subsystem
- describe embodiment variations
- describe claim scope

