# Background.

2.1. Compressive sensing. CS deals with the recovery of a signal y P R N from undersampled linear measurements of the form z " Φy `e, where Φ P R M ˆN is the measurement matrix, M ă N, and e is the measurement noise [7,14]. Estimating y from the measurements z is ill-conditioned, since the linear system formed by z " Φy is under-determined. CS works under the assumption that the signal y is sparse in a basis Ψ; that is, the signal s, defined as y " Ψs, has at most K non-zero components. Exploiting the sparsity of s, the signal y can be recovered exactly from M " OpK logpN {Kqq measurements provided the matrix ΦΨ satisfies the so-called restricted isometry property (RIP) [4]. In particular, when Ψ is an orthonormal basis and the entries of the matrix Φ are i.i.d. samples from a sub-Gaussian distribution, the product ΦΨ satisfies the RIP. Further, the signal y can be recovered from z by solving a convex problem of the form min }s} 1 subject to }z ´ΦΨs} 2 ď ,

where is an upper bound on the measurement noise e. It can be shown that the solution to (1) is with high probability the K-sparse solution that we seek. The theoretical guarantees of CS have been extended to compressible signals, where the sorted coefficients of s decay rapidly according to a power-law [22].

There exist a wide range of algorithms to solve (1) under various approximations or reformulations [7,38]. Greedy techniques such as Orthogonal Matching Pursuit [28] and CoSAMP [26] solve the sparse approximation problem efficiently with strong convergence properties and low computational complexity. It is also simple to impose structural constraints such as block sparsity into CoSAMP, giving variants such as model-based CoSAMP [3].

## Video compressive sensing.

In this paper, we model a video as a sequence of time-indexed images. Specifically, if y t is the image of a scene at time t, then y 1:T " ty 1 , . . . , y T u is the video of the scene from time 1 to T . Further, we also refer to y t as the "video frame" at time t.

In video CS, the goal is to sense a time-varying scene using compressive measurements of the form z t " Φ t y t , where z t , Φ t and y t are the compressive measurements, the measurement matrix and the video frame at time t, respectively. Given the sequence of compressive measurements z 1:T " tz 1 , z 2 , . . . , z T u, our goal is to recover the video y 1:T " ty 1 , y 2 , . . . , y T u. There are currently two fundamentally different imaging architectures for video CS: the single pixel camera (SPC) and the programmable pixel camera. The SPC [16] uses a single or a small number of sensing elements. Typically, a photo-detector is used to obtain a single measurement at each time instant of the form z t " φ T t y t , where φ t is a pseudo-random vector of 0s and 1s. Typically, under an assumption of a slowly varying scene, consecutive measurements from the SPC are grouped as measurements of the same video frame. This assumption works only when the scene motion is small or when the number of measurements associated with a frame is small. The SPC provides complete freedom in the spatial multiplexing of pixels; however, there is no temporal multiplexing. In contrast, programmable pixel cameras [23,31,43] use a full frame sensor array; during each exposure of the sensor array, the shutter at each pixel is temporally modulated. This enables extensive temporal multiplexing but a limited amount of spatial multiplexing. A key advantage of SPC-based designs is that they can operate efficiently at wavelengths (such as the far infrared) that require exotic detectors; in such cases, building a full frame sensor can be prohibitively expensive.

To date, recovery algorithms for the SPC have used various signal models to reconstruct the sensed scene. Wakin et al. [45] use 3D wavelets as the sparsifying basis for recovering videos from compressive measurements. Park and Wakin [27] use a coarse-to-fine estimation framework wherein the video, reconstructed at a coarse scale, is used to estimate motion vectors that are subsequently used to design dictionaries for reconstruction at a finer scale. Vaswani [40] and Vaswani and Lu [41] use a sequential framework that exploits the similarity of support of the signal between adjacent frames of a video. Under this model, a frame of video is reconstructed using a linear inversion over the support at the previous time instant and a small-scale CS recovery over the residue to detect components beyond the known support. Cevher et al. [9] provide a CS framework for directly sensing innovations over a static scene thereby enabling background subtraction from compressive measurements.

2.3. Linear dynamical system model for video sequences. Linear dynamical systems (LDSs) represent an important class of parametric models for time-series data. A wide variety of spatio-temporal signals have often been modeled as realizations of LDSs. These include dynamic textures [15], traffic scenes [10], video inpainting [13], multi-camera tracking [2] and human activities [37]. The interested reader is referred to [36] for a survey of the use of LDSs as a concise representation for a wide range of computer vision problems. rapidly. This is a consequence of the linear nature of light suggests that the frames of the video lie on a six-dimensional subspace. In practice, deviations from linearity due to saturation lead to small deviations from the six-dimensional subspace as noted from the decaying singular values. (c) Basis vectors associated with a six-dimensional approximation of the data. Blacker pixels denote nonnegative entries while whiter pixels denote positive entries. Together, they define a six-dimensional subspace that defines the observation model of the LDS. (d) State sequence associated with the sixdimensional approximation. The smooth variation of the state values indicate predictability over small time durations -one of the key hallmarks of an LDS. These smooth transitions are captured by the state transition model.

Intuitively, a LDS for a video comprises of two models. First, an observation model that suggests that frames of the video lie close to a d-dimensional subspace; the frame of the video at time t can be represented as y t « Cx t , where C is a basis for the subspace and x t are the subspace coefficients or the state vector at time t. Second, the trajectory that the video charts out in this d-dimensional subspace varies smoothly, is predictable and modeled by a linear evolution of the form x t`1 « Ax t . Figure 1 provides an example of an LDS.

We now formally define the LDS for a video. The model equations are given by y t "Cx t `wt , w t " N p0, Rq (2)

where x t P R d is the state vector at time t, d is the dimension of the state space, A P R dˆd is the state transition matrix, C P R N ˆd is the observation matrix, y t P R N represents the observed measurements, where for the videos of interest in this paper, d ! N . w t and v t are noise components modeled as Gaussian with 0 mean vector and covariance matrices given by R P R N ˆN and Q P R dˆd , respectively. The Gaussian assumption for the process noise is not necessarily an optimal one, but is made for the sake of simplifying the model estimation algorithm. It is known to work well for representing a large class of dynamic textures [15]. An LDS is parameterized by the matrix pair pC, Aq. Note that the choice of C and the state sequence x 1:T is unique only up to a d ˆd linear transformation given the inherent ambiguities in the notion of a state space. In particular, given any invertible d ˆd matrix L, the LDS defined by pC, Aq with the state sequence x 1:T is equivalent to the LDS defined by pCL, L ´1ALq with the state sequence L ´1x 1:T " tL ´1x 1 , L ´1x 2 , . . . , L ´1x T u. This lack of uniqueness has implications that we will touch upon later in Section 5.

Given a video sequence, the most common approach to fitting an LDS model is to first estimate a lower-dimensional embedding of the observations via principal component analysis (PCA) and then learn the temporal dynamics captured in x t , and equivalently A. The most popular model estimation algorithms are N4SID [39], PCA-ID [35], and expectation-maximization (EM) [10]. N4SID is a subspace identification algorithm that provides an asymptotically optimal solution for the model parameters. However, for large problems the computational requirements make this method prohibitive. PCA-ID [35] is a sub-optimal solution to the learning problem. It makes the assumption that estimation of the observation matrix C and the state transition matrix A can be separable, which makes it possible to estimate the parameters of the model very efficiently via PCA. Under this assumption, one first estimates the observation matrix C, (space-filter) and then uses the result to estimate the state state transition matrix A (time-filter) [15]. This learning problem can also be posed as a maximum likelihood estimation of the model parameters that maximize the likelihood of the observations, which can be solved by the EM algorithm [10].

3. CS-LDS Architecture. We provide a high level overview of our proposed framework for video CS; the goal here is to build a CS framework, implementable on the SPC, for videos that are modeled as LDSs. We flesh out the details in Sections 4 and 5. This amounts to estimating the LDS parameters from compressive measurements, i.e, we seek to recover the model parameters C and x 1:T given compressive measurements of the form z t " Φ t y t " Φ t Cx t . We recall that C is the time-invariant observation matrix of the LDS, and y t and x t are the video frame and the state at time t, respectively. The compressive measurements z 1:T are hence expressed as bilinear terms in the unknown parameters C and x 1:t . Handling bilinear unknowns typically requires non-convex optimization techniques thereby invalidating conventional CS recovery algorithms. To avoid this, we propose a two-step sensing method that is specifically designed to address the bilinearity; we refer to this sensing method and its associated recovery algorithm as the CS-LDS framework [34] .

Measurement model: We summarize the CS-LDS measurement model as follows. At time t, we take two sets of measurements:

where q z t P R | M and r z t P R Ă M such that the total number of measurements at each frame is M " | M `Ă M . 1 The measurement matrix in ( 4) is composed of two distinct components: the time-invariant part q Φ and the time-varying part r Φ t . We denote by q z t the common measurements and by r z t the innovation measurements.

We solve for the LDS parameters in two steps. First, we obtain an estimate of the state sequence using only the common measurements q z 1:T . Second, we use this state sequence estimate to recover the observation matrix C using the innovation measurements. State sequence estimation: We recover the state sequence x 1:T using only the common measurements q z 1:T . The key idea is that when y 1:T form the observations of an LDS with system matrices pC, Aq, the measurements q z 1:T form the observations of an LDS with system matrices p q ΦC, Aq. Estimation of the state sequence now can be mapped to a simple exercise in system identification. In particular, an estimate of the state sequence can be obtained by the singular value decomposition (SVD) of the block-Hankel matrix

Given the SVDpHankpq z 1:T , dqq " U H S H V T H , the state sequence estimate is given by

In Section 4, we leverage results from system identification to analyze the properties of this particular estimate as well as characterize the number of measurements | M required. Observation matrix estimation: Given an estimate of the state sequence, p

x 1:T , the relationship between the observation matrix C and the innovation measurements is linear, i.e., r z t " r Φ t Cp x t . In addition, C is time-invariant. Hence, we can accumulate innovation measurements over a duration of time to stably reconstruct C. This significantly reduces the number of innovation measurements Ă M required at each frame. This is especially important in the context of sensing videos, since the scene changes as we acquire measurements. Hence, requiring fewer measurements for each reconstructed frame of the video implies less error due to motion blur.  Using the estimates of the state sequence p x 1:T , we can recover C by solving the following convex problem:

where c i denotes the i-th column of C and Ψ is a sparsifying basis for the columns of C. Note that, in (6), we use all of the compressive measurements z t obtained for each frame of the video -that is, we use both the common and innovation measurements since the common measurement, much like the innovation measurements, are linear measurements of the frames. Further, as we show later in Section 5.2, ambiguities in the estimation of the state sequence induce a structured sparsity pattern in the support of C. The convex program ( 6) can be modified to incorporate such constraints. In addition to this, in Section 5, we also propose a greedy alternative for solving a variant of the convex program.

To summarize, the two-step measurement process described in (4) enables a twostep recovery (see Figure 2). First, we obtain an estimate of the state sequence using SVD on just the common measurements. Second, we use the state sequence estimate for recovering the observation matrix using a convex program. The details of these two steps are discussed in the next two sections.

4. Estimating the state sequence. In this section, we discuss methods to estimate the state sequence x 1:T from the compressive measurements q z 1:T . In particular, we seek to establish sufficient conditions under which the state sequence can be estimated reliably.

## Observability of the state sequence. Consider the compressive measurements given by

where q z t P R | M are the compressive measurements at time t, q Φ P R | M ˆN is the corresponding measurement matrix, and

Φ is time-invariant; hence, ( 7) is a part of the measurement model described in (4) relating to the common measurements. A key observation is that, when y 1:T form the observations of an LDS defined by pC, Aq, the compressive measurement sequence q z 1:T forms an LDS as well; that is,

The LDS associated with q z 1:T is parameterized by the system matrices p q ΦC, Aq. Estimating the state sequence from the observations of an LDS is possible only when the LDS is observable [5]. Thus, it is important to consider the question of observability of the LDS parameterized by p q ΦC, Aq.2 Definition 4.1 (Observability of an LDS [5]). An LDS is observable if, for any possible state sequence, the current state can be estimated from a finite number of observations. Lemma 4.2 (Test for observability of an LDS [5]). An LDS defined by the system matrices pC, Aq and of state space dimension d is observable if and only if the observability matrix

is full rank.

A necessary condition for the observability of the LDS defined by p q ΦC, Aq is that the LDS defined by pC, Aq is observable. However, for the LDSs we consider in this paper, N " d; for such systems, the LDS defined by pC, Aq is observable. Given this assumption, we consider the observability of the LDS parameterized by p q ΦC, Aq next. Lemma 4.3. For N ą d, the LDS defined by p q ΦC, Aq is observable, with high probability, if | M ě d and the entries of the matrix q Φ are sampled i.i.d. from a sub-Gaussian distribution.

Proof. This is established by proving that rankp q ΦCq " d when | M ě d. Assume that rankp q ΦCq ă d, i.e., D α P R d such that q ΦCα " 0, α ‰ 0. Let φ T be a row of q Φ. The event that φ T Cα " 0 is one of negligible probability when the elements of φ are assumed to be i.i.d. according to a sub-Gaussian distribution such as Gaussian or Bernoulli. Hence, with high probability rankp q ΦCq " d when | M ě d. Observability is the key criterion for recovering the state sequence from the common measurements. When the LDS associated with the common measurements is observable, we can estimate the state sequence -up to a linear transformationby factorizing the block Hankel matrix Hankpq z 1:T , dq in (5). Hankpq z 1:T , dq can be written as Hankpq z 1:T , dq " Op q ΦC, Aqrx 1 x 2 ¨¨¨x T ´d`1 s.

Hence, when the observability matrix Op q ΦC, Aq is full rank, we can recover the state sequence by factoring the Hankel matrix using the SVD. Suppose the SVD of the Hankel matrix is Hankpq z 1:T , dq " U SV T . Then, the estimate of the state sequence is obtained by

where S d is the diagonal matrix containing the d-largest singular values in S, and V d is the matrix composed of the right singular vectors corresponding to these singular values. The estimate of the state sequence obtained from SVD differs from its true value by a linear transformation. This is a fundamental ambiguity that stems from the lack of uniqueness in the definition of the state space (see Section 2.3). The state sequence estimate in (9) can be improved, especially for high levels of measurement noise, by using system identification techniques mentioned in Section 2.3. However, the simplicity of this estimate makes it amenable for further analysis. When | M ą d, we can choose to factorize a smaller-sized Hankel matrix Hankpq z 1:T , qq provided q ą d{ | M . Note that when q " 1, we do not enforce the constraints provided by the state transition model, thereby simply reducing the LDS to a linear system. For q ą 1, we enforce the state transition model over q successive time instants; i.e., we enforce

Larger values of q lead to smoother state sequences, since the estimates conform to the state transition model for longer durations.

We next study the observability properties of specific classes of interesting LDSs and the conditions on q Φ under which the observability of p q ΦC, Aq holds.

## Case: |

M " 1. A particularly interesting scenario is when we obtain exactly one common measurement for each video frame. For such a scenario, | M " 1 and, hence, the measurement matrix can be written as a row-vector: q Φ " φ T P R 1ˆN . We now establish conditions when the observability matrix Opφ T C, Aq is full rank for this particular scenario. Let q c " pφ T Cq T " C T φ and B " A T . We seek a condition when the observability matrix, or equivalently its transpose,

is full rank. 3 We concentrate on the specific scenario where the matrix B (and hence, A) is diagonalizable, i.e., B " QΛQ ´1, where Q P R dˆd is an invertible matrix (hence, full rank) and Λ is a diagonal matrix with diagonal elements tλ i , 1 ď i ď du. For such matrices, the transpose of the observability matrix can be written as

where e " Q ´1q c. This can be expanded as . 3 There is an interesting connection to Krylov-subspace methods here. In Krylov-subspace methods, a low-rank approximation to a matrix K is obtained by forming the matrix rc Kc K 2 c ¨¨¨s with c randomly chosen. Convergence proofs for this method are closely related to Theorem 4.4. To the best of our knowledge, diagonalizability of K plays an important role in most of these proofs. The interested reader is referred to [32] for more details.

We can establish a sufficient condition for when the observability matrix is full rank.

Theorem 4.4. Let | M " 1 and let the elements of q Φ " φ T be i.i.d. from a sub-Gaussian distribution. Then, with high probability, the observability matrix is full rank when the state transition matrix is diagonalizable and its eigenvectors and eigenvalues are unique.

Proof. From the discussion above, the observability matrix can be written as a product of three square matrices: Q, the matrix of eigenvectors of A T ; a diagonal matrix with entries defined by the vector e " Q ´1C T φ; and a Vandermonde matrix defined by the vector of eigenvalues of A tλ i , 1 ď i ď du. When the eigenvectors and eigenvalues are distinct, the first and last matrices are full rank. Given that the elements of φ are i.i.d., the probability that e i " 0 is negligible and, hence, the diagonal matrix is full rank with high probability. Since the product of full rank square matrices is full rank as well, this implies that the observability matrix is full rank with high probability.

Remark: Theorem 4.4 requires that the state-transition matrix be full-rank (non-zero Eigenvalues) and be diagonalizable with unique Eigenvalues. Most matrices are diagonalizable (once, we allow complex Eigenvalues) and hence, the requirement that state transition matrix be diagonalizable is not restrictive. A more restrictive condition is requiring the Eigenvalues of the matrix to be unique. Unfortunately, this eliminates some commonly observed state transition matrix such as the Identity matrix -which is coupled with Brownian processes. Nonetheless, Theorem 4.4 is intriguing, since it guarantees recovery of the state sequence even when we obtain only one common measurement per time instant. This is immensely useful in reducing the number of measurements required to sense a video sequence.

Interestingly, we can reduce | M even further. This is achieved by not obtaining common measurements at some time instants.

## Missing measurements: Case |

M ă 1. If we do not obtain common measurements at some time instants, then is it still possible to obtain an estimate of the state sequence? One way to view this problem is that we have incomplete knowledge of the Hankel matrix defined in (5) and we seek to complete this matrix. Matrix completion, especially for low rank matrices, has received significant attention recently [6,8,30].

Given that the Hankel matrix Hankpq z 1:T , qq in ( 5) is low rank for videos modeled as LDSs, we formulate the missing measurement recovery problem as one of matrix completion. Suppose that we have the common measurements only at time instants given by the index set I Ă t1, . . . , T u, i.e., we have knowledge of tq z i , i P I u. We can recover the missing measurements by exploiting the low-rank property of Hankpq z 1:T , qq. Specifically, we solve the following problem to obtain the missing measurements: min rankpHankpg 1:T , qqq s.t. g i " q z i , i P I .

However, rankp¨q is a non-convex function which renders the above problem NPcomplete. In practice, we can solve a convex relaxation of this problem4 min }Hankpg 1:T , qq} ˚s.t. g i " q z i , i P I ,

where }H} ˚is the nuclear norm of the matrix H, which equals the sum of its singular values. Once we fill in the missing measurements, we use (9) to recover an estimate of the state sequence. An important quantity to characterize is the proportion of time instants in which we can choose to not obtain common measurements. This amounts to developing a sampling theorem for the completion of low-rank Hankel matrices; to the best of our knowledge, there has been little theoretical work on this problem. Instead, we address it empirically in Section 6.

# 5.

Estimating the observation matrix. In this section, we discuss estimation of the observation matrix C given the estimates of the state space sequence p

x 1:T .

5.1. Need for innovation measurements. Given estimates of the state sequence p

x 1:T , the matrix C is linear in the compressive measurements which enables a host of conventional 2 -based methods as well as 1 -based recovery algorithms to estimate C. However, recall that the C is a N ˆd matrix and, hence, the common measurements by themselves are not enough to recover C, unless | M is large. The common measurements q z 1:T used in the estimation of the state sequence are measured using a time-invariant measurement matrix q Φ. A time-invariant measurement matrix, by itself, is not sufficient for estimating C unless | M is very large. To alleviate this problem, we take additional compressive measurements of each frame using a time-varying measurement matrix. Let r z t " r Φ t y t `ωt " r Φ t Cx t `ωt , where

ˆN are the compressive measurements and the corresponding measurement matrix at time t. As mentioned earlier in Section 3, we refer to these as innovation measurements. Noting that C is a time-invariant parameter, we can collect innovation measurements over a period of time before reconstructing C. This enables a significant reduction in the number of measurements taken at each time instant.

## Structured sparsity for C.

Individual frames of a video, being images, exhibit sparsity/compressibility in a certain transform bases such as wavelets and DCT. If the support of the frames are highly overlapping -this is to be expected given the redundancies in a video -then columns of C are compressible in the same transform bases; a consequence of C being a basis for the frames of the video. Further, note that the columns of C are also the top principal components and hence, capture the dominant motion patterns in the scene; when motion in the scene is spatially correlated, the columns of C are compressible in wavelet/DCT basis. For these reasons, we assume that the columns of C are compressible in a wavelet/DCT basis and employ sparse priors in the recovery of the observation matrix C. We can potentially obtain an estimate of C by solving the following convex program:

Here, we denote the columns of the matrix C as c i , i " 1, . . . , d. Ψ is a sparsifying basis for the columns of C; we have the freedom to choose different sparsifying bases for different columns of C.

The assumption of compressibility in a transform basis was sufficient for all the videos we test on (see Section 6). However, it is entirely possible that a video is not compressible in a transform basis. There are two possible ways to address such a scenario. First, given training data, we can use dictionary learning algorithms [24] to learn an appropriate basis where in the columns of C are sparse/compressible. Second, in the absence of training data, we revert to 2 -based methods to recover C; in such cases, we would typically need more measurements to recover C.

However, the convex program pP 1 q is not sufficient as-is to recover C. The reason for this stems from ambiguities in the definition of the LDS (see Section 2.3). The use of SVD for recovering the state sequence introduces an ambiguity in the estimates of the state sequence in the form of rp x 1:T s « L ´1rx 1:T s, where L is an invertible d ˆd matrix. As a consequence, this will lead to an estimate p C " CL satisfying z " Φ p Cp x t " ΦpCLqpL ´1x t q " ΦCx t . Suppose the columns of C are K-sparse (equivalently, compressible for a certain value of K) each in Ψ with support S k for the k-th column. Then, the of CL are potentially dK-sparse with identical supports S " Ť k S k . The support is exactly dK-sparse when the S k are disjoint and L is dense. At first glance, this seems to be a significant drawback, since the overall sparsity of p C has increased to d 2 K (the sparsity of C is dK). However, this apparent increase in sparsity is alleviated by the columns having identical supports, which can be exploited in the recovery process [17].

Given the estimates p x 1:T , we estimate the matrix C by solving the following convex program:

where s i is the i-th row of the matrix S " Ψ T C and Ψ is a sparsifying basis for the columns of C. The above problem is an instance of an 2 ´ 1 mixed-norm optimization that promotes group sparsity; in this instance, we use it to promote group column sparsity in the matrix S, i.e., all columns have the same sparsity pattern.

There are multiple efficient ways to solve pP 2´ 1 q, including solvers such as SPG-L1 [38] and model-based CoSAMP [3]. Algorithm 1 summarizes a model-based CoSAMP algorithm used for recovering the observation matrix C. The specific model used here is a union-of-subspaces model that groups each row of S " Ψ T C into a single subspace/model.

## Value of Ă

M . For stable recovery of the observation matrix C, we need in total OpdK logpN {Kqq measurements; for a large class of practical solvers, a rule of thumb is 4dK logpN {Kq. Given that we measure Ă M time-varying compressive measurements at each time instant, over a period of T time instants, we have Ă M T compressive measurements for estimating C. Hence, for stable recovery of C, we need approximately

This indicates extremely favorable operating scenarios for the CS-LDS framework, especially when T is large (as in high frame rate capture). Let T " τ f s , where τ is the time duration of the video in seconds and f s is the sampling rate of the measurement device. The number of compressive measurements required in this case is Ă M " 4 dK τ fs log `N K ˘. Given that the complexity of the LDS typically (however, not always) depends on τ , for a fixed τ the number of measurements required to estimate C decreases as 1{f s as the sampling rate f s is increased. Indeed, as the sampling rate f s increases, Ă

M can be decreased while keeping M f s constant. This will ensure that ( 14) is satisfied, enabling stable recovery of C. @t, v t Ð z t ´Θt Sp x t Ω old Ð Ω end 5.4. Mean + LDS. In many instances, a dynamical scene is modeled better as an LDS over a static background, that is, y t " Cx t `µ. This can be handled with two small modifications to the Algorithm 1. First, the state sequence rx 1:T s is obtained by performing an SVD on the matrix Hankpq z 1:T , d guess q modified such that each row sums to zero. This works under the assumption that the sample mean of q z 1:T is equal to q Φµ, the compressive measurement of µ. Second, given that the support of µ need not be similar to that of C, the resulting optimization problem can be reformulated as

As with the convex formulation, the model-based CoSAMP algorithm described in Algorithm 1 can be modified to incorporate the mean term µ; an additional modification here is the requirement to specify a priori the sparsity of the mean K µ " }Ψ T µ} 0 .

6. Experiments. We present a range of experiments validating various aspects of the CS-LDS framework. We use permuted noiselets [12] for the measurement M per frame. Each curve is for a different level of measurement noise as measured using input SNR. For low noise levels, we obtain a good reconstruction SNR ( ą 20 dB) even at | M " 1; this hints at very high compression ratios. (b) Reconstruction SNR of the Hankel matrix for the scenario with missing common measurements. We can estimate the Hankel matrix very accurately even at 80% missing measurements. This suggests immense flexibility in the implementation of the CS-LDS system. matrices, since they have a fast scalable implementation. We use the term compression ratio N {M to denote the reduction in the number of measurements as compared to the Nyquist rate. Finally, we use the reconstruction SNR to evaluate the recovered videos. Given the ground truth video y 1:T and a reconstruction p y 1:T , the reconstruction SNR in dB is defined by 10 log 10

We compare CS-LDS against frame-by-frame CS, where each frame of the video is recovered separately using conventional CS techniques. We use the term oracle LDS when the parameters and video reconstruction are obtained by operating on the original data itself. Oracle LDS estimates the parameters using a rank-d approximation of the ground truth data. The reconstruction SNR of the oracle LDS gives an upper bound on the achievable SNR. Finally, the ambiguity in the observation matrix (due to non-uniqueness of the SVD based factorization) as estimated by oracle LDS and CS-LDS is resolved by finding the best d ˆd linear transformation that registers the two estimates.

6.1. State sequence estimation. We first provide empirical verification of the results derived in Sections 4.1 and 4.2. It is worth noting that, in the absence of noise, Theorem 4.4 suggests exact recovery of the state sequence. In practice, it is important to check the robustness of the estimate to measurement noise. Figure 3(a) analyzes the performance of the state space estimation for different values of the number of common measurements | M and different SNRs of the measurement noise. We define input SNR in dB as 10 log 10 `př }y t } 2 2 q{pT σ 2 q ˘, where σ is the standard deviation of the noise. Here, we consider the scenario when | M ě 1. The underlying state space dimension is d " 10 with T " 500 frames. As expected, for low SNRs, the reconstruction SNR is very high even for small values of | M . In addition to this, the accuracy at | M " 1 is acceptable, especially at low SNRs. Next, we validate the implications of Section 4.3, where we discuss the scenario of | M ă 1 by simulating various proportions of missing common measurements. Figure 3(b) shows reconstruction SNR for the Hankel matrix in (5) for varying amounts of missing measurements. We recover the Hankel matrix by solving (11) using CVX [21]. Figure 3(b) demonstrates a very high reconstruction SNR even at a very high rate of missing measurements. As mentioned earlier, not having to sense common measurements at all frames is very useful, since we can stagger our acquisition of common and innovation measurements. In theory, this enables a measurement strategy where we need to sense only one measurement per frame of the video without having to group consecutive measurements of the SPC. Hence, we can aim to reconstruct videos at the sampling rate of the SPC. To the best of our knowledge, this is the first video CS acquisition design capable of doing this. 6.2. Dynamic Textures. Our test dataset comprises of videos from the DynTex dataset [29]. We used the mean+LDS model from Section 5.4 for all the video CS experiments with the 2D DCT as the sparsifying basis for the columns of C and 2D wavelets as the sparsifying basis for the mean. We used the model-based CoSAMP solver in Algorithm 1 for these results, since it provides explicit control of the sparsity of the mean and the columns of C. We used (14) as a guide to select these values.

Figure 4 shows video reconstruction of a dynamic texture from the DynTex dataset [29]. Reconstruction results are under a compression N {M " 234; this is an operating point where frame-to-frame CS recovery is completely infeasible. However, the dynamic component of the scene is relatively small (d " 20), which allows us to recover the video from relatively few measurements. The reconstruction SNRs of the recovered videos shown are as follows: oracle LDS = 24.97 dB, frame-to-frame Each row shows a sampling of frames of the video reconstructed at a different compression ratios. Inset in each row is the resolution of the video used as well as the compression at sensing and the reconstruction SNR. While performance degrades with increasing compression, it also gains significantly for higher dimensional data; the reconstruction at 256 ˆ256 pixels preserves finer details. Figure 5 shows the reconstruction of a video, of 6 blinking LED lights, from the DynTex dataset. We show reconstruction results at different compression ratios as well as different image resolutions. It is noteworthy that, even at a 100ˆcompression, the reconstruction at a resolution of 256 ˆ256 pixels preserves fine details. Performance with measurement noise: We validate the performance of our recovery algorithm under various amounts of measurement noise. Note that the columns of C with larger singular values are, inherently, better conditioned to deal with this measurement error. The columns corresponding to the smaller singular values are invariably estimated with higher error. Figure 6 shows the performance of the recovery algorithm for various levels of measurement noise. The effect of the measurement noise on the reconstructions is perceived only at low input SNRs. In part, this robustness to measurement noise is due to the LDS model mismatch dominating the reconstruction error at high input SNRs. As the input SNR drops significantly below the model mismatch term, predictably, it starts influencing the reconstructions more. This provides a certain amount of flexibility in the design of potential CS-LDS cameras. Computation time and spatial resolution: Figure 7 shows recovery algorithm applied to a video of length 560 frames at different spatial resolutions. Shown in Figure 7 are the amount of time taken for each recovery, which scales gracefully for increasing spatial resolution, and reconstruction SNR, which approaches the performance of an oracle LDS. The improvement in reconstruction comes due to the increase in the number of compressive measurements at high resolutions, since the compression ratio is held fixed. However this does comes at the cost of requiring a faster compressive camera to acquire the data since a larger number of measurements. Gallery of results: Finally, in Figure 8, we demonstrate performance of the CS-LDS methodology for sensing and reconstructing a wide range of videos. The reader is directed to the supplemental material as well as the project webpage [1] for animated videos of these results.

6.3. Application in activity analysis. mentioned in Section 2.3, LDSs are often used in classification problems, especially in the context of scene/activity analysis. A key experiment in this context is to check if the CS-LDS framework recovers videos that are sufficiently informative for such applications. To this end, we Procrustes distance between them is given by

where spanpQ 1 q " spanpOpC 1 , A 1 qq and spanpQ 2 q " spanpOpC 2 , A 2 qq. We use this distance function in a nearest neighbor classifier in both the activity classification experiment.

The UCSD Traffic Dataset [10] consists of 254 videos capturing traffic of three types: light, moderate, and heavy. Each video is of length 50 frames at a resolution of 64 ˆ64 pixels. Figure 9 shows the reconstruction results on a traffic sequence from the dataset. We perform a classification experiment of the videos into these three categories. There are four different train-test scenarios provided with the dataset. For comparison, we also perform the same experiments with fitting the LDS model on the original frames (oracle LDS). We perform classification at two different values of the state space dimension d and at a fixed compression ratio of 25ˆ. Table 1 shows classification results. We also show comparative results obtained using a probabilistic kernel on dynamic texture models [10] in conjunction with SVMs in the last two rows of the table. Results for each individual experiment were not reported, only an aggregate number was reported which is shown in the table. It can be seen that even without sophisticated non-linear classifiers, we are able to obtain comparable performance using a simple nearest neighbor classifier using the dynamic texture model parameters. This shows that the obtained parameters possess discriminatory properties, and can be used in conjunction with other sophisticated classifiers that build on dynamic texture models as in [10]. The UMD Human Activity Dataset [42] consists of 100 videos, each of length 80 frames, depicting 10 different activities: pickup object, jog, push, squat, wave, kick, bend, throw, turn around and talk on cellhpone. Each activity was repeated 10 times, so there were a total of 100 sequences in the dataset. As with the traffic experiment, we use an LDS model on the image intensity values without any feature extraction. Images were cropped to contain the human and resized to 330 ˆ300. The state space dimension was fixed at d " 5 and the compression was varied from 50ˆto 200ˆ. We performed a leave-one-execution-out test. The results are summarized in table 2. As can be seen, the CS-LDS framework obtained a classification performance that is comparable to the oracle LDS. For this dataset, both oracle LDS and CS-LDS obtained a perfect classification score of 100% up to a compression ratio of 50ˆ. Further, as shown in Table 2, we obtain comparable performance to a far more sophisticated method employing advance shape-based features for activity recognition. This suggests that the CS-LDS framework should be extremely useful in a wide range of applications beyond just video recovery, and can provide a basis to acquire more sophisticated features for tackling challenging activity recognition problems.

7. Discussion. In this paper, we have proposed a framework for the compressive acquisition of dynamic scenes modeled as LDSs. In particular, this paper emphasizes the power of predictive/generative video models. In this regard, we have shown that a strong model for the scene dynamics enables stable video reconstructions at very low measurement rates. In particular, it enables the estimation of the state sequence associated with a video even at fractional number of common measurements per video frame ( | M ď 1). The use of CS-LDS for dynamic scene modeling and classification also highlights the purposive nature of the framework. Implementation issues: The results provided in the paper are mainly based on simulations. While a full-fledged implementation on hardware is beyond the scope    of this paper, we discuss some of the key issues and challenges in obtaining such results. Focusing on the single pixel camera (SPC) as our imaging architecture, the achievable compression and resolution are limited by the amount of motion in the scene and the sampling rate of the camera. We discuss the roles these two parameters play in practice. Amount of motion determines an inherent notion of frame-rate of the video; note that real life scenes have no notion of "frame-rate". If the scene changes negligibly for a time duration τ , then 1{τ (for the largest value of τ ) becomes a good measure of frame-rate for a scene. For example, static scenes do not change over an infinite time duration (τ " 8) and hence, can be sensed at 1{τ " 0 fps. Given that we seek to sense this scene at a spatial resolution of N pixels, a Nyquist camera would need to operate at N {τ measurements per second.

Suppose this scene over a duration of T seconds can be well approximated by a ddimensional LDS, then the total number of free variables to estimate is approximately dpT {τ q for the state sequence and Kd for the observation matrix. An SPC operating at 1{f s samples per second obtains a total of T f s compressive measurements. If CS-LDS were employed at a compression ratio of C, then The key dependence here are on how d, K and τ change as a function of N . In particular, even if d and K increased as ? N , then f s would need be scale linearly in N to maintain the same compression level. Connection to affine-rank minimization: The pioneering work of Fazel [18] in developing convex optimization techniques to system identification problems has interesting parallels to the ideas proposed in this paper. One of the key ideas espoused in [18] is that, when the video sequence y 1:T is an LDS, the block Hankel matrix Hankpy 1:T , qq is low rank. When we have linear measurements of the video frames, we can solve an affine-rank problem to recover the video. However, such methods optimize on the Hankel matrix directly and lead to computationally infeasible designs even for videos of very small dimensions. In contrast, CS-LDS has been shown to be fast and computationally feasible for very large videos involving millions of variables. The key is our two-step solution that isolates the space of unknowns into two manageable sets and solves for each separately. Universality: An attractive property of random matrix-based CS measurement is the universality of the measurement process. Universality implies that the sensing process is independent of the subsequent reconstruction algorithm. This makes the sensing design "future-proof"; for such systems, if we devise a more sophisticated and powerful recovery algorithm in the future, then we do not need to redesign the camera or the sensing framework. The CS-LDS framework violates this property. The two-step measurement process of Section 3, which is key to breaking the bilinearity introduced by the LDS prior, implies that the CS-LDS design is not universal. An intriguing direction for future research is the design of a universal CS-LDS measurement process. Online tracking: We have made the assumption of a static observation matrix C. However, as the length of the video increases, the assumption of a static C is satisfied only by increasing the state space dimension. An alternate approach is to allow for a time-varying observation matrix Cptq and track it from the compressive measurements. This would give us the benefit of a low state space dimension and yet, be accurate when we sense for long durations. Beyond LDS: Figure 10 captures the relative performance of MPEG-4 compression algorithm and CS-LDS on a video. MPEG-4 has access to the ground truth video and,  7). Shown are (a) reconstruction SNR at various compression ratios, and (b, c -top) a few reconstructed frames and (b,c -bottom) error in reconstruction magnified 10ˆ. It is worth nothing that the MPEG-4 algorithm has complete access to the ground truth video, while CS-LDS works purely with undersampled linear measurements of the video. None-the-less, even at the same reconstruction SNR, the quality of MPEG-4 recovery is significantly better. This can be attributed to the non-linear and adapted coding that seeks to mitigate errors that are perceptually dominant.

as a consequence, it achieves significantly better compressions for the same performance in recovery (see Figure 10(a)). Further, it is worth noting that the non-linear encoding in MPEG-4 produces errors that are imperceptible and hence, even at the same level of reconstruction error, produces videos that are of higher visual quality (see Figure 10(b,c)). This points at the inherent drawbacks of a linear encoder. While the CS-LDS framework makes a compelling case study of LDSs for video CS, its applicability to arbitrary videos is limited. In particular, it does not extend to simple non-stationary scenes such as people walking or panning cameras (see the result associated with Figure 8(h)). This motivates the search for models more general than LDS. In this regard, a promising line of future research is to leverage models from the video compression literature for CS recovery.

