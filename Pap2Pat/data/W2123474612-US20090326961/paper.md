# II. TRANSACTION TRACKING WATERMARKS

Transaction tracking watermarks, by definition, are used to distinguish individual copies of the content. This means that different copies of the same audio and/or visual content must carry distinct codes. Typical scenario is to embed a new U.S. Government work not protected by U.S. copyright watermark whenever a new copy is generated and sent out, i.e. when a transaction is done. This can be contrasted to other digital watermark applications, such as copy-control, content ID, source ID (authentication) watermarks, etc., where watermarks in each copy of given content have the same code. Therefore, in other applications the embedding of watermark is typically done once per content, as the last step in producing the content. Sometimes transaction watermarking is called 'fingerprinting' to signify that seemingly identical copies of a content are still unique akin to human fingerprints [10]. Also, this technique is called forensic watermarking since the detection of copyright violators is done for forensic purposes. Further, the technique based on transaction watermarks is sometimes referred as 'traitor tracing' [11] technique. This name comes from an old application [12] where different copies of sensitive document (state secrets) contain different watermarks. Once the copy is found in unauthorized hands it is possible to trace down the traitor who disclosed it.

One application for transaction watermarks could be electronic content distribution over the Internet. Whenever a customer orders a song or a movie, a unique code is imbedded into the copy sent to the particular user, and the code is associated (in a database) with other information about the user such as email address, credit card information etc. If this copy is later illegally distributed on a file-swapping Internet site it is possible to identify the user who obtained it through legal channels, prosecute him, or simply blacklist him to prevent further content downloads. In this application each transaction, such as downloading of a movie, is associated with the watermark embedding.

Alternative usage scenario is to embed transaction watermarks in each copy of prerelease for a content sent to relevant people in the industry, producers, audio engineers, even broadcast stations, in order to generate some interest in the public before the regular release. The example of Oscar screeners described above illustrates this application.

Another case where transaction watermarks are needed is in distribution of pay-per-view programs on cable TV. Each settop box can, while de-scrambling the content, also could embed the unique code that identifies particular user. If a copy of the content shows up in illegal distribution channels, the embedded code can be used to track down the user who served as a front for pirates.

In the case of theater piracy it is responsibility of theater owners to look for cases of hand-held video recorders used to capture the movie for further unlawful usage and/or distribution. Therefore, if individual copies of movies carry transactional watermarks it is possible to identify theater in which the owner didn't prevent the piracy and the date and time when the copying occurred. This approach would also cover cases where theater employees perform illegal copying.

Further, transaction watermarks can be used in news generation and distribution. Audio and/or video clips are exchanged between broadcast stations and networks with attached limitations on it usage, number of broadcasts, redistribution etc. It is desirable to embed distinct watermarks in each copy, so that it is possible to track down violators in the case of usage outside specified limits.

## III. TRANSACTION WATERMARK REQUIREMENTS

The design requirements imposed on transaction watermarks are in some cases similar or the same as for other, better-known, watermark applications, such as copy control, content ID, and source ID watermarks. For example, all watermarks should be virtually imperceptible, either in normal viewing/listening conditions and untrained viewers/listeners, or even imperceptible to skilled engineers in optimal studio conditions.

Similarly, transaction watermarks, as well as other digital watermarks, should be robust to all standard signal processing techniques, such as D/A and A/D conversion, lossy data compression, cropping, dynamic range compression etc. List of standard processing that watermarks should survive can be found in [13], [14].

Generally all watermarks should have small probability of false detection, but this requirement varies depending on application. For example, in the case of copy control watermarks specified for DVD audio standard, the requirement is one false detection in 10 12 time intervals of 15 second each, which can be recalculated as one false detection in five million years of continuous monitoring.

Alternatively, for broadcast monitoring of feature music for the purpose of 'spin count', and building of popularity charts, the probability of false detections is required to be much lower, e g. of the order of one false per day per station.

Requirement for false positive detection rate for transaction watermarks falls somewhere between these two extremes. Typically it is desirable to have reliability of some other tools used in courts to 'prove guilt beyond reasonable doubt', such as fingerprint matching or DNA testing. However, the most important feature is to have reliable calculation of probability of false detections, e.g. when the data is presented in the court.

Typically amount of information that is stored within watermark payload is larger for transaction watermarks than for other listed applications (copy control, content ID, source ID etc). This comes from the fact that transaction watermarks usually also need to carry content/source ID, and than some more data to distinguish individual copies.

However, the most important difference in requirements between transaction watermarks and all other watermarks come in two fields -security requirements, and processing requirements, and we will discuss them in separate sections below.

# A. Security Requirements

Security of a watermarking technology refers to its ability to withstand intentional attacks designed with full knowledge of the design algorithms, but without the knowledge of a secret key. Most attacks are attempts to erase watermarks, i.e. make them undetectable, for example in order to disable copy control [15][16]. Some attacks are concerned with forging (falsification) of a watermark, or copying watermarks from one content onto another, in order to give false authority to a signal, or to affect royalty payments, etc.

Ability of watermarks to withstand erasure attacks is related to robustness in the sense that any watermark that is not robust to standard content processing techniques cannot be considered secure. However, many watermark technologies are quite robust to regular processing, but still have a weakness that renders them insecure. For example, many watermarks based on spread spectrum techniques [17], [18] are susceptible to synchronization attacks.

It should be clear that any watermark could be erased if enough distortion is piled upon the watermarked signal. However, the value of the signal is diminished by the distortion. Therefore a successful attack must satisfy some limits on how much distortion is allowed. For example in SDMI Public Challenge [19] for audio watermarks the requirement was that no attack should damage audio content more than MPEG compression corresponding to 96 kbps for stereo signal.

There is a lot of ongoing effort to design novel attacks to a particular technology [20], [21], and to design attack suite that can be used as benchmark to compare different technologies [22]. Some people argue that no watermarking technology can possibly be secure, since it is impossible to predict all future attacks. Others would argue that in most applications it is enough to put significant obstacles on the path of pirates to discourage most of them, and to reduce piracy, if not eliminate it.

Transaction watermarks should also be able to withstand erasure attacks in the same manner as, say, copy control watermarks. However, on one hand copy control watermarks are more exposed since attacker has readily available outcome of his attack (copying allowed or not), while transaction watermarks are analyzed in a secure, forensic environment. On the other hand transaction watermarks are more exposed due to existence of copies of the same content with distinct codes. Parties in possession of distinct copies may collude to facilitate a number attacks not feasible in copy control environment.

For example, by simply subtracting two copies with different watermarks, the pirate obtains the difference of the pure watermarks, which can help him analyze the secret key of the hiding technique and devise a sophisticated attack. Secondly, the pirate can average a number of copies to weaken individual watermarks, make them interfere, and eventually make them undetectable. Similarly, the pirate can cut portions of different copies and splice them together. The resulting signal has segments of different watermarks spliced together, which is hard to use to identify the pirate.

There are a number of papers that analyze transaction watermarking from information theory perspective [23][24][25][26][27][28]. The objective is to design codes such that in the case of embedding of n distinct codes any subset of k codes has a unique set of identical symbols. The implication is that identical symbols are not affected by any collusion attack while non-identical symbols are. Therefore, upon identification of symbols not corrupted in the collusion it is possible to identify all colluders if their number doesn't exceed k. This approach is not very practical since for most watermarking systems it is difficult to distinguish symbols that are affected by collusion attack from those that are not. Many symbols are corrupted due to regular processing or erasure attacks. Effects of such corruption are heavy on all techniques cited above, and may result in false accusation of innocent owners of watermarked content.

# B. Processing Load Requirements

Watermark processing occurs at two ends -watermark embedding and extracting. In principle it is desirable to minimize the processing load at both ends, but the emphasis can be largely different depending on the application. For example for copy control application, the watermark is embedded once per content, typically in studio where the content is generated, but the watermark extraction occurs in consumer devices. Obviously it is paramount to have extractors cheap and simple to implement, while embedder processing is less critical.

On the other hand, transaction watermarking is done many times, for each copy, e.g. while user is waiting to download a content from the Internet site. However, extraction is done rarely, when an offending party needs to be identified. Obviously, in this case simplicity of embedding is more important than simplicity of extracting a watermark.

Moreover, in the Internet distribution business, the host signal (music, image or video) is typically stored and delivered in a compressed form (e.g., MP3 format in music). This means that a typical watermark embedding process requires decompression, embedding, and then recompression before transmission. This imposes additional processing requirements, and adds more noise to the host signal in the process. Therefore, it is desirable to embed watermarks without decompression/recompression steps.

## IV. COMPRESSED DOMAIN EMBEDDING

The compressed domain embedding proposed in this paper consists of two steps, preprocessing and marking, as illustrated in Fig. 1. In the preprocessing stage, a host signal is marked by one or more embedders. Each embedder embeds a string of identical symbols. Distinct embedders may, but do not have to, use the same embedding technology. Important restriction is that all embedders should use the same symbol interval, which is further related to perceptual compression technique as described below. After embedding, marked signals are compressed by a perceptual compression technique such as MPEG, JPEG, etc, and saved in storage such as hard disk, optical disk, flash memory etc. Similarly, unmarked host signal may be compressed and saved in the storage. At the end of preprocessing stage the storage should contain at least two distinct copies of host signal that are at least partially overlapping. For example, at the end of preprocessing stage the storage may contain complete compressed copy of unmarked signal together with a partial copy of host signal marked by embedder 0. Alternatively, storage may contain two full copies of host signal, one marked by embedder 0, and the other marked by embedder 1, but without a compressed copy of unmarked signal. Note that marked and unmarked copies are perceptually similar and any of them can be used to present the host signal, or its portion, to the user. Selection among alternatives used to present host signal can be done differently for different copies, which is the basis for forensic marking. If only two distinct versions of host signal are present in the storage at the end of preprocessing, the marking phase can create only binary symbols of forensic mark in the marked content, but if N distinct copies are present, marking phase can generate N-ary symbols of forensic mark.

In the marking phase of the process, two or more distinct copies of host signal, also known as tributaries, are brought from the storage into a multiplexer (MUX) at the time when a creation of marked copy is requested. This request must be associated with metadata that describe the details of the transaction, such as intended destination of the marked copy, time and source of the request etc.

Each request for creation of a marked copy triggers a creation of a unique code in Code Generator block. This code is embedded in the marked copy, but also saved in a database, where it is linked to the Transaction Metadata. This database is later used to link the codes extracted from a marked copy to the transaction that caused the creation of this particular copy.

The code created by code generator controls the operation of MUX block, and governs selection of host signal segments from different tributaries. As an example we will explain in more detail MUX operation where the code is binary, and there are two tributaries one coming from embedder 0 and the other coming from embedder 1, which is equivalent to the case where one tributary is unmarked host signal, while the other tributary is host signal marked by embedder 0.

Generally perceptual compression algorithms, such as MPEG or JPEG, divide host signal into compression units or frames, and each compression unit is independently processed and stored. MUX block performs selection of compression units from tributaries according to code provided by code generator, and assembles a string of compression units that represent bitstream of marked content. This procedure can be called cut-and-splice procedure.

An illustration of cut-and-splice procedure is shown in Fig. 2. Suppose the desired watermark bit pattern is 00101…. Then the first unit of the output bitstream should be the first unit of bitstream from 0.bs. The second unit of the output bitstream should be the second unit of bitstream from 0.bs. The third unit of the output bitstream should be the third unit of bitstream from 1.bs, etc. Since different perceptual compression techniques use different compression units, the marking technology has to be adjusted to a particular selection of perceptual compression technology. However, this is not a significant restriction since selection of watermarking parameters can be done after the selection of perceptual compression technology, and can be adjusted case-by-case. Note that code extraction is done in forensic environment, where details of selected watermark parameters for particular content can be known prior to the extraction process. Alternatively, multiple extraction attempts can be done using various selection of watermarking parameters matching various perceptual compression algorithms.

# A. AAC Compression Example

In order to illustrate adjustment of watermarking technology to the selection of perceptual compression technology we will describe in more detail the case of audio signal watermarking, where perceptual compression is represented by Advanced Audio Coding (AAC) technology [29].

In AAC, as in most other audio compression technologies, time domain audio samples are first transformed to frequency domain spectrum. The transformation used in AAC is MDCT (Modified Discrete Cosine Transform) with 50% windowed overlap. The compressed bitstream contains all information needed to reconstruct the spectrum. In order to reconstruct the time domain audio samples, an inverse transform, IMDCT, is performed with 50% windowed overlap and add. Spectrum values in each bitstream unit are independent from those of other units. An example of string of overlapping windowed compression units with matching watermarking bits is shown in Fig. 3. Note that in the Fig. 3 one watermarking bit corresponds to two compression units or frames. More specifically, in AAC a new frame is created every 1024 samples, and thus a new watermarking bit is created once per 2048 samples. Therefore, in the case of audio sampling rate of 44.1 kHz, the bit rate for forensic marking is 44100/2048 = 21.533 bits per second.

In MUX block in Fig. 1 selection of frames from tributaries is done according to the code created by the code generator. Transition from one tributary to another happens when there is a transition in the code from one symbol to another. This transition doesn't produce noticeable artifacts as long as the tributaries are perceptually similar, and window shapes of both tributaries are the same. However, if window shapes in the tributaries are not the same, it is possible to create an audible artifact, which can be avoided by adjustments described below.

The window shapes in AAC compression are illustrated in Fig. 4. Top portion of the figure contains sequence of so called long windows. Those windows provide good audio quality for slowly changing audio signal, such as tonal music. However, in the case of fast changing audio signal, such as percussions attack, the long window may cause undesirable effect of pre-echo. In this case better audio quality is achieved by so called short windows shown in the middle of the bottom part in Fig. 4. Therefore, AAC compressor automatically detects audio attacks and changes window shape from long to short as needed. Note that one compression frame carries data from one long window, or eight short windows. In order to smooth the transition from long to short windows and back, and avoid audible artifacts, AAC introduces two additional windows: long-start, shown in Fig. 4 prior to the short window, and long-stop shown in Fig. 4 after the short window.

Typically different tributaries are perceptually similar, and AAC detector would detect audio attacks and switch to short window in the same place (frame) in each of them. However, occasionally AAC compressor may make different window choices for different tributaries, and transition between them may create audible artifacts. For example, transition from a tributary frame with a long-stop window to another tributary with the frame containing long-stop window will create a silence gap in the output audio stream. Therefore MUX block has to read information about window shapes in tributaries whenever a switch between them is scheduled based on the code. If MUX block detects the window mismatch between tributaries that may cause audio artifact, the "switch abandon" is needed.

The switch abandon will effectively insert a bit error in the embedded bit stream, or an inversion of the bit value generated in the code generator. We have found in our experiments that such bit errors are fairly rare, and can be effectively mitigated by error correction codes. Alternatively, bit error locations due to switch abandon actions can be saved in the database in order to use this information in forensic processing of extracted codes. Switch abandon described above should be used whenever the switch from one tributary to another may cause perceptual artifacts due to the mismatch of perceptual compression parameters between tributaries. Besides the mismatch between short and long windows, AAC compression may have a mismatch where one tributary is using Kaiser-Bessel Derived window, while the other uses Sine window.

Our experiments have shown that the number of switch abandon instances depend strongly on type of perceptual compressor and parameter selection used in a particular application. Some perceptual compressors do not use Kaiser-Bessel Derived window at all, and thus the mismatch with Sine window is avoided altogether. Therefore, if selection of perceptual compressor is not fixed in advance, it is desirable to test multiple candidates to find one that produce minimum density of switch abandon events.

In the case of multichannel audio it is possible to encounter situation where on one of the channels we have switch abandon condition, while on the other(s) we don't. This is undesirable situation, since it will lead to different symbol embedded in different channels, which may cause audio artifacts. Further, if channel mixdown is executed by an attacker, different symbols embedded in different channel will interfere with each other. Therefore, in preferred implementation we have switch abandon enforced on all channels as long as one of them requires it. However, many perceptual compressors have the option where the same set of compression parameters, such as window shapes, is used for all channels. By selecting this option we can reduce the density of switch abandon events.

## V. DIFFERENTIAL ANALYSIS OBSTRUCTION

In the case of forensic marking attacker may obtain two or more copies of the same content marked by distinct forensic marks. By subtracting one copy from the other, attacker may find places where different forensic symbols are embedded, and obtain the difference between embedded symbols. By analyzing the difference between copies, attacker may be able to reverse engineer the watermarking technology and find the secret key (a.k.a. stego key) used in embedding. With this information attacker may be able to devise attacks that would remove or jam embedded watermarks, or even forge them. Therefore it is important to prevent attacker from obtaining clear information about watermarking technology from the difference between distinct copies. Here we will disclose two general methods which can be used separately or in combination to obstruct the differential analysis.

The first method is used in the preprocessing stage in each of embedders. The objective is to use one or more distortions that are different in each tributary but still perceptually insignificant. Than the attacker will face the challenge to distinguish which feature of the difference signal carries information relevant for the watermarking technology, and which does not.

For example we have found that nonlinear amplitude modification done differently in each embedder makes insignificant impact on marked copy quality, but makes differential analysis very hard. An example of nonlinear amplitude modification is shown in Fig. 5 in the form of input -output sample characteristic deviating from straight line. This characteristic should be different for each embedder, but it is also desirable to make it change slowly and randomly with time, so that it is difficult for attacker to undo the modification. Similarly, random phase offsets can be applied independently for each tributary in order to make difference between them large and to obstruct the insight into watermarking technology. Note that the technique where each copy (not tributary) has independent phase offsets produces annoying artifacts when attacker attempts averaging or splicing attack, while using random phase offsets on tributaries obstructs the differential analysis.

### Output sample

Furthermore, embedders may use two or more distinct watermarking technologies to embed the same symbol in the same compression unit. This way attacker faces dilemma about which feature of the difference signal belongs to which technology, which makes reverse engineering hard.

Another method of differential analysis obstruction can be implemented at the marking stage, after the multiplexing. The objective is to increase difference between distinct copies of marked content by manipulating parameters of compressed domain stream differently for each copy. For example, in AAC compressor we found that we can do small, random, amplitude modification by using AAC Fill elements, without noticeable audio artifacts. This process doesn't require decompression, and thus it doesn't require a lot of processing. On the other hand, it effectively masks watermark features in difference signal, and it is hard to reverse because of random nature of the modification.

In particular we recommend changing the Dynamic Range Control (DRC) part in the Fill element of the compressed AAC bitstream. By changing and/or inserting a few bits into the DRC part of the compressed AAC bitstream, we change the final value of the decoded sound signal. If the original AAC compressed bitstream has DRC signaling bit = 0 (no DRC bits present), we need to add 39 bits per frame, which is a fraction of one percent of total number of bits in a frame. Otherwise, we only to change the value of bits in the original DRC part of the bitstream. The total number of bits in the bitstream may or may not be increased.

## VI. CONCLUSION

It has been shown in this paper that transaction watermarking is important for copyright protection since it enables tracing of channels for illegal distribution of copyrighted materials. Important difference from other watermarking techniques is found in security domain and processing requirements domain. Security requirements are higher than for other watermarking techniques because of the possibility of collusion attack, while processing requirements emphasize simplicity and efficiency of watermark embedding in compressed domain.

The technique proposed here achieves security enhancement by deploying differential analysis obfuscation during embedding process. Random signal modifications that are imperceptible to users mask actual watermarks and prevent reverse engineering.

Simplicity and efficiency of watermark embedding in compressed domain is achieved by deploying two-step process. In the first step, prior to the perceptual compression, multiple copies of the content are created, each of them having a single symbol embedded. In the second step, after the perceptual compression, a multiplexer performs selection of compression units from tributaries according to code unique to each transaction. In order to avoid perceptual artifacts the multiplexer monitors the size of compression units and abandons switching if a mismatch is detected.

