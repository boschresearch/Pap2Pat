# DESCRIPTION

## TECHNICAL FIELD

- relate to machine learning models and neural networks

## BACKGROUND

- describe limitations of deep learning approaches

## DETAILED DESCRIPTION

- describe existing deep learning systems and methods
- describe limitations of existing systems and methods
- introduce NLP systems and methods using energy-based models
- describe NLP module
- describe EBM module
- describe NCE loss module
- describe data samples and noise samples
- describe encoding data samples and noise samples
- describe generating classification outputs
- describe computing energy terms
- describe computing NCE loss objective
- describe training NLP classifier
- describe alternative implementation of energy function
- describe scalar function
- describe hidden function
- describe sharp-hidden function
- describe computing energy term using scalar function
- describe computing energy term using hidden function
- describe computing energy term using sharp-hidden function
- describe NCE loss objective
- describe training NLP classifier using NCE loss objective
- describe alternative implementation of NCE loss objective
- describe joint training using NCE loss and CE loss
- describe CE loss module
- describe computing CE loss objective
- describe joint optimization using NCE loss and CE loss
- describe updating NLP classifier using joint loss objective
- describe awareness of Pθ(x) and Pθ(y|x)
- describe improvement in calibration
- describe outputting NCE loss objective to training module
- describe training NLP classifier using training module
- describe receiving training dataset
- describe generating noise samples
- describe inputting data samples and noise samples into NLP classifier
- describe encoding data samples and noise samples
- describe generating classification outputs
- describe computing energy terms
- describe computing NCE loss objective
- describe training NLP classifier
- describe alternative implementation of training NLP classifier

## EXAMPLES

- finetune GPT-2 language model
- adopt masked language model loss
- generate noise samples
- use top-k sampling
- show examples of generated noise samples
- describe alternative noise sampling method
- finetune Roberta-base model on GLUE tasks
- measure calibration error using ECE metric
- define ECE formula
- compare EBM training with baseline methods
- show test-set accuracy and ECE for different methods
- discuss performance of EBM variants
- show how test-set ECE changes during training
- analyze energy value and posterior distribution
- provide concrete examples of computing devices
- describe machine readable media
- discuss scope of invention
- provide disclaimer on embodiments

