# DESCRIPTION

## CROSS REFERENCE(S)

- claim priority

## TECHNICAL FIELD

- define technical field

## BACKGROUND

- motivate paraphrase generation

## DETAILED DESCRIPTION

- introduce dynamic blocking for paraphrase generation
- describe architecture of language model with encoder and decoder

### Overview

- illustrate architecture of language model for generating paraphrase
- describe encoder and decoder components
- explain dynamic blocking mechanism
- describe block dictionary and sampling process
- explain how decoder generates paraphrased sentence
- describe beam search for generating multiple candidates
- illustrate example of dynamic blocking in action
- explain benefits of dynamic blocking for paraphrase generation

### Computer Environment

- describe computing device for implementing dynamic blocking
- explain processor and memory components
- describe paraphrase generation module and sub-modules

### Work Flows

- illustrate logic flow diagram for generating paraphrase text
- provide pseudo-code algorithm for dynamic blocking

### Example Performance

- introduce BertBLEU metric
- motivate semantic similarity and surface form dissimilarity
- define BERT-score
- define self-BLEU
- describe Dynamic Blocking strategy
- introduce blocking surface-form variations and closed-class words
- describe example training datasets
- describe experiment setup on QQP
- describe experiment setup on ParaNMT
- evaluate paraphrasing quality using existing metrics
- report human evaluation results on QQP and ParaNMT
- describe human evaluation methodology
- analyze correlation between automatic metrics and human evaluation
- present automatic evaluation results on QQP and ParaNMT
- discuss ablation studies on finetuning phases
- demonstrate generalization to other languages

