# DESCRIPTION

## BACKGROUND

- introduce machine learning

## SUMMARY

- introduce techniques for training
- describe method for generating synthetic utterances
- describe system for generating synthetic training examples
- describe method for obtaining task-adapted generative model

## DETAILED DESCRIPTION

### Machine Learning Overview

- introduce machine learning frameworks
- describe neural networks
- define parameters
- explain model structure
- introduce transfer learning
- describe pretraining
- describe tuning

### Machine Learning Models for Natural Language Processing

- introduce natural language understanding models
- introduce natural language generation models
- describe task-specific training examples
- describe limitations of existing techniques
- introduce generative models for task-specific training examples
- describe pretraining a generative model
- describe tuning a generative model
- describe example training stages
- describe pretraining stage 110
- describe pretraining stage 120
- describe tuning stage 130
- describe pretraining stage 110 in detail
- describe pretraining stage 120 in detail
- describe tuning stage 130 in detail
- describe example model inputs and outputs
- describe pretraining stage 110 inputs and outputs
- describe pretraining stage 120 inputs and outputs
- describe tuning stage 130 inputs and outputs
- describe example generative model structure
- describe transformer decoders
- describe masked self-attention layers
- describe feed-forward neural network layers
- describe training algorithm details
- define dialog act
- describe natural language generation module
- describe semantically conditioned generative pre-training
- describe first pretraining stage
- describe GPT-2 architecture
- describe second pretraining stage
- describe dialog act pre-processing
- describe response pre-processing
- describe task-specific fine tuning
- describe characteristics of semantically-conditioned generative models
- describe flexibility
- describe controllability
- describe generalizability
- describe example training data
- describe example tuning data
- describe example model outputs
- describe example dialog acts
- describe example intents
- describe example slot-value pairs

### Data Augmentation

- motivate data augmentation
- describe natural language understanding model integration
- introduce task-oriented spoken dialog system
- describe pipeline architecture
- define training data representation
- describe limitations of training data
- introduce data augmentation module
- describe generative model training
- define dialog act
- describe data augmentation scenarios
- introduce paired-data scenario
- introduce rich-in-ontology scenario
- introduce rich-in-utterance scenario
- describe example data augmentation processing flow
- describe semantic conditioning
- describe task tuning
- describe synthetic corpus generation
- describe filtering
- describe example data augmentation for paired-data or rich-in-ontology scenarios
- describe example data augmentation for rich-in-utterance scenarios
- describe intent and slot value prediction
- describe synthetic label generation
- describe corpus generation

### Example System

- introduce example system
- describe client device
- describe server
- describe network
- describe processing resources
- describe storage resources
- describe configuration module
- describe generative training module
- describe data augmentation module
- describe NLU training module
- describe NLU model
- describe architecture parameters
- describe training parameters
- describe model training
- describe trained NLU model output
- describe NLU execution module
- describe application module
- describe interface module
- describe input data processing
- describe output processing
- describe dialog tracking
- describe user interaction
- describe system implementation
- describe device implementation
- describe data center implementation

### Device Implementations

- define device
- describe processing capability
- explain storage resources
- introduce computer-readable media
- distinguish computer-readable storage media
- describe general-purpose hardware processor
- explain system on a chip design
- introduce hardware logic components
- describe software implementation
- explain firmware implementation
- describe input mechanisms
- describe output mechanisms
- explain stand-alone and cooperative functionality
- introduce network communication
- motivate task-adapted generative model
- describe method for obtaining synthetic training corpus
- explain synthetic training examples
- describe training natural language understanding model
- introduce system for generating synthetic training corpus
- describe sampling predicted next tokens
- explain filtering synthetic training examples

## CONCLUSION

- clarify claim scope

