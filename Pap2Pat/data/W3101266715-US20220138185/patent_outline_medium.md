# DESCRIPTION

## BACKGROUND

- motivate natural language processing

## SUMMARY

- introduce conditional graph modification
- application of neural networks
- summarize embodiments

## DETAILED DESCRIPTION

- introduce natural language processing (NLP) systems and methods
- motivate conditional graph modification
- describe limitations of conventional NLP devices
- introduce neural network model for graph modification
- describe application of graph modification to image search
- illustrate process for providing search results
- describe user interaction with computer
- generate structured representation of search query
- describe neural network model for encoding structured representation and modification query
- combine structured representation features and natural language expression features
- describe graph generator for generating structured representation
- provide search results based on structured representation
- describe user modification of search query
- modify graph based on modification query
- provide updated search results based on modified graph
- describe system for natural language processing
- introduce user device, server, cloud, and database components
- describe server components, including processor unit, memory unit, input component, neural network, graph generator, and search component
- describe artificial neural network (ANN) and recurrent neural network (RNN)
- describe input component for receiving structured representation and modification expression
- describe neural network for generating modified structured representation
- describe graph generator and search component for generating structured representation and performing search
- define neural network architecture
- describe graph encoder
- describe text encoder
- describe feature fusion network
- describe edge decoder
- describe node decoder
- describe graph-conditioned sparse transformer
- describe structured representation features
- describe natural language expression features
- describe combined features
- describe gating mechanism
- describe early fusion technique
- describe target graph generation
- describe gating mechanism
- introduce early fusion via cross-attention
- share parameters of graph and query encoders
- describe feature fusion network
- describe transformer encoder
- describe node-level RNN decoder
- describe edge decoder
- describe adjacency matrix style edge decoder
- describe flat edge-level decoder
- describe scene graph
- describe graph generator
- describe label attention model
- describe object ontologies
- describe grounding ontology
- describe insertion process
- describe deletion process
- describe object substitution process
- describe attribute substitution process
- describe natural language processing
- describe process for modifying structured representation
- describe process overview
- introduce graph encoder
- describe graph encoder operations
- introduce text encoder
- describe text encoder operations
- introduce feature fusion network
- describe feature fusion network operations
- introduce node decoder
- describe node decoder operations
- introduce edge decoder
- describe edge decoder operations
- describe training process
- formulate conditional generation task
- describe training data
- describe model architecture
- describe training procedure
- describe model evaluation
- describe model optimization

### Evaluation

- create benchmark datasets
- captioning datasets
- construct scene graphs
- generate modified scene graphs
- leverage human annotators
- add annotations on top of captions
- create 200 k scene graphs from MSCOCO
- create 420 k scene graphs from GCC data
- compare MSCOCO and GCC graphs
- achieve up to 8.5% increase in performance
- define F1 score
- use crowd-sourcing applications
- obtain diverse modification queries
- refer to template-based datasets as “synthetic”
- refer to user-generated contents as “user-generated”
- face challenges during data collection
- manually filter the data
- perform user study with 15 testers
- record score distribution
- analyze graph size distributions
- augment user-generated data with synthetic data
- up-sample user-generated data
- compare data augmentation with transfer learning
- record graph accuracy results
- consider five baselines for comparison
- evaluate multiple operations scenario

