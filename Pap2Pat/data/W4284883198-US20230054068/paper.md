# Introduction

Abstractive summarization aims to generate a compact and fluent summary that preserves the most salient content of the source document. Recent advances in pre-trained language models (Devlin et al., 2018;Liu and Lapata, 2019;Lewis et al., 2020) have led to improvements in the quality of generated summaries.

However, one prominent limitation of existing abstractive summarization systems is the lack of faithfulness of generated outputs. Faithful summaries should only contain content that can be derived from the source document instead of hallucinated or fabricated statements. Summary hallucination could be categorized by the information source as intrinsic and extrinsic hallucinations. Cao et al. (2018); Kryściński et al. (2019) showed that about 30% of the summaries generated by seq2seq models suffer from the hallucination phenomenon at Source: When the experiments are eventually run, the results will be streamed live on YouTube. Alongside Prof Hawking, the judging panel consists of [...] Summary: Stephen Hawking joined the judging panel of a science competition on the internet education site Gumtree. Table 1: An example of model generated unfaithful summary due to entity hallucination from XSum dataset.

either the entity level or the summary level. Table 1 shows an example of a model generated summary with hallucinated entities. The BBC article discusses a teenage science competition streamed on the Youtube website, while a BART-based summarizer makes up the term 'Gumtree' instead. Such hallucinations may cause factual errors and hinder the practical use of summarization models.

Faithfulness and factuality in abstractive summarization has received growing attention from the NLP community (Kryscinski et al., 2020;Goyal and Durrett, 2021;Zhu et al., 2021;Narayan et al., 2021). Recent works have attempted to address the hallucination problem at the entity level by reducing hallucinated entities during generation. Chen et al. (2021) proposed a post-processing method, which replaces the hallucinated entities in the generated outputs with the same type entities in the source document. However, it introduces additional errors to the summary and increases the intrinsic hallucination. Nan et al. (2021) proposed to address entity hallucination by filtering the training data and multi-task learning with summary-worthy named-entities classification. However, the method sacrifices part of the training data and decreases the quality of the summary.

To address the above issues, we propose to solve entity hallucination by guiding the model learning process with entity control code (ECC) (Keskar et al., 2019;He et al., 2020;Fan et al., 2017). We utilize the entity coverage precision between the training document and its reference summary as faithfulness guidance and prepend it to the corre- sponding document in the training phase. Then, we prepend faithful control code during inference and reduce hallucinated entities effectively without decreasing the fluency and salience of generated summaries according to our experimental results. In addition, we extend control code to a Wikipediabased intermediate fine-tuning model, which generates faithful and salient summaries across domains in the zero-shot setting. We validate our methods on three benchmark datasets across different domains, and experimental results demonstrate the effectiveness of our methods.

# Methods

## Problem Formulation

Let D = {(d 1 , s 1 ), (d 2 , s 2 ), ..., (d n , s n )} denote a dataset composed of n document and summary pairs. During inference phase, a seq2seq model generates summary hypothesis h i for a given document d i by computing the probability p θ (h i |d i ). The generated summary h i is expected to be faithful, which means all the information in h i should be entailed by the source document d i .

Following (Nan et al., 2021), we quantify entitylevel hallucination with entity coverage precision prec en . It approximates the faithfulness by measuring the ratio of the named entities in the summary that are coming from the source document. Formally, it is defined as:

where N (t) represents the set of all named entities found in a given input text t.

## Entity Coverage Control

Figure 1 shows our entity coverage control method. We generate a control code C i for each training document and reference summary pair (d i , s i ) so the seq2seq model generates a summary conditioned on both the source document d i and its control code

We first compute entity coverage precision prec en for each document and reference summary pair (d i , s i ) in the training set D. Then, we quantize prec en into k discrete bins, each representing a range of entity faithfulness. These bin boundaries are selected to ensure that each bin contains roughly the same number of training examples to avoid data imbalance. We then represent each bin by a special token control code C i and add all these special tokens {C 1 , C 2 , ..., C k } to the input vocabulary of our seq2seq model.

During training, we prepend the corresponding pseudo label C i to the input document as control code. The seq2seq model is now conditioned on both the source document d i and its control code C i , so it could learn different faithful level generation patterns from the control codes. Then during inference, we prepend the high faithfulness control code C k to all documents in the test set and generate faithful summaries by p θ (h i |d i , C k ).

## Controllable Intermediate Fine-tuning

Large pre-trained language models (Devlin et al., 2018;Lewis et al., 2019) perform poorly in the zero-shot summarization setting since sentence salience information is not learned through pretraining tasks (Zhang et al., 2020b). Thus, we propose a controllable generalized intermediate finetuning for zero-shot summarization.

We first generate pseudo document summary pairs from Wikipedia article dump with similar summary length (n), document length (m) and abstractiveness (a) to the target datasets following Wikitransfer (Fabbri et al., 2021). Instead of training different models for different target datasets as in WikiTransfer, we propose a unified model that generalizes well across different domains. Assume we have l target-specific pseudo training subsets {D 1 (n 1 , m 1 , a 1 ), ..., D l (n l , m l , a l )}, we give each subset another special token E i as a pseudo label to represent the target-specific pattern and also add all these special tokens {E 1 , E 2 , ..., E l } to the input vocabulary of the seq2seq model. In the training phase, we prepend the corresponding target code E i to the document, and a summary is generated conditioned on both the source document d i and its target control code E i , which is represented as p θ (h i |d i , E i ). This allows for control over the domain and generation style of generated summaries by prepending different domain control codes during inference. The control codes are also stackable, so we can stack the target control with entity coverage control for faithful zeroshot summarization, which could be denoted as

3 Experiments  (Gliwa et al., 2019). We use Entity Precision (Nan et al., 2021) and FEQA (Durmus et al., 2020) to evaluate summary faithfulness and use ROUGE (Lin, 2004) to evaluate the fluency and salience.

We also ask expert annotators to perform a human evaluation in both summary faithfulness and quality. We use BART-large as backbone model and set hyperparameter k = 3 for all experiments. The three discrete ECC bins are represented with control codes: <FF-low>, <FF-mid> and <FF-high> respectively. More implementation details are described in Appendix A.

Baselines: We compare our methods with two state-of-the-art methods in summarization faithfulness: (1)Post-processing correction in (Chen et   2021) together with original BART. For zero-shot summarization, we compare with state-of-the-art method WikiTransfer (Fabbri et al., 2021).

## Automatic Evaluation

Table 2 shows the performance of ECC in the supervised setting. Compared to the summaries generated by BART, our method increases the entity coverage precision significantly with roughly the same summary quality. Table 3 shows the performance comparison to strong baselines on the XSum dataset. Our methods achieves comparable faithfulness improvements without degrading the summary quality compared to data filtering and post-processing methods. We notice there is a trade-off between entity coverage precision and summary quality in Xsum dataset, which is likely due to the low faithfulness level of the reference summaries of Xsum (Maynez et al., 2020).

Table 4 shows the zero-shot summarization results. We notice BART tends to copy from the source document, so it achieves high entity coverage precision (92.61) but low summary quality. In contrast, with our intermediate fine-tuning, BART learns the characteristic of the downstream dataset and achieves a considerable improvement in ROUGE score. Compared to the baseline Wikitransfer, we see improvements in both the entity coverage precision and summary quality. Our model is also generalized cross datasets, so we use   one model for different downstream targets instead of training separate models like Wikitransfer.

## Human Evaluation

Table 5 shows the human evaluation results on the 50 randomly sampled subset of articles from the XSum dataset following the setting of (Chen et al., 2021). Four expert annotators assign each summary output into three faithfulness categories (faithful summary, intrinsic hallucination, extrinsic hallucination) and three summary quality categories (low(1), medium (2), high(3)). Note that a summary may contain both intrinsic and extrinsic hallucinations. As the results show, our ECC model improves the faithfulness of the summaries without degrading summary quality, which agrees with our automatic evaluation results.  

# Analysis and Discussion

Does our model generate fewer entities to be safe? One obvious way to get higher entity coverage precision is to avoid generating entities or generating extra non-sense named entities from the source document. We show the distribution of the number of entities in the generated summaries by our model and BART in Fig 2 . We see that the two distributions are very similar and have almost the same mean number of entities. As a result, we argue that our method doesn't under-generate nor over-generate entities from the source document, and we don't need to separately control the entity compression rate.

How does control code affect inference phase?

We also study the effect of decoding with different control codes. We prepend different entity coverage control codes during inference on the XSum test set. As shown in Table 6, our model still generates reasonable summaries when inferred with low and medium control codes. We notice that summaries inferred with low control codes have higher ROUGE scores, which agrees with the trade-off described earlier.

# Why does BART generate hallucinated tokens?

As shown in Table 7, fine-tuned BART generates 'Gary Anderson' according to the context 'Saints captain Anderson' , which is erroneous since the actual captain is 'Steven Anderson'. Language models contain abundant relational knowledge from pre-training data and could be extracted by masked text filling (Petroni et al., 2019). Similarly, we insert a mask token before 'Anderson' and probe untuned BART to fill the masked tokens. BART generates 'Paul Anderson' (actor) when only given the first sentence context. When given the whole news article, BART learns the context is sports-related and generates famous athletes 'Craig Anderson' (hockey athlete) and 'Gary Anderson' (football athlete) according to its pre-trained prior knowledge. The ground truth 'Steven Anderson' appears much less frequent during pre-training, so BART has a low probability of generating it correctly. We observe the same for ground truth 'Rob Kiernan', which probably appears less frequently in BART's pre-training corpus.

# Related Work

The faithfulness and factuality in abstractive summarization has received growing attention by the summarization community recently (Kryscinski et al., 2020;Cao et al., 2018;Goyal and Durrett, 2021). Maynez et al. (2020) categorized hallucinations by the information source as intrinsic and extrinsic hallucinations. Researchers have turned to textual entailment (Maynez et al., 2020), question answering (QA) (Durmus et al., 2020;Wang et al., 2020), Natural Language Inference (NLI) (Kryscinski et al., 2020) and entity level precision (Nan et al., 2021) for automatic faithfulness evaluation. To improve the faithfulness of generated summaries. Cao et al. (2018) proposes a fact-aware summarization model with open information extraction and dependency parse technologies. (Zhu et al., 2021) uses graph attention to integrate factual relations into the summary generation process. Recent works also focus on addressing entity-level hallucination problems. Chen et al. (2021) proposes a post-processing method to correct hallucinated entities and (Nan et al., 2021) addresses entity hallucination by filtering the training data and multi-task learning. One concurrent work Narayan et al. (2021) incorporates entity chain content planning to guide faithful summary generation.

The transformer-based seq2seq architecture (Vaswani et al., 2017) currently dominates the stateof-the-art performance in many NLP tasks (Liu and Lapata, 2019;Zhang et al., 2020a;Zhang and Zhang, 2020). We use BART (Lewis et al., 2020) as a backbone for abstractive summarization in this work, but our method is generally appliable for all seq2seq models.

Our work is also related to controllable abstractive summarization. Liu et al. (2018) controls the summary length by extending a convolutional sequence to sequence model. He et al. (2020) introduces a keyword guided framework for entity-centric, length-controllable summarization and question-guided summarization. Fan et al. (2017) proposes to control the summary generation with a list of desired named entities. Recently, Feng et al. (2021) proposes to use language models to generate pseudo labels to control the generation of dialogue summarization. Our work uses control code to improve summary generation faithfulness and cross-domain generalizability.

# Conclusion

In this paper, we propose ECC to address extrinsic hallucination in abstractive summarization in both supervised and zero-shot settings. Our extensive experiments demonstrate that the proposed method effectively reduces entity hallucination without hurting the quality of the generated summaries.

# Acknowledgement

Work done during internship at Salesforce Research. Thanks to Man Luo, Xi Ye, and everyone at Salesforce Research for helpful discussions, as well as to the anonymous reviewers for their helpful feedback.

# A Implementation Details

We use Huggingface libraries (Wolf et al., 2020) for all our experiment implementations. Our backbone abstractive summarization model is BARTlarge (Lewis et al., 2020), a pre-trained denoising autoencoder language model with 336M parameters based on the sequence-to-sequence transformer (Vaswani et al., 2017). For fair comparison, we finetune BART-large on each dataset for on 8 Tesla A100 GPU pods with same learning rate 5e -5 with weight decay using Adam optimizer (Kingma and Ba, 2014). We set hyperparameter k = 3 for all experiments. Larger number of k doesn't increase the performance significantly. The three discrete ECC bins are represented with control codes: <FF-low>, <FF-mid> and <FF-high> respectively. The entity coverage precision boundaries are 0.36 and 0.5 for Pubmed, 0.33 and 0.66 for SAMsum and Xsum.

For entity recognition, we use a neural Named Entity Recognition (NER) system from the Stanza NLP toolkit (Qi et al., 2020) trained on the OntoNotes corpus (Weischedel et al., 2011) except for Pubmed dataset. Since Pubmed is a medical scientific article collection, we use biomedical, scientific, and clinical text Named Entity Recognition toolkit scispaCy (Neumann et al., 2019) instead.

# B Representative Examples Analysis

In Table 8, we provide several representative examples from XSum dataset. Example 1 (first row) shows how our entity control method gets rid of hallucination terms from BART output. The reference summary here is not faithful since 'Los Angeles' is not covered in the source document. The correction baseline changes 'Los Angeles' to 'Mexico', which is a factual error. In contrast, the ECCoutput is totally faithful to the source document and contains salient information.

Example 2 (second row) shows the outputs decoded with different control codes during inference. We can see the output decoded with low faithfulness control code is still fluent and reasonable, but contains less faithful entities compared to the output decoded with high faithfulness control code.

Example 3 (third row) shows an example of factual statement, which is verifiable in the real world independent of the source text. The reference summary uses 'most of Wales' to summarize the county names in the source document. This type of hallucination needs more external knowledge and com-534 BART: A video game based on one of the world's most popular wrestling traditions has been launched at the E3 gaming show in Los Angeles.' Correction: A video game based on one of the world's most popular wrestling traditions has been launched at the E3 gaming show in Mexico. ECC: A video game dedicated to Mexican wrestling has been released at E3. Reference: One of the more unusual titles at E3, the worlds largest video games exhibition held each year in Los Angeles, is Konami's Lucha Libre AAA: Heroes del Ring. BART: Tourists in Spain have been accused of harassing a dolphin after it became stranded on a beach. Low Code: A dolphin that became stranded in the sea off the coast of Spain has been harassed by a group of tourists. High Code: A dolphin that became stranded in the sea off the coast of Andalucia has been harassed by tourists. Reference: A baby dolphin has died after it was surrounded by tourists looking to take photographs on a beach in southern Spain. Document: The warning begins at 22:00 GMT on Saturday and ends at 10:00 on Sunday. The ice could lead to difficult driving conditions on untreated roads and slippery conditions on pavements, the weather service warned. Only the southernmost counties and parts of the most westerly counties are expected to escape. Counties expected to be affected are Carmarthenshire, Powys, Ceredigion, Pembrokeshire, Denbighshire, Gwynedd, Wrexham, Conwy, Flintshire, Anglesey, ..., Rhondda Cynon Taff and Torfaen. Reference:The Met Office has issued a yellow weather warning for ice across most of Wales.  monsense reasoning to decide its factuality. Our method only focuses on entity level hallucination problems instead.

# C Human Evaluation Confidence

Our human evaluation follows the setting of prior work (Chen et al., 2021). We calculate the interannotator agreement with additional annotations from two other experts. We estimate the adjusted mean and 95% confidence interval from the mean and standard deviation. The full results are shown in Table 9.

