# DESCRIPTION

## TECHNICAL FIELD

- relate to sparse training

## BACKGROUND

- introduce sparse training

## DETAILED DESCRIPTION

- introduce SpFDE framework
- describe benefits of SpFDE framework
- explain FLOPs reduction
- define terms used in the disclosure
- describe sparse training
- categorize sparse training approaches
- discuss limitations of conventional sparse training
- introduce Dynamic Sparse Training (DST)
- describe SpFDE framework architecture
- explain initial stage of SpFDE framework
- describe active training stage of SpFDE framework
- introduce data sieving method
- explain progressive layer freezing stage of SpFDE framework
- describe layer freezing algorithm
- discuss design principles for layer freezing
- describe circular data sieving method

### Experimental Results

- evaluate SpFDE framework on benchmark datasets
- introduce CIFAR-100 and ImageNet datasets
- describe ResNet-32 and ResNet-50 models
- outline PyTorch and Torch frameworks
- specify data augmentation and SGD optimizer
- detail layer-wise cosine annealing learning rate schedule
- choose MEST+EM&S as training algorithm
- apply uniform unstructured sparsity across convolutional layers
- show accuracy and computation FLOPs results on CIFAR-100 dataset
- compare SpFDE framework with existing sparse training methods
- highlight advantages of SpFDE framework
- provide comparison results on ImageNet dataset
- show superior memory saving of SpFDE framework
- illustrate sample configuration of a computer system
- describe machine 800 and its components
- outline software and hardware configurations
- detail machine readable medium and instructions
- describe communication networks and protocols
- discuss applications and embodiments of the technology

