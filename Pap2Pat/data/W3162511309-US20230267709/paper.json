{
    "id": "https://semopenalex.org/work/W3162511309",
    "authors": [
        "Lin Chen",
        "Jiebo Luo",
        "Gaoang Wang",
        "Mingwei He",
        "Tianqiang Liu"
    ],
    "title": "DAIL: Dataset-Aware and Invariant Learning for Face Recognition",
    "date": "2021-01-10",
    "abstract": "To achieve good performance in face recognition, a large scale training dataset is usually required. A simple yet effective way to improve the recognition performance is to use a dataset as large as possible by combining multiple datasets in the training. However, it is problematic and troublesome to naively combine different datasets due to two major issues. First, the same person can possibly appear in different datasets, leading to an identity overlapping issue between different datasets. Naively treating the same person as different classes in different datasets during training will affect back-propagation and generate nonrepresentative embeddings. On the other hand, manually cleaning labels may take formidable human efforts, especially when there are millions of images and thousands of identities. Second, different datasets are collected in different situations and thus will lead to different domain distributions. Naively combining datasets will make it difficult to learn domain invariant embeddings across different datasets. In this paper, we propose DAIL: Dataset-Aware and Invariant Learning to resolve the above-mentioned issues. To solve the first issue of identity overlapping, we propose a dataset-aware loss for multi-dataset training by reducing the penalty when the same person appears in multiple datasets. This can be readily achieved with a modified softmax loss with a dataset-aware term. To solve the second issue, domain adaptation with gradient reversal layers is employed for dataset invariant learning. The proposed approach not only achieves the state-of-the-art results on several commonly used face recognition validation sets, including LFW, CFP-FP, and AgeDB-30, but also shows great benefit for practical use.",
    "sections": [
        {
            "title": "I. INTRODUCTION",
            "paragraphs": [
                "Face recognition has received much attention in recent years and has been widely used in many industrial fields, such as security, surveillance and mobile applications. Many deep learning based state-of-the-art methods [1]- [7] are introduced and more and more accurate models have been achieved.",
                "Many existing state-of-the-art (SOTA) methods explore different loss functions to achieve good performance in face recognition. Most of the loss functions aim at learning face embeddings that maximize the inter-class distance and minimize the intra-class distance. Typically, two types of losses are commonly used. One is softmax-based classification loss with several variations, such as SphereFace [4], [8], CosFace [5], [9], and ArcFace [1]. The other is the contrastive loss, including triplet loss [10], center loss [6], range loss [11] and margin loss [12].",
                "Embedding network architecture is another important factor in face recognition. Some commonly used feature extractors include VGG [13], ResNet [14]. Some modifications like squeeze-and-excitation (SE) [15] module, group convolutions [16], can be also applied to the existing backbones. Generally speaking, for the same type of architectures, larger models tend to have better performance. There are also some light-weighted backbones, like MobileNet [17]- [19], EfficientNet [20], which enable the face recognition to run on mobile devices and cameras. This type of carefully designed architectures only has a marginal impact on the accuracy drop but saves a lot of computational cost.",
                "Training data is also very critical for learning a good model. A few years ago, DeepID [21] includes only a few hundreds of thousands of images in the training. Recently, more and more large scale datasets have been created, such as VGGFace2 [22], MS1M [23], MegaFace [24], CASIA [25]. FaceNet [10] even takes over 200 million images in the training. With the help of these large scale datasets, significant progress has been made for face recognition in recent years.",
                "A simple and straight forward idea to achieve a further improvement is to combine all the available face recognition datasets in the training. However, this idea is rarely explored or mentioned in the literature. The main challenge of dataset fusion is the label cleaning issue. As we know, some existing datasets contain a lot of public celebrity images. ID overlapping across different datasets is a very common issue in face recognition, i.e., several datasets may contain the same person or face images. Take CASIA [25] and VGGFace2 [22] for example. There are a lot of the overlapping identities, as shown in Fig. 1. In the training, if we naively set distinct class IDs for images from different datasets even if they are actually from the same person, the incorrect labels will harm the classification for multi-dataset training. This issue is illustrated in Fig. 2 for better understanding. To overcome such issues, label cleaning is one approach that carefully checks the face ID and images across different datasets, but this may take a lot of computational cost and human effort. Whenever a new face recognition dataset is being created, there would be a huge trouble and effort to check whether certain face images have been already included in the existing datasets, in order to avoid the ID overlapping issue across datasets.",
                "To address the challenge of combing multiple datasets training in face recognition, we propose a novel approach with a designed dataset-aware loss, aiming at large scale multidataset training without any prerequisites for label cleaning. To be specific, the dataset-aware loss is built upon the commonly used softmax loss with a binary dataset indicator. Whenever a training sample comes, the softmax is calculated within the dataset it belongs to with no influence from other datasets. As a result, the ID overlapping issue is largely alleviated. Meanwhile, to further ensure the face embeddings are not dataset dependent, dataset invariant learning with gradient reversal layers (GRL) [26] is adopted for multi-dataset domain adaptation. The entire training framework is illustrated in Fig. 3.",
                "We summarize the contributions as follows: "
            ],
            "subsections": [
                {
                    "title": "II. RELATED WORK A. Loss Function",
                    "paragraphs": [
                        "Classification Loss. Classification-based losses, including softmax loss and its variations, are widely used in face recognition [1], [4], [5], [8], [9], [27]- [29]. In recent years, angular margin based softmax loss shows great power in face recognition, as discussed in [1], [4], [5], [8], [9]. For example, SphereFace [4], [8] introduces an angular margin to the softmax; CosFace [5], [9] proposes a large margin cosine loss where an extra margin is applied in cosine space rather than the angle space, and ArcFace [1] employs an additive angular margin to the softmax. With such margin modifications, the feature embeddings are more discriminative across different IDs.",
                        "Rather than using angular based margin softmax, other variations are also explored in [27]- [29]. In [27], noisy softmax is proposed to mitigate the early saturation issue by injecting annealed noise in softmax. Gaussian mixture loss is introduced with the assumption that the deep features follow the Gaussian mixture distribution in [28]. Moreover, [29] proposes a centralized coordinate learning approach with angular margin enhancement.",
                        "Contrastive Loss. Contrastive loss is commonly used in the distance metric learning field and is also well explored in face recognition. This type of loss aims at learning face embeddings that maximize the inter-class distance while minimize the intra-class distance within the batch samples. Examples include [6], [10]- [12]. FaceNet [10] first introduces triplet loss that encourages the distance learning from an anchor sample to the positive and negative samples in a triplet manner. Then center loss is proposed in [6] to penalize the discrepancy between the deep features and their corresponding class centers. Besides that, range loss [11] is designed to reduce overall intra-personal variations while enlarging interpersonal differences simultaneously. Similarly, the marginal loss [12] simultaneously minimizes the intra-class variances and maximizes the inter-class distances by focusing on the marginal samples. Since the focus of classification loss and contrastive loss has a small difference, combining these two types of losses is also commonly used in the training, such as [6], [12]. Despite their benefit for generating discriminative features, none of these proposed losses can address the mislabeling issues for multi-dataset training."
                    ],
                    "subsections": []
                },
                {
                    "title": "B. Handling Noisy Data",
                    "paragraphs": [
                        "Label Cleaning. The noisy label is a common issue in face recognition. Several approaches are proposed for label cleaning [30]- [33], aiming at generating a clean dataset from noisy annotated labels. For example, a comprehensive study of noisy data is summarized and data cleaning approaches are investigated in [33]. A graph-based cleaning method that employs the community detection algorithm and deep CNN models to delete mislabeled images is proposed in [30]. Besides that, identifying and removing the wrong labeled face images is formulated as a quadratic programming problem in [31]. Furthermore, with a simpler strategy [32], pre-trained face recognition models are applied directly for label cleaning. However, such automatic or semi-automatic approaches usually have very high computational cost. How to efficiently remove overlapping labels from different datasets are seldom touched.",
                        "Noise-Resistant Learning. Rather than cleaning the dataset, there are also many noise-resistant approaches [34]- [37] that can alleviate the effect from noisy data in the training. For example, [34] designs a light CNN for face representation with noisy labels. Besides that, a data filtering method is proposed in [35] to automatically filter out the data with incorrect labels in the training stage. Furthermore, as presented in [36], [37], sample weighting strategies are well explored and empirically proved to be also effective ways for handling noisy labels. These noise-resistant online learning approache do not require any cleaning step in advance, and thus can save much computational cost. However, the error can be easily propagated in the long time training with pseudo corrected labels and the ID overlapping issue is still not well addressed for multi-dataset training."
                    ],
                    "subsections": []
                },
                {
                    "title": "C. Domain Adaptation",
                    "paragraphs": [
                        "Domain adaptation [38]- [49] also plays a very important role in face recognition to deal with the domain drift issue between training datasets and testing datasets. Transfer learning is one of the most straightforward approaches for domain adaptation [40], [47], [48]. For example, fine-tuning approaches are explored in [40]. Template adaptation is used in [47] for face verification and identification. Transfer learning with triplet loss [48] is employed for bridging the gap between different domains. However, transfer learning based approaches cannot be easily applied to unlabeled target domain images.",
                        "Domain specific architecture design also shows effectiveness in face recognition [41]. Specifically, in [41], a domain specific unit architecture is proposed for each domain, aiming at extracting different low-level features from different domains. However, such methods require several sub-networks for each domain and are not efficient for practical usage.",
                        "Besides that, directly transferring the face images from the source to the target domain is also one commonly used approach for domain adaptation [39], [42], [45], [46]. For example, an image generator is applied to transform the image from the source domain to the target domain in [39], [42]. Using a linear combination of sparse target domain neighbors in the image space to represent the source images is proposed in [45]. In [46], a generative approach with the help of a 3D face model is investigated for a single sample face recognition. Such generative approaches show great power in the domain adaptation field but usually require a large dataset for training.",
                        "Alternatively, domain adaptation can also be conducted in the latent feature space [38], [43], [44], [49]. For example, disentangled variational representation is proposed in [38] for cross-model matching. In [43], a simple SVM-like model is applied to transform the latent feature space for the adaptation. Maximum mean discrepancy based approaches are also proved to be effective in [44], [49]. Compared with the direct methods that generate target images directly, such latent space adaptation methods are more efficient and robust. However, combining multiple datasets in the training for the adaptation is rarely explored."
                    ],
                    "subsections": [
                        {
                            "title": "III. PROPOSED METHOD",
                            "paragraphs": [
                                "To achieve a better performance, combining different datasets in training is a straightforward strategy. As we know, ID overlapping across different datasets is a very common issue in face recognition. In the training, the same face ID from different datasets is treated as different labels. Such mislabeled examples will largely affect the recognition performance. Label cleaning is one approach to overcome such issues, but it requires a lot of human effort.",
                                "In the following subsections, we present the dataset-aware loss that can be utilized in the multi-dataset training without any label cleaning effort. The dataset-aware loss can be easily combined with existing state-of-the-art softmax based losses, like SphereFace [4], [8], CosFace [5], [9] and ArcFace [1]. Meanwhile, we also employ the domain adaptation approach with gradient reversal layers (GRL) to ensure that the learned embeddings are dataset invariant. The overall multi-dataset training approach is illustrated in Fig. 3."
                            ],
                            "subsections": []
                        }
                    ]
                },
                {
                    "title": "A. Dataset-Aware Softmax Loss",
                    "paragraphs": [
                        "Let us denote D = {D 1 , D 2 , ..., D K } as the training set which contains K different datasets D 1 , D 2 , ..., D K . We represent each training example as (x i , y i , k yi ), where x i is the embedding vector of the i-th training sample, y i is the face ID label and k yi presents a mapping from the face ID label y i to the dataset index k. The ID overlapping issue is described as two samples x i , x j with the same ID y i = y j but are from different datasets, i.e., k yi = k yj . We can naively set y i = y j since the IDs from different datasets should be different; however, such ambiguity of the mislabeling issue can do harm in the training.",
                        "One of the most widely used loss function in classification problems is softmax loss, which is defined as follows,",
                        "where {W, } \u00afare the softmax layer parameters and C is the number of classes. To overcome the mislabeling issue, we define the dataset indicator to represent whether samples are from the same dataset, i.e.,",
                        "With this, we define the dataset-aware softmax loss as follows,",
                        "In other words, the softmax loss is computed within each dataset separately. As a result, the mislabeling issue can be easily solved. An example is shown in Fig. 4.",
                        "Another advantage of the dataset-aware loss is that it can be combined with any variations of softmax based losses. Take ArcFace [1] for example. The dataset-aware ArcFace can be presented as follows,",
                        "log e s cos(\u03b8y i +m) e s cos(\u03b8y i +m) + C j=1,j =yi 1 kj =ky i e s cos \u03b8j , (4) where \u03b8, m and s represent the angle, margin penalty and scale, respectively. This example shows the compatibility of the dataset-aware loss with the most advanced loss functions."
                    ],
                    "subsections": []
                },
                {
                    "title": "B. Dataset-Invariant Learning by Domain Adaptation",
                    "paragraphs": [
                        "To further improve the robustness of face recognition performance across multiple domains, dataset invariant learning is crucial to ensure that the latent face embeddings are not dataset dependent. Domain adaptation with gradient reversal layers (GRL) [26] is adopted for learning the face embeddings.",
                        "We now give more details on the domain adaptation model with GRL. For the face recognition networks, we usually have two sub-networks, a feature embedding subnetwork x i = G f (I i ; W f ) and a classification sub-network \u0177i = G y (x i ; W y ), where I i is the input face image, x i is the embedded feature vector, W f and W y are the network parameters. An extra domain classifier sub-network, ki = G d (x i ; W d ), is added after the embedding network to classify which dataset the sample belongs to. We consider two loss functions as follows,",
                        "Here, J cls (\u2022) is the classification loss, which can be the proposed dataset-aware softmax loss and J d (\u2022) is the classification loss for the dataset classifier.",
                        "To learn the network parameters, we look for embeddings that minimize the classification loss as much as possible. In the meantime, a good embedding should be dataset invariant, i.e., the embedding can fool the dataset classifier so that the embedding does not correlate with the dataset. To ensure the above assumptions, the network parameters should be optimized as follows,",
                        "where \u03bb controls the trade-off between the two objectives that shape the embeddings during learning."
                    ],
                    "subsections": []
                },
                {
                    "title": "C. Optimization",
                    "paragraphs": [
                        "At the beginning of the training, the dataset classifier G d (\u2022, W d ) is not well established. As a result, the gradient update for the feature embedding W f from L d (W f , \u0174d , k) is not quite stable and will negatively affect the discriminative ability in the classification. To further stabilize the training process, we split the optimization into two stages. The first stage is to initialize the model parameters and train the classification sub-network and dataset classifier separately as follows:",
                        "Note that in (9), the embedding sub-network W f is only supervised by the classification loss L cls (W f , W y , y, k) without the dataset classifier loss L d (W f , \u0174d , k). After each subnetwork converges, we further fine-tune all the parameters based on ( 7) and ( 8) in the second stage of the training."
                    ],
                    "subsections": []
                },
                {
                    "title": "A. Datasets and Experimental Settings",
                    "paragraphs": [
                        "Datasets. We combine 10 datasets during training, including 14-Celebrity [50], Asian-Celeb [51], CASIA [25], CelebA [52], DeepGlint [51], MS1M [1], PinsFace [53], 200-Celeb, VGGFace2 [22] and UMDFace [54]. The validation datasets include LFW [55], CFP-FP [56] and AgeDB-30 [57]. The description of each dataset is listed as follows:",
                        "\u2022 14-Celebrity [50] is a small face recognition dataset for Kaggle competition, including 14 identities and 117 images.",
                        "\u2022 Asian-Celeb [51] is a dataset contains around 94 thousand Asian celebrities with 2.8 million images.",
                        "\u2022 CASIA [25] is created and annotated from internet faces, including more than 10 thousand identities with about 0.5 million images.",
                        "\u2022 CelebA [52] is selected from [21], including 10 thousand identities, each of which has 20 images.  [54] contains the images downloaded from the internet with face detection and human annotation and cleaning. In total, it has 8.3 thousand identities and 0.4 million images.",
                        "\u2022 LFW [55] is the most widely used dataset for face recognition validation. It contains 5.7 thousand identities and 13 thousand faces. \u2022 CFP-FP [56] dataset focuses on frontal to profile face verification task. It includes 500 identities and 7000 images. \u2022 AgeDB-30 [57] contains 16 thousand images of 568 distinct subjects. It has a large age range for each subject. The information of each dataset is summarized in TABLE I. Experimental Settings. Two backbones, ResNet50 [14] and MobileNetV1 [17], are used as the embedding networks, followed by two separate fully connected layers used for the classification network and the dataset classifier. The embedding dimensions for ResNet50 and MobileNet are set to be 512 and 128, respectively. The parameter \u03bb from ( 7) is set to 0.1. In the training, we use a batch size of 256 and 512 for ResNet50 and MobileNet, respectively. The pre-trained model is adopted from [1]. We set the initial learning rate as 0.005, "
                    ],
                    "subsections": []
                }
            ]
        },
        {
            "title": "Dataset",
            "paragraphs": [
                "#ID #Image 14-Celebrity [50] 14 117 Asian-Celeb [51] 94.0K 2.8M CASIA [25] 10.5K 0.5M CelebA [52] 10.2K 0.2M DeepGlint [51] 180.9K 6.8M MS1M [23] 85.7K 5.8M PinsFace [53] 105 14.1K 200-Celeb 268 24.9K VGGFace2 [22] 8.6K 3.1M UMDFace [54] 8.3K 0.4M LFW [55] 5.7K 13,233 CFP-FP [56] 500 7,000 AgeDB-30 [57] 568 16,488  "
            ],
            "subsections": [
                {
                    "title": "B. Compared with State-of-the-Art Methods",
                    "paragraphs": [
                        "Our proposed method combines the ArcFace loss with dataset-aware loss as the default setting. As a result, we show the comparison with softmax based loss in TABLE II, where the numbers in the table are the face verification accuracy. The \"Comb\" in the table means combining the listed datasets from Section IV-A in the training. From the table, we can see that the results are largely dependent on the training dataset. There is 0.3% increase in accuracy if changing the CASIA dataset to the MS1M using the ArcFace loss. It is reasonable since the MS1M dataset has 8 times more IDs and is 10 times larger than the CASIA dataset. If we combine multiple datasets in the training, the accuracy on CFP-FP increases 3.1% and 6.0% compared with the individual CASIA and MS1M dataset, respectively. Similarly, The accuracy also increases on the AgeDB-30 dataset when combining multiple datasets in the training. This experiment shows evidence that there should be a performance gain for multi-dataset training. Such observation can be very beneficial for a practical purpose.",
                        "Apart from the comparison with ArcFace, CosFace and SphereFace, we also summarize the results compared with several state-of-the-art (SOTA) methods along with the num- "
                    ],
                    "subsections": []
                },
                {
                    "title": "Method",
                    "paragraphs": [
                        "#Image LFW DeepID [21] 0.2M 99.5 Deep Face [58] 4.4M 97.4 VGG Face [13] 2.6M 99.0 FaceNet [10] 200M 99.6 Baidu [59] 1.3M 99.1 Center Loss [6] 0.7M 99.3 Range Loss [11] 5M 99.5 Marginal Loss [12] 3.8M 99.5 Proposed (ResNet50)",
                        "19.6M 99.8 ber of training images on the LFW dataset for verification task in TABLE III. The competing methods include DeepID [21], Deep Face [58], VGG Face [13], FaceNet [10], Baidu [59], Center Loss [6], Range Loss [11] and Marginal Loss [12]. Specifically, DeepID [21] extracts visual features hierarchically from local low-level to global high-level and is supervised by both identification and verification loss. Deep Face [58] derives the face representation by employing an explicit 3D face modeling approach. For VGG Face [13], it explores the effect of using a large scale dataset in the training, while FaceNet [10] proposes a triplet loss for training on more than 200 million images. Baidu [59] aggregates multipatch information to learn the discriminative features. For Center Loss [6], Range Loss [11] and Marginal Loss [12], loss design to generate discriminative embeddings is explored.",
                        "From these methods, we can see that a large scale dataset is one important factor to achieve good performance. With our proposed approach with ResNet50 architecture, we have outperformed other SOTA methods with the help of the multidataset training strategy. Note that FaceNet adopts over 200 million images in the training, but this large database is not open to the public."
                    ],
                    "subsections": []
                },
                {
                    "title": "C. Ablation Study",
                    "paragraphs": [
                        "To validate the effectiveness of each component of our proposed method, we conduct ablation studies for the datasetaware loss and dataset invariant learning and summarize the results in TABLE IV. In this experiment, we adopt MobileNet as the embedding network and evaluated on LFW, CFP-FP and AgeDB-30 datasets for the verification task. First, we compare the effect of different training data. Two large scale training datasets, MS1M and VGGFace2, are used for the comparison. We adopt ArcFace loss without dataset-aware and domain adaptation since only a single dataset is used in the training. The verification accuracy is shown in the first rows of TABLE IV. We can see that the performance on the LFW is similar with just a few percent difference on CFP-FP and AgeDB-30. This indicates that the training set indeed has a large effect on the performance. Then we also evaluate the baseline method that naively combines the ten training sets from TABLE I to learn the face embedding by the default ArcFace loss. The result is shown in the 3rd row of TABLE IV with the method named \"Naive Comb\". As expected, there is no big improvement compared with single dataset training, and there is even an accuracy drop on the LFW dataset. This is due to the label overlapping issue for multidataset training. Without the label cleaning techniques, the training can be sensitive and not robust with such mislabeled data. The 4th row, with the method named \"DA\" (datasetaware), shows the result with dataset-aware ArcFace loss in the training. Compared with \"Naive Comb\", there is a significant improvement on all the three validation sets. This demonstrates that the label overlapping issue for multi-dataset training is automatically handled with the dataset-aware loss. The last two rows show the effectiveness incorporated with the domain adaptation approach using GRL in the training. From the results, we can see that there is a further improvement over \"DA\", and obviously, \"DA+GRL\" is much better than single dataset training and \"Naive Comb\". As the last experiment, we also implement a \"Crossing Dropout (CD)\" operation in the dataset-aware loss. Specifically, we replace (2) from Section III-A with the following modification, 1 ki=kj ,z<p = 1, if k i = k j , or k i = k j and z < p, 0, otherwise, .",
                        "(11) where z is a random variable with uniform distribution z \u223c U(0, 1) and p is a pre-defined probability, set as 0.0001 in the experiment. Different from the original dataset-aware loss, this modification only includes a few classes from other datasets for each training sample. Setting p = 1 will degrade to the original softmax loss and p = 0 is the proposed dataset-aware loss. With a small value p, the randomly selected classes are not likely to be the overlapping class of the training sample. Meanwhile, it can also help the network learn discrimination across different datasets. Interestingly, we find that setting p to be a small value of 0.0001, there is an improvement on CFP-FP and AgeDB-30 datasets and also comparable on the LFW dataset."
                    ],
                    "subsections": [
                        {
                            "title": "V. CONCLUSION",
                            "paragraphs": [
                                "In this paper, a dataset-aware loss with dataset invariant learning approach is presented for face recognition to address multi-dataset training issues, including ID overlapping issue and domain distribution mismatches. From the experiments, the proposed dataset-aware loss outperforms the single dataset training and naive combining strategy. Dataset-invariant learning with domain adaptation can further improve the verification accuracy."
                            ],
                            "subsections": []
                        }
                    ]
                }
            ]
        }
    ]
}