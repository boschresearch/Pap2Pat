# DESCRIPTION

## BACKGROUND

- motivate transformer architecture

## SUMMARY

- introduce adaptive sparse attention pattern
- advantages over fixed patterns

## DETAILED DESCRIPTION

- introduce adaptive sparse attention pattern
- motivate sparse attention patterns
- define sparse attention patterns
- describe benefits of adaptive sparse attention pattern
- explain how adaptive sparse attention pattern is customized
- describe how adaptive sparse attention pattern is developed during fine-tuning
- explain how important tokens are identified
- describe how adaptive sparse attention pattern is custom built
- explain how adaptive sparse attention pattern may be customized on a layer-by-layer basis
- describe how adaptive sparse attention pattern may be implemented with less training
- explain how adaptive sparse attention pattern provides increased accuracy
- describe FIG. 1, a high-level transformer model in a sparse attention-pattern environment
- explain how components in FIG. 1 operate
- describe how the technology described herein may be applied to other models
- explain how the sparse-attention pattern environment includes a generic pre-trainer
- describe how the sparse-attention model builder generates a sparse attention pattern
- explain how the adaptive sparse attention pattern is added to the generic model during fine-tuning
- illustrate transformer architecture without sparse attention pattern
- describe generic transformer model
- explain encoder-decoder model
- detail encoder and decoder stacks
- describe self-attention layer and feed forward neural network
- illustrate transformer architecture with sparse attention pattern
- describe task-specific model with adaptive sparse attention
- detail importance scorer and adaptive sparse attention pattern
- explain sparsity component and sparsity score
- define sparsity measure
- describe sparsity-controlled pattern generation
- detail importance scorer and fully connected layer
- explain Gumble sigmoid function and importance indicators
- calculate axis pattern
- describe pairing with local patterns
- summarize sparse attention pattern builder

## EXEMPLARY METHODS

- describe computing process
- introduce method 500 for training machine classifier
- generate sparse-attention model
- fine-tune sparse-attention model
- store sparse-attention model
- introduce method 600 for training machine classifier
- introduce method 700 for training machine classifier
- describe task-specific inference generation

### Exemplary Operating Environment

- describe computing device 800
- introduce bus 810
- describe memory 812
- introduce processors 814
- describe presentation components 816
- introduce input/output ports 818
- describe input/output components 820
- introduce power supply 822
- describe computer-readable media
- introduce computer storage media
- describe communication media
- introduce machine-learning system
- describe machine-learning tools
- introduce training components
- describe technical solution system
- describe API library

