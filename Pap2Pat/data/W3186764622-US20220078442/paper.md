# I. INTRODUCTION

V IDEO coding standards play an increasingly important role in diversified video applications and services ranging from the conventional television broadcasting, internet

## II. SUBBLOCK-BASED MOTION DERIVATION

One commonality among subblock-based motion derivation mechanisms in AMC, DMVR, and SbTMVP is to derive luma MV with 1/16 fractional-sample accuracy for subblock MC, instead of explicit coding subblock MVs. This feature enables subblock level MC at the cost of CU level signaling of motion information, which can theoretically reduce the number of bits for motion information coding for the same quality of inter prediction.

# A. Affine Motion Compensation

There are two variants of AMC in VVC, the affine inter mode and the affine merge mode. The difference is that the affine motion model is explicitly transmitted for the former one but derived at the decoder side for the latter one.

1) Control Point Representation for Affine Motion Model: Affine motion model of two types, a 4-parameter one and a 6parameter one, are introduced for describing complex motion typically characterized by zooming and rotation in addition to translation. The classic 6-paramater affine model is

where mv = (mv x , mv y ) is the MV at coordinate (i, j ); a, b, c, d, e, and f are the model parameters.

Representing the affine model by control point motion vectors (CPMVs) instead of the conventional model parameters was adopted in VVC AMC to take the advantage of the 

where The luma CB of a CU is split into 4×4 subblocks. The MV at the central sample position of a subblock, with coordinates as (2, 2) specifically, is calculated according to the affine motion model and set as the subblock MV, as illustrated in Fig. 2. The calculated subblock MV is rounded to 1/16 fractional-sample accuracy as the output. With the derived subblock MV, a set of 6-tap interpolation filters is applied to generate the prediction of each subblock [22]. The subblock size of chroma components is set to be 4 × 4, and the MV of a 4 × 4 chroma subblock is calculated as the average of the MVs of the top-left and bottom-right luma subblocks in the collocated 8 × 8 luma region for video contents in 4 : 2 : 0 color format [19].

2) Affine Inter Mode: Affine inter mode is restricted to CUs with both width and height larger than or equal to 16 luma samples, because the cost of transmitting CPMVs for smaller size CUs is too high to achieve a reasonable trade-off in ratedistortion performance. The usage of the mode is controlled by an indication flag. Another flag is signaled to indicate the motion model type, i.e., whether the 4-parameter model or the 6-parameter model is used. Depending on the motion model type, two or three motion vector differences (MVDs) between the CPMVs and the predictors of them are signaled. Without loss of generality, the 6-parameter model is used for explanation hereinafter in this section. The advanced motion vector prediction mechanism for MV coding in VVC [5] is adapted to the affine inter prediction where an affine motion vector predictor (MVP) comprises three MVPs at the three control points of the CU. For the derivation of the affine MVP in the prediction direction of the current CU, an affine MVP list with two candidates is constructed and an index is signaled to indicate the one selected at the encoder side. Note that this affine MVP derivation process is applied twice, separately for list 0 prediction and list 1 prediction, when bi-prediction is applied to the current CU.

The affine MVP list is constructed by firstly inserting the left neighbor candidate and the above neighbor candidate if available. The model inheritance mechanism is introduced to derive the affine model of the current CU from a spatial neighboring CU coded with affine mode. Specifically, the affine model of a neighbor CU coded in affine mode, represented by three CPMVs of (mv N 0 , mv N 1 , mv N 2 ), is applied to derive the MVPs at the three control points of the current CU, as shown in Fig. 3. The affine MVP candidate derived in this way is called an inherited affine MVP candidate. The neighboring CUs in position A0 and A1 are checked in order and the model inheritance mechanism is applied to the first available affine-coded CU to derive the left neighbor candidate. Note that the left neighbor candidate may not exist if the CUs at A0 and A1 are not affine-coded or the reference picture of the neighbor affine-coded CU is not the same as that of the current CU. The same process of checking availability and candidate derivation is applied to obtain the above neighbor candidate from CUs at B0, B1, B2 positions.

Secondly, the model construction mechanism is employed to derive one constructed affine merge candidate and put it in the affine MVP list if the list is not yet full. As illustrated in Fig. 4, the spatial neighbors around each control point are checked one by one, to identify if there exists an MV that points to the same reference picture as the current CU, and the first available MV is assigned as the CPMV predictor of the control point. The checking order is B2→B3→A2 for CP1, B1→B0 for CP2 and A1→A0 for CP3. The CPMV predictors at CP1, CP2 and CP3 are denoted as mv p 0 , mv p 1 , and mv p 2 , respectively. A constructed affine candidate is obtained if all the three CPMV predictors are available.

If the affine MVP list is still not full, stuffing affine candidates are inserted to the list. A stuffing affine candidate is derived by setting all three CPMV predictors to one of the MV in a pre-defined set of stuffing candidates. The pre-defined set of stuffing candidates comprises mv p 2 , mv p 1 , mv p 0 , TMVP, and zero MV. Each candidate in the set can only be used once.

The CPMVs (mv 0 , mv 1 , mv 2 ) of the 6-parameter model are derived at the decoder side as

where (mv p 0 , mv p 1 , mv p 2 ) is the affine MVP candidate selected at the encoder side, mvd 0 , mvd 1 , and mvd 2 are the received MVDs for the three MVPs accordingly. As illustrated in (4), both mvd 1 and mvd 2 are predicted by mvd 0 . This MVD prediction mechanism is designed specifically for coding affine MVDs and can exploit the similarities in the MVDs at affine control points.

3) Subblock Merge Mode: Similar to the regular merge mode in VVC where a list of motion candidates is derived for inter prediction at CU level [5], the subblock merge mode in VVC constructs a separate merge list with only subblock-based motion candidates. The candidate selected by the encoder is indicated by a merge index which is transmitted to the decoder. Subblock merge mode is applied to CUs with both width and height larger than or equal to 8 luma samples [41]. The SbTMVP candidate (introduced in Section II-B) is put in the first place of the list, followed by inherited affine merge candidates and constructed affine merge candidates. Maximum 5 candidates can be put in the subblock merge list. Since most of the candidates in the list are affine merge candidates, the subblock merge mode may also be referred to as the affine merge mode. Similar to the derivation of the inherited affine MVP candidate, the availability of the left and the top neighbor candidates are checked to derive the inherited affine merge candidates. The only difference is that the spatial neighboring CU in affine mode is not required to have the same reference picture as the current CU. The reference index of the current CU is set to be the same as that of the neighboring affine-coded CU, in the derivation of the inherited affine merge candidates. In addition, the motion model type and the prediction direction of the neighboring affine-coded CU are reused as well.

For the derivation of the constructed affine merge candidates, the motion information of all four control points is firstly derived from the spatial and temporal neighbors, as shown in Fig. 4. Using the same checking order as in the derivation of the constructed affine MVP candidate, the motion information at CP1, CP2 and CP3 is obtained. The temporal motion information in the collocated position T is obtained and set to be the motion information at CP4. The motion information at a control point may not exist if no valid motion information is found, e.g., in case the neighboring CU is coded in intra mode. A set of control point combinations is constructed as {CP1, CP2, CP3}, {CP1, CP2, CP4}, {CP1, CP3, CP4}, {CP2, CP3, CP4}, {CP1, CP2}, {CP1, CP3}, and is checked one after another. The availability of all CPMVs of a control point combination in bi-prediction, list 0 prediction, and list 1 prediction are checked in order, and a valid affine merge candidate is constructed if all CPMVs in a specified prediction direction exist and share the same reference index. Note that only the first valid candidate constructed from control point combination is selected. It is obvious that a 6-parameter affine motion model will be constructed from the combinations with three control points, and a 4-parameter model will be derived from the combinations with two control points.

If the subblock merge list is still not full after adding all subblock merge candidates abovementioned, one or more stuffing candidates of the 4-parameter affine model with zero CPMVs are inserted into the list.

# B. Subblock-Based Temporal Motion Vector Prediction

SbTMVP obtains motion information for each subblock of a CU in three steps: a) derive the displacement vector (DV) for the current CU, b) check availability of the SbTMVP candidate and derive the central motion, and c) derive the subblock motion information from the corresponding subblock identified by the DV. The derived subblock level motion information is used for the MC of both luma and chroma CBs of the CU. The collocated picture is the reference picture that is used as the source picture for temporal motion information derivation. Unlike TMVP candidate derivation in HEVC merge mode [3], which always derives the temporal motion vectors from the collocated block in the collocated picture, SbTMVP applies a DV to find the correspondence of the positions or the partitioned blocks in the current picture and those in the collocated picture. As shown in Fig. 5, the MV of the left neighboring CU of the current CU is selected to be the DV if the left neighboring CU uses the collocated picture as its reference picture. In case the left neighboring CU is not coded in inter prediction mode or the MV does not point to the collocated picture, the DV is set to (0, 0). The DV is then applied to the central position of the current CU to locate the displaced central position in the collocated picture, as illustrated in Fig. 5. If the block containing the displaced central position is not inter-coded, the SbTMVP candidate is considered not available. Otherwise, the motion information of the central position of the current CU, named as central motion, is derived from the motion information of the block containing the displaced central position in the collocated picture, marked as MV3 in Fig. 5. The central motion is derived in a similar way as the temporal motion candidate derivation where the temporal motion scaling is applied to align the reference pictures of the temporal motion vectors to those of the current CU [4]. Up to two motion vectors, one per list, can be derived. When the SbTMVP candidate is available, the DV is applied to find the corresponding subblock in the collocated picture for each subblock of the current CU. And the motion information of the corresponding subblock is used to derive the motion information of the subblock in the current CU in the same way as deriving the central motion. In case the corresponding subblock is not inter-coded, the motion information of the current subblock is set to be the central motion.

SbTMVP is applicable to CUs with both width and height larger than or equal to 8 luma samples. The subblock size for SbTMVP is set to 8 × 8 in VVC [42] in order to restrict the memory bandwidth consumption not exceeding the worst-case situation in 8 × 8 bi-prediction. To avoid additional memory access burden of loading motion information from random locations in the collocated picture, the location is restricted to be within the collocated area of the current CTU plus one column of 4 × 4 blocks at the right boundary. The location of the corresponding subblock is clipped to be within the constrained area if it goes outside after applying the DV.

# C. Decoder-Side Motion Vector Refinement

This section presents the design of DMVR in VVC. Readers can refer to [43]- [45] for the details of the technical discussion and the alternative versions of DMVR considered along its evolution. 1) General Description of DMVR Process: DMVR is applied to CUs in the regular merge mode in VVC [5]. The pair of MVs obtained from the regular merge mode is the input to the DMVR process. As shown in Fig. 6, DMVR applies bilateral matching to refine the accuracy of the input MV pair mv0 0,0 , mv1 0,0 and uses the refined MV pair for the motion-compensated prediction of both luma and chroma CBs of a CU. The input and the output of the DMVR process, namely the initial and refined MV pairs, obey the following equation:

(

The motion vector difference mv is added to mv0 0,0 and subtracted from mv1 0,0 to obtain the refined MV pair mv0 re f ined , mv1 re f ined , which is known as the MVD mirroring property of DMVR. MVD mirroring property is applied to reduce the number of candidate MV pairs, and is frequently used in VVC for MVD coding, for instance, in the merge mode with MVD and the symmetric MVD coding mode [5]. To ensure the equal distance MVD mirroring property, DMVR is allowed only if the initial MV pair point to two different reference pictures that have equal distance in picture order count (POC) to the current picture, wherein POC is an integer value used to uniquely identify each picture in a coded sequence. In addition to the equal POC distance restriction as described above, DMVR is restricted to CUs with width and height larger than or equal to 8 luma samples and the number of luma samples greater than or equal to 128, to avoid DMVR process on smaller CUs for complexity reduction. Other restrictions on the usage of DMVR can be found in [23].

A luma CB is divided into 16 × 16 subblocks for the MV refinement process if both the width and height of the CB are greater than or equal to 16 luma samples. If the width or the height of a luma CB is equal to 8 samples, the subblock size is set to be 8 × 16 or 16 × 8, respectively. The mv is obtained independently for each subblock in two steps, an integer-sample search step followed by a fractional-sample search step. And finally the subblock MC is applied using {mv0 refined , mv1 refined }.

2) Integer-Sample Search: A search space consisting of 25 candidate MV pairs is constructed as follows: where i, j represents the coordinate of a search point around the initial MV pair, and i and j are integer numbers between -2 and 2 inclusive. Since the internal MV precision is in 1/16 fractional-sample in VVC, the difference vector i, j is multiplied by 16. The difference between the candidate MVs are multiple of an integer-sample interval, hence the first step of DMVR is called the integer-sample search.

The candidate MV pairs are used to obtain pairs of motion-compensated luma prediction blocks (denoted P0 i, j and P1 i, j ). A bilinear interpolation filter, which has a lower memory bandwidth requirement and computational complexity than the 8-tap DCT-based interpolation filter (DCT-IF) [46], is applied at this stage. Test results in [47] and [48] had shown a negligible RD performance degradation when using bilinear interpolation instead of DCT-IF. It should be noted that the bilinear interpolation can be performed at CU level, as all subblocks in a CU have the same search space.

Afterwards, row subsampled sum of absolute differences (SAD) cost is calculated for prediction blocks of each candidate pair according to

where

Here, W and H are the width and height of the current subblock. The row subsampling reduces the operations for SAD computation by a factor of 2, while still being friendly to Single Instruction Multiple Data (SIMD) operations. The SAD corresponding to the initial MV pair is scaled with a factor of 3/4 to favor the center point in the search window, in order to stabilize the refinement process. The search coordinates resulting in the minimum SAD cost, denoted as i min , j min , is selected as the output of the integer-sample search step.

The SAD cost with the initial MV pair, indicating the center position in the search space, is first computed. Only if this cost is greater than or equal to a threshold value that is equal to the number of samples in the subblock, the remaining SAD costs are evaluated. This early termination results in complexity reduction and power savings in both hardware and software implementations with negligible impact on coding gains.

3) Fractional-Sample Search: The candidate MV pair selected in the integer-sample search step is further refined by leveraging the SAD costs already calculated. A quadratic error surface function with the following form, which is depicted in Fig. 7, is used to model the SAD costs at fractional-sample search coordinates:

Equation ( 10) is fitted to 5 of the 25 SAD costs calculated in the first step in order to determine the 5 unknowns parameters, i.e., α, β, γ , x min , and y min . The 5 SAD costs are selected as the costs corresponding to the coordinates i min , j min , i min -1, j min , i min , j min -1, i min + 1, j min and i min , j min + 1. The unknown parameters α, β, x min , and y min are therefore determined as

and

with S AD x = S AD(i min -1, j min ) + S AD(i min + 1, j min ), (15) S AD y = S AD(i min , j min -1) + S AD(i min , j min + 1), ( 16) S AD α = S AD(i min -1, j min )-S AD(i min + 1, j min ), (17) and S AD β = S AD(i min , j min -1)-S AD(i min , j min + 1). ( 18)

The motion vector difference in fractional-sample accuracy is determined by the coordinates x, y that minimizes the SAD cost S AD(x, y), which is equal to x min , y min . The mv in ( 5) is set equal to x min , y min , which is then used to obtain the refined motion vector pairs, i.e., mv0 re f ined and mv1 re f ined . It is worth noting that this fractional-sample search step will be skipped if any of the absolute values of i min and j min is equal to 2, indicating that i min , j min is at the boundary in the search space of the integer-sample search step. Because in this case not all of the 5 SAD costs required for the fractional-sample search would be available. This parametric error surface function based fractional-sample search eliminates the need for any sample processing in this stage. Against an alternative method that performs one iteration of half-sample refinement, this method offers a decoder complexity reduction (measured by running time) of 7 % without compression efficiency penalty [49]. 

## III. PREDICTION REFINEMENT WITH OPTICAL FLOW

Compared to traditional block MC, optical flow is expected to achieve the effect of sample-wise inter prediction. It is embodied in VVC as BDOF to refine the prediction of the CUbased bi-directional inter prediction, and as PROF to refine the subblock prediction of AMC.

# A. Bi-Directional Optical Flow for CU-Based Inter Prediction

Conventional bi-prediction is a weighted combination of two prediction blocks from previously coded pictures. Two MVs are used to obtain the two prediction blocks from a list 0 reference picture and a list 1 reference picture, respectively. However, due to the limitation of block-based MC, there are usually remaining displacements between the samples inside the two prediction blocks. The BDOF aims at compensating such fine displacement for each prediction sample on top of the original block-level MVs. In opposite to the block-based motion compensation, the refinement values of MVs are not signaled in BDOF. The BDOF is applied to the luma CB of a CU in regular merge mode or in the inter mode where symmetric MVD is not applied. And the BDOF is restricted to CUs with width and height larger than or equal to 8 luma samples and the number of luma samples greater than or equal to 128. Other restrictions on the usage of BDOF can be found in [23].

The BDOF is built upon the optical flow concept [33], [34]. Let I (i, j, t) be the luminance value of a sample at position (i, j ) and time t. Assuming the luminance of each sample is constant during the movement of the object, the optical flow differential equation, in this case, can be expressed as follows

As shown in Fig. 8, at each sample position the motion (v x , v y ) describing the remaining small displacement from I c to I 0 is symmetrical to its motion from I c to I 1 . Here I c , I 0 and I 1 are arrays of luminance values in the current block and the two prediction blocks from the list 0 and list 1 reference pictures, respectively. For the simplicity, remaining motions relative to both reference pictures are assumed to be the same in magnitude and opposite in directions. This assumption is reflected by the constraint that BDOF is applied only if the two different reference pictures have equal distance in POC to the current picture. It is worth noting that the same constraint is applied to DMVR as well.

Based on the symmetric motion model, (19) can be used to approximate the value of each sample in I c from two directions, one from its correspondence A in I 0 and the other from its correspondence B in I 1 . The value of (v x , v y ) is calculated by minimizing the difference between two predictions with refined motion:

Here (i, j ) is the spatial coordinate of a sample inside the predicted block, is surrounding of this sample. Spatial derivatives are approximated for the discrete sample arrays I 0 (i, j ) and I 1 (i, j ):

∂ I 0,1 (i, j ) ∂y = (I 0,1 (i, j + 1) -I 0,1 (i, j -1)) 1. (23) To reduce the computational complexity of the derivation of local remaining motions, the vector (v x , v y ) is assumed constant inside each 4 × 4 subblock. It is calculated once and shared by all the samples in the subblock [50]. Additionally, to make the derived motion field more stable, (v x , v y ) of each 4 × 4 subblock is calculated from the extended 6 × 6 region (noted as in ( 20)) containing a 4 × 4 subblock in the center.

The optimization problem in (20) can be resolved by setting both partial derivatives to zero and the resulting linear equation system is approximately solved by

where

and are the auto-and cross-correlation parameters, and ϑ x (i, j ) and ϑ y (i, j ) are the horizontal and vertical gradients and ϑ t (i, j ) is the temporal gradient of the sample at position (i, j ), which are calculated as

and

After (v x , v y ) is derived, the final bi-prediction signal I c (i, j ) in the current position (i, j ) of the block is calculated by interpolating list 0 and list 1 prediction samples along the motion trajectory (as shown in Fig. 8) based on the Hermite interpolation, i.e.,

# B. Affine Prediction Refinement With Optical Flow

At a later stage of VVC standardization, PROF was adopted to compensate for the prediction error of subblock-based AMC by applying the optical flow-based sample-wise refinement to the prediction.

Let P be the affine subblock prediction. Assume P(i, j ), the prediction at position (i, j ) in the current subblock is predicted from sample I (x, y) at position (x, y) in the reference picture with the subblock MV. Let (u i j , v i j ) be the displacement between the sample MV and the subblock MV, I (x + u i j , y + v i j ) would be the prediction if sample MV is used for motion compensation. The subblock-based and sample-based AMC are illustrated in Fig. 9.

Assuming (u i j , v i j ) is small, I (x + u i j , y + v i j ) can be approximated by Taylor expansion:

The prediction refinement is obtained by

where g x (i, j ) and g y (i, j ) are the spatial gradients of the subblock prediction in the horizontal and vertical directions. The gradient calculation is performed for each 4 × 4 subblock in an affine-coded CU in the following steps. At first, the 4 × 4 subblock prediction is extended by one sample on each side. The extended samples are copied from the nearest integer positions in the reference picture to avoid additional memory bandwidth consumption. Then, for each position (i, j ) in the 4 × 4 subblock, the spatial gradient is calculated as follow: (37) g y (i, j ) = (P(i, j + 1) 6) -(P(i, j -1) 6). (38) This is equivalent to applying a 2-tap filter on prediction samples for gradient calculation.

The displacement (u i j , v i j ) associated to each sample in the a subblock of an affine-coded CU can be derived based on the affine matrix A of the CU and the sample position relative to the center of a subblock with the following equation:

where (1.5, 1.5) is the center position relative to the top-left sample in a subblock. A is the affine matrix of the CU:

where a, b, c, and d are the affine model parameters as in (1). Since the sample positions relative to the subblock center are independent of the subblock position in a CU, (u i j , v i j ) can be derived for one subblock and reused in all subblocks in the same CU in an optimized implementation.

The intermediate precision of the calculation is carefully designed to reduce the rounding error. The precision of the spatial gradient in ( 37)-( 38) is designed to be the same as that in the BDOF process (see Section IV-C.3), such that the gradient computation component can be reused. u i j and v i j are rounded to 1/32 fractional-sample accuracy and further clipped within the range of [-31/32, 31/32] to avoid large MV difference.

The prediction refinement I (i, j ) is then clipped according to the internal bit-depth and added to the affine subblock prediction to form the final affine prediction. PROF is always applied to CUs in affine mode, but bypassed in case of identical CPMVs of an affine model, reference picture resampling [1], [51] being used, or the affine fallback mode (see Section IV-A.3) being triggered. The affine fallback mode will be triggered when subblocks of an affine-coded CU spread far apart from each other which poses a challenge to the memory bandwidth consumption during MC.  

## IV. IMPLEMENTATION CONSIDERATIONS

The preliminary designs of AMVC, DMVR and BDOF have been proposed and studied inside the JVET for a long time, but have not been considered mature until they were simplified in several important aspects for feasible hardware implementations with an affordable cost. Therefore, important simplifications of the three tools are elaborated in this section.

# A. Affine Motion Compensation 1) Motion Information Storage of Affine-Coded CUs:

After processing an affine-coded CU, the motion information of all 4 × 4 subblocks of the luma CB is stored and will be used in subsequent processes such as the MV prediction of following CUs and the deblocking filtering on block boundaries. Due to the introduction of the model inheritance mechanism which refers to the affine model of a previous CU coded in affine mode, the CPMVs of an affine-coded CU need to be additionally stored in a separate buffer [17]. Specifically, the stored CPMVs of neighboring CUs are used to derive the inherited affine MVP candidates and the inherited affine merge candidates for the current CU.

2) Affine Model Inheritance From the Above CTU Line: In a typical hardware design, a line buffer is used to store the motion information of the above CTU line and then the CUs in the current CTU line can refer to the stored motion information for MV prediction and deblocking filtering. Similarly, the CPMVs of the affine-coded CUs located at the bottom of the above CTU line need to be additionally stored and then can be used by the affine-coded CUs located at the top of the current CTU line, according to the model inheritance mechanism. To avoid adding additional line buffer for CPMVs in the above CTU line, a modified model inheritance mechanism was adopted in VVC to handle the situation. Specifically, when an affine-coded CU at the bottom of the above CTU line is referred to, the bottom-left and bottom-right subblock MVs of the CU are fetched and treated as the MVs at the bottom-left and bottom-right corner points, and a 4-parameter affine model represented by the two corner point MVs is assumed for the CU. The model is then applied to derive the inherited affine MVP candidates and the inherited affine merge candidates for the current CU [18], as shown in Fig. 10. With such a design, the subblock MVs already stored in the line buffer is reused for affine model inheritance.

3) Bounding Box Constraint for Low Complexity MC: The reference blocks for the MC of all 4 × 4 subblocks of an affine-coded CU may spread to a large region in the reference picture and have zero overlapping with each other, which may lead to non-affordable peak memory bandwidth consumption when fetching reference samples for MC [21]. To constrain the complexity of MC in such a case, the MV at the center position (W/2, H /2) of the CU is calculated according to the affine model and is set to be the MVs of all subblocks. This is called affine fallback mode and is triggered if the size of the bounding box calculated for an affined-coded CU exceeds a pre-defined threshold. The bounding box is defined as the rectangular region covering all reference blocks of a pre-defined cluster of subblocks in the current CU. A reference block contains all reference luma samples required for the MC of the corresponding subblock.

For an affine-coded CU with bi-prediction, the bounding box covers all four reference blocks of a 2 × 2 cluster of subblocks, as shown in Fig. 11. The size of the bounding box is W box × H box . W box and H box are calculated as,

where a, b, c, and d are the affine parameters. The pre-defined threshold is set to 225 = (8 + 7) × (8 + 7), which is the number of luma reference samples required for 8 × 8 block MC with 8-tap DCT-IF. By this design, the memory bandwidth consumption does not exceed that for the bi-prediction of intercoded 8 × 8 CU in VVC.

Similarly, for an affine-coded CU with uni-prediction, the bounding box covers the two reference blocks of the 2 × 1 or 1 × 2 cluster of subblocks. The threshold is set to 165 = (8 + 7) × (4 + 7) for both bounding boxes, where 165 is the number of luma reference samples required for the MC of an 8 × 4 or a 4 × 8 block. And the memory bandwidth consumption does not exceed that for the uni-prediction of inter-coded 8 × 4 or 4 × 8 CU in VVC by this design. 

# B. Decoder-Side Motion Vector Refinement

The predecessors of DMVR such as FRUC with BM and TM in JEM have significantly high decoding complexity. A series of simplifications were proposed for DMVR to arrive at the sweet spot between compression gains and decoding/encoding complexity. The usage of bilinear interpolation during refinement, row subsampled SAD during the integersample search, and parametric error surface-based fractionalsample search are such simplifications already covered in Section II-C. Additional important simplifications are presented here.

# 1) DMVR Search Range and Integer-Sample Search Precision:

The main source of the computational complexity of DMVR is SAD cost calculations in the integer-sample search step, which is proportional to the number of candidate MV pairs. The candidate MVs, either list 0 or list 1 MVs of the candidate MV pairs, point to search points that form a grid with a displacement of one luma sample in horizontal and vertical directions. The selection of the integer-sample interval as the displacement is a deliberate design choice, since the generation of predictions P0 i, j and P1 i, j by interpolation filtering is greatly simplified due to the following relationships:

According to the above relationships the 25 prediction pairs of size W and H can be computed as a single prediction pair with size W + 2R and H + 2R, where R is the search range.

The search range, which determines the number of equally spaced candidate MVs in the integer-sample search step, is set equal to 2 luma samples for the best trade-off of computational complexity and coding efficiency. This results in the aforementioned 25 candidate MV pairs and 25 necessary SAD computations.

2) Forced Subblock Partition: The motion refinement is performed for the entire luma CB in an early-phase design of DMVR. Performing refinement at luma block sizes of 128 × 128 requires two internal buffers of size up to (128 + 4) × (128 + 4), which is quite prohibitive. Also, handling the granularity of the different luma CB sizes while performing the refinement poses additional complexity. For these reasons, the luma CB is partitioned into subblocks with luma width and height not exceeding 16. The refinement is performed independently for each subblock. Different subblock maximum sizes were experimented in [31]. The subblock partition design lowers the internal memory requirement in hardware to as low as 2 × (16 + 7) × (16 + 7) samples. Also, the refinement logic needs to handle only three possible subblock sizes, namely, 16 × 8, 8 × 16, and 16 × 16. It is noted that this forced subblock partition increases the overall number of operations required for MC in the final stage, compared to luma CB-based refinement. Since hardware decoders are designed to handle the theoretical worst-case number of partitions, this aspect is more of a concern only for software implementations.

3) Restriction on Using Refined MV: In typical hardware architectures of the MC module, reference samples are pre-fetched at a granularity higher than that of a CU through direct memory access (DMA). In a preliminary design of DMVR, the refined MVs are used as spatial MV predictors for subsequent CUs. This complicates the existing pre-fetching mechanism since the refined MVs inside a region are not available at the time when pre-fetching is working on the region. On the other hand, the derivation of the MVs of the subsequent CUs may need to wait for the refined MV of the current CU, which potentially adds additional latency for typical hardware pipelines. To eliminate potential implementation difficulties mentioned above, the use of refined MVs for merge MV derivation and spatial MV prediction was disabled [52]. Later, in [31], the use of refined MVs in boundary strength (BS) derivation for deblocking filtering was also disabled. Hence in VVC the refined MVs are used only for the motion compensation for the current CU and are stored in temporal MV buffer for coding of subsequent pictures. It is worth noting that the same restriction is applied to the BDOF process, where the refined motions of all 4 × 4 subblocks are used exclusively for the prediction refinement of the current CU.

4) Sample Padding for MC in the Final Stage: The conventional MC for a W × H block requires fetching up to (W + 7) × (H + 7) luma reference samples and (W/2 + 3) × (H /2 + 3) chroma reference samples per reference picture. With the ±2 search window around the starting point for DMVR, (W +11)×(H +11) luma and (W/2 +5)×(H /2 +5) chroma reference samples would need pre-fetching. Considering the worst-case situation where each block would need to access the memory independently for its reference samples, the memory bandwidth consumption would be increased by DMVR. To maintain the same worst-case memory bandwidth, the block of reference samples is constrained to be the same as that for the conventional MC. In case samples outside of the reference area are required for MC in DMVR, padded samples are used instead. The padded sample values are obtained from the closest sample positions falling within the block of reference samples for conventional MC [53].  are larger than 16 luma samples, it will be split into subblocks with width and height not exceeding 16. With such a design, the internal buffer size required by BDOF implementations is reduced, and the unit size for BDOF processing is perfectly aligned with that for DMVR processing in hardware codec design. Meanwhile, as will be discussed later, such a design also allows the initial SAD of the DMVR refinement to be used for bypassing partial BDOF operations. Without loss of generality, 16×16 size subblock is assumed for the explanation hereinafter in this section. The gradient calculations specified in ( 22)-( 23) are conducted at the 16 × 16 subblock level. Each 16 × 16 subblock is extended by one sample on each side. Instead of performing motion-compensated interpolation to obtain the extended samples, these samples are copied from the nearest integer sample positions in the reference picture to avoid additional memory bandwidth and additional MC operations. The obtained gradients are then used for the calculation of v x , v y , and I c (i, j ) as specified in ( 24)- (34), which is conducted for each 4 × 4 subblock inside a 16 × 16 subblock. As each 4×4 subblock is extended to a 6×6 region for the calculations, prediction samples and gradients outside of the current 16×16 subblock boundaries are requested for 4 × 4 subblocks located at the boundaries of the 16 × 16 subblock. These prediction samples and gradients are directly copied from their nearest neighbors on the 16 × 16 subblock boundaries [37].

# C. Bi-Directional Optical Flow

An early termination for BDOF operations is applied at the 16 × 16 subblock level [36]. Specifically, the BDOF process may be skipped for a subblock when the DMVR is applied to the subblock as well. In this case, the SAD cost with the initial MV pair from the DMVR process is checked. If the SAD cost is smaller than a threshold, the prediction is considered to be of high quality, and therefore the BDOF process is skipped. The threshold is set equal to (2 × W × H ), where W and H indicate the width and height of the subblock.

2) Simplified BDOF Parameter Derivation: As shown in ( 25)-( 29), large numbers of multiplications are needed to calculate the auto-and cross-correlation parameters S1, S2, . . . , S5 in a straightforward design. This results in Based on the assumption that gradients are nearly constant inside a subblock, the multiplications can be replaced by sign operations and ( 25)-( 29) are approximated by:

and

This approximation removes all multiplications and reduces the overall number of multiplications of BDOF by more than 80 % [38].

3) Bit-Width Control of BDOF Intermediate Parameters: To reduce the dynamic range of intermediate parameters used for the BDOF process, different bitwise right shifts are introduced [37] to lower the precisions of the BDOF parameters ϑ x (i, j ), ϑ y (i, j ) and ϑ t (i, j ) in ( 30)- (32), as indicated below:

and

where

Table I illustrates the bit-widths of the BDOF intermediate parameters in ( 21)- (34) for different internal bit-depths. As shown in the table, for internal bit-depths from 8 to 16 bits, all the BDOF related computations can be implemented using integer arithmetic not exceeding 32 bits.

## V. EXPERIMENTAL RESULTS AND ANALYSIS

Encoder configurations of random access (RA) and low delay with B slices (LDB) specified in the JVET common test conditions (CTC) [54] were used for evaluating the implementations of the five subblock-based inter coding tools in VTM-9.0 [55]. In CTC, test sequences are grouped into several categories according to the spatial resolution and the application scenario. Class A1 and A2 contain 4K sequences representing the high quality entertainment video content and therefore they are not tested with LDB configuration that is primarily for real-time communication scenario. Out of the same reason, class E that comprises three typical video conferencing sequences is tested with LDB only. The Bjøntegaard Delta rate (BD-rate) [56] was employed to measure the bitrate 

# A. Rate-Distortion Performance

The anchor for comparison is VTM-9.0 with the five tools switched off. The compression efficiency improvement in terms of BD-rate as well as the computational complexity increase in terms of the encoder and decoder runtime ratio are presented in Table II. Averaged BD-rate savings over all test sequences with joint YUV measurement are 5.7 % and 3.4 % with RA and LDB configurations, respectively. In addition, a balanced performance on Y, U, and V components can be observed. Since DMVR and BDOF are not applicable to the LDB configuration where the two reference pictures for bi-prediction come from the same temporal direction, the compression efficiency in LDB is lower than that in RA. With the RA configuration, more than 10 % BD-rate saving is observed for test sequence CatRobot1, Cactus, and DaylightRoad2 where complex motion such as rotation and zooming are observed. It is worth noting that such complex motion typically consumes a lot of bits for coding with previous standards and therefore is considered to be very challenging for video compression. However, the five VVC tools presented in this paper are especially good at handling complex motion according to the results. Since the encoder and decoder runtime increase in percentage highly depends on the specific implementation and the level of optimization, the data provided in Table II can only be referenced as a rough estimation of the computational complexity. It is observed that the encoder runtime in LDB is higher than that in RA. This is caused by the specific implementation of AMC motion estimation module in VTM-9.0 where more reference pictures are checked in the bi-prediction stage with the LDB configuration.

The gain in compression efficiency with regard to individual tools are presented in Table III. Only the RA configuration is tested because DMVR and BDOF are not applicable to LDB. As shown in Table III, all tools show decent gain while AMC shows the biggest gain. And in general the overall complexity considering both encoder and decoder runtime correlates well with the BD-rate saving for the five tools. Therefore all the tools demonstrate good trade-off between the compression efficiency and the computational complexity. Note that PROF is only applicable to affine-coded CUs and therefore can only be tested on top of AMC.

Different from Table II and Table III, VTM-9.0 with all five tools switched on was used as the anchor in Table IV, and each tool was switched off individually to observe the compression efficiency loss, where the negative sign of a BD-rate value indicates a loss. Averaged PSNR of Y, U, and V components is used for the BD-rate calculation in Table III and Table IV. We can get a hint of the interaction of the five tools by checking the corresponding BD-rate values in Table III and Table IV. For example, the BD-rate of AMC + PROF is similar to that in Table III in absolute value but different in sign, which shows that AMC + PROF has almost no overlap with the other three tools in terms of compression efficiency gain. However, for SbTMVP, DMVR and BDOF, the absolute values of BD-rate in Table IV are about half of the corresponding ones in Table III, indicating that each tool has a certain level of overlap with the set of the remaining four tools. Since all the three tools try to save the signaling overhead of motion information, it is reasonable to observe an overlap with each other because of competition. Furthermore, each of the three tools may have an overlap with AMC which tries to reduce the signaling overhead of motion information by a more compact representation. However, mild overlap actually gives more flexibility in practical applications. Assuming that a certain implementation of the VVC encoder may not favor a specific coding tool, in this case, this tool can be switched off while the potential compression efficiency loss can be partially compensated by other tools.

# B. Statistics Analysis

Table V shows the percentage of bitrate reduction for the test of Class A2 sequences with RA configuration. Class A2 was selected for illustration because it shows top performance among all classes and therefore can better demonstrate the trends in statistics. We observed that the five tools can significantly reduce the bits for coding the partition and motion  information. For example, in case of QP 37, the bits reduction for coding partition information takes 1.3 % of the total bitstream, and the bits reduction for coding motion information is 5.3 %. This is because the five tools are designed to either represent the motion information in a more efficient way or to derive the motion at the decoder side. And therefore the bits for coding fine-granular motion in small blocks can be saved. The bits for coding prediction residual can also be reduced because more accurate prediction can be achieved by the five tools. It is also observed that the total bitrate saving increased dramatically with QP values, reaching up to 7.6 % for QP 37. The reason is that the portion of partition and motion information in the bitstream becomes larger for higher QP values, and therefore the advantages of the five tools become more evident.

Fig. 12(a) and Fig. 12(b) show the CU partitioning in a part of the 9 th frame of the sequence CatRobot1, with the five tools disabled and enabled. It can be obviously seen that the CU size increases a lot in the area of the rotating plate. Without the five subblock-based inter tools, the encoder has to split the complex motion region into small CUs and transmit huge amount of motion information. With the five tools enabled, the complex motion can be efficiently represented and further refined at the decoder side, and therefore large CU sizes are selected instead.

# C. Visual Quality Impact

The reconstruction for a part of the 41 st frame of CatRo-bot1, with the five tools disabled and enabled, is shown in Fig. 13. RA configuration was used for the simulation. With the five tools enabled, the bits for coding the frame is decreased to 72928 from 90088. Meanwhile, a much better visual quality is observed. Specifically, the blocking artifact along the sharp edges on the rotating plate is largely removed. We believe that the visual quality can be further improved if the bits for coding the two frames are aligned. In the example in Fig. 13, most of the visual quality benefits are contributed by AMC and PROF since the two tools are especially good at handling rotations in video content. For the other three tools, SbTMVP, DMVR and BDOF, it is observed that their primary effect is reducing the bits for coding motion information rather than improving the quality of reconstruction.

## VI. CONCLUSION

Five VVC inter coding tools, AMC, DMVR, SbTMVP, BDOF and PROF, are introduced in this paper. These tools are designed to perform fine-granular motion compensation without explicit signaling of subblock MVs. Design elements considering typical hardware implementations are presented as well. Experiments are conducted to demonstrate the advantages in RD efficiency and to provide a comprehensive analysis of the inherent characteristics of the tools.

## ACKNOWLEDGMENT

The authors would like to thank Han Gao who contributed to the drafting of this paper. They thank Prof. Shuai Wan for the help to improve the English writing of this paper. They thank JVET experts for their great contributions to the design of the subblock-based inter coding tools throughout the standardization period of VVC.

