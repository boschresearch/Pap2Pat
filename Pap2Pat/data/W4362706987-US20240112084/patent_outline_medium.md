# DESCRIPTION

## BACKGROUND

- motivate feature selection

## BRIEF SUMMARY

- introduce sparse learnable masks
- describe dual mechanisms for mask scaling
- describe objective for mutual information
- summarize empirical results
- outline method for training machine learning model
- describe aspects of disclosure

## DETAILED DESCRIPTION

- introduce sparse learnable masks (SLM) for scalable feature selection
- describe SLM integration into deep learning or machine learning architecture
- depict block diagram of sparse learnable masks system 100
- describe input data 102 for feature selection
- explain training data for machine learning task
- describe training process for scalable feature selection
- introduce normalization engine 106 for sparse non-linear normalization
- describe tempering engine 108 for gradual feature selection
- explain mask scaling engine 110 for sparse feature mask scaling
- introduce mutual information engine 112 for increasing mutual information
- describe quadratic relaxation of mutual information
- explain connection of mutual information with predictor model
- describe error term E(X,Y) for quadratic relaxation
- explain Lagrange multipliers for solving optimal model predictions
- describe feature selection using mutual information engine 112
- explain error reduction under consistency constraints
- describe soft consistency regularization term for unconstrained optimization
- define probabilistic form of consistency regularization
- derive regularized objective to maximize mutual information
- describe sparse learnable masks system architecture
- explain computational complexity of sparse learnable masks system
- depict block diagram of example environment for implementing sparse learnable masks system
- describe server computing device and client computing device
- explain data storage and retrieval in server computing device and client computing device
- describe instructions and data in server computing device and client computing device
- depict block diagram of machine learning model architectures for deployment in data center
- describe hardware accelerator in data center
- explain communication between devices over network
- describe example process for training machine learning model using scalable feature selection
- explain receiving features and labels for training machine learning model
- describe sparse learnable masks system
- initialize learnable mask vector
- perform training step
- generate sparse mask vector
- select features
- compute mutual information based error
- update learnable mask vector
- output final selected features
- describe process for training machine learning model
- receive number of features to be selected
- generate sparse mask vector
- select features
- compute mutual information based error
- update learnable mask vector
- compare accuracy with other feature selection approaches
- describe advantages of sparse learnable masks system
- describe implementation of aspects of disclosure
- define terms used in disclosure

