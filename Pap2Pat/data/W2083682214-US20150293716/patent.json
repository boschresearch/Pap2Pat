{
    "id": "US20150293716",
    "authors": [
        "Anxiao Jiang",
        "Yue Li",
        "Eyal En Gad",
        "Michael Langberg",
        "Jehoshua Bruck"
    ],
    "title": "JOINT REWRITING AND ERROR CORRECTION IN WRITE-ONCE MEMORIES",
    "date": "2013-07-05 00:00:00",
    "abstract": "Both rewriting and error correction are technologies usable for non-volatile memories, such as flash memories. A coding scheme is disclosed herein that combines rewriting and error correction for the write-once memory model. In some embodiments, code construction is based on polar codes, and supports any number of rewrites and corrects a substantial number of errors. The code may be analyzed for a binary symmetric channel. The results can be extended to multi-level cells and more general noise models.",
    "sections": [
        {
            "title": "DESCRIPTION",
            "paragraphs": [],
            "subsections": [
                {
                    "title": "STATEMENT REGARDING GOVERNMENT SPONSORED RESEARCH AND DEVELOPMENT",
                    "paragraphs": [
                        "The subject matter described herein was made at least in part with government support under CIF1218005 awarded by the National Science Foundation. The United States government may have certain rights in the subject matter disclosed herein."
                    ],
                    "subsections": [],
                    "outline_long": [
                        "disclose government support"
                    ],
                    "num_characters": 239,
                    "outline_medium": [
                        "disclose government support"
                    ],
                    "outline_short": [
                        "disclose government support"
                    ]
                },
                {
                    "title": "TECHNICAL FIELD",
                    "paragraphs": [
                        "The field generally relates to unidirectional or write only memories (WOM), which have cells which may be individually changed in a single direction, but are erased as a group, and more specifically but not exclusively to rewriting write only memories with error correction."
                    ],
                    "subsections": [],
                    "outline_long": [
                        "define technical field"
                    ],
                    "num_characters": 274,
                    "outline_medium": [
                        "define technical field"
                    ],
                    "outline_short": [
                        "define technical field of write-only memories"
                    ]
                },
                {
                    "title": "BACKGROUND",
                    "paragraphs": [
                        "Unless otherwise indicated herein, the materials described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.",
                        "Coding for rewriting is a technology used for flash memories. Coding has the potential to substantially increase the longevity, speed, and power efficiency of flash memories. Coding for rewriting has been proposed recently. See, e.g. V. Bohossian, A. Jiang, and J. Bruck, \u201cBuffer coding for asymmetric multi-level memory,\u201d in Proc. IEEE Internatio. Nal Symposium on Information Theory, June 2007, pp. 1186-1190, and A. Jiang, V. Bohossian, and J. Bruck, \u201cFloating codes for joint information storage in write asymmetric memories,\u201d in Proc. IEEE International Symposium on Information Theory, June 2007, pp. 1166-1170, which are incorporated herein by reference. Since the time coding was initially proposed, many works have appeared in this area. See, e.g. Y. Wu, \u201cLow complexity codes for writing a write-once memory twice,\u201d in Proc. IEEE International Symposium on Information Theory, June 2010, pp. 1928-1932, Y. Wu and A. Jiang, \u201cPosition modulation code for rewriting write-once memories,\u201d IEEE Trans. Inf. Theor., vol. 57, no. 6, pp. 3692-3697, June 2011, E. Yaakobi, S. Kayser, P. H. Siegel, A. Vardy, and J. K. Wolf, \u201cCodes for write-once memories,\u201d IEEE Trans. Inf. Theor., vol. 58, no. 9, pp. 5985-5999, September 2012, and E. Yaakobi, S. Kayser, P. Siegel, A. Vardy, and J. Wolf, \u201cEfficient two-write wom-codes,\u201d in Proc. IEEE Information Theory Workshop, September 2010, pp. 1-5, which are incorporated herein by reference.",
                        "A model for rewriting is a write-once memory (WOM) model. See. e.g. R. L. Rivest and A. Shamir, \u201cHow to reuse a write-once memory,\u201d Information and Control, vol. 55, no. 1-3, pp. 1-19, 1982, which is incorporated herein by reference. In the WOM model, a set of binary cells are used to store data, and the cell charge levels are increased when the data are rewritten. For flash memories, this constraint implies that the rewriting operation may delay the expensive block erasure, which leads to better preservation of cell quality and higher writing performance.",
                        "There have been many techniques for the design of WOM codes. They include linear code, tabular code, codes based on projective geometry, coset coding, etc. See, e.g. G. Cohen, P. Godlewski, and F. Merkx, \u201cLinear binary code for write-once memories,\u201d IEEE Trans. Inf. Theor., vol. 32, no. 5, pp. 697-700, September 1986, Merkx, \u201cWomcodes constructed with projective geometries\u201d Traitement du Signal, vol. 1, no. 2-2, pp. 227-231, 1984, and R. L. Rivest and A. Shamir, \u201cHow to reuse a write-once memory,\u201d Information and Control, vol. 55. no. 1-3, pp. 1-19, 1982, which are incorporated herein by reference. Codes with substantially higher rates were discovered in recent years. See, e.g. V. Bohossian, A. Jiang, and J. Bruck, \u201cBuffer coding for asymmetric multi-level memory,\u201d in Proc. IEEE International Symposium on Information Theory, June 2007, pp. 1186-1190, and A. Jiang, V. Bohossian, and J. Bruck, \u201cFloating codes for joint information storage in write asymmetric memories,\u201d in Proc. IEEE International Symposium on Information Theory, June 2007, pp. 1166-1170, which are incorporated herein by references. Since the time such coding was initially proposed, many works have appeared in this area. See, e.g. Y. Wu, \u201cLow complexity codes for writing a write-once memory twice,\u201d in Proc. IEEE International Symposium on Information Theory, June 2010, pp. 1928-1 2, E. Yaakobi, S. Kayser, P. H. Siegel, A. Vardy, and J. K. Wolf, \u201cCodes for write-once memories,\u201d IEEE Trans. Inf. Theor., vol. 58, no. 9, pp. 5985-5999, September 2012, which are incorporated herein by reference. In 2012, WOM codes that achieved capacity were discovered by Shpilka et al. and Burshtein et al. See, e.g. A. Shpilka, \u201cCapacity achieving multiwrite wom codes,\u201d CoRR, vol. abs/1207.1128, 2012, \u201cCapacity achieving two-write wom codes,\u201d in LATIN 2012: Theoretical Informatics, ser. Lecture Notes in Computer Science, vol. 7256. Springer Berlin Heidelberg, 2012, pp. 631-642, E. Yaakobi and A. Shpilka, \u201cHigh sum-rate three-write and non-binary wom codes,\u201d in Proc. IEEE International Symposium on Information Theory, July 2012, pp. 1386-1390, and D. Burshtein and A. Strugatski, \u201cPolar write once memory codes,\u201d in Proc. IEEE International Symposium on Information Theory, July 2012, pp. 1972-1976, which are incorporated herein by reference. The latter code used a construction based on polar coding.",
                        "Compared to the large amount of work on WOM codes, the work on WOM codes that also correct errors has been much more limited. Existing works are mainly on correcting a few errors (for example, 1, 2, or 3 errors). See, e.g. E. Yaakobi, P. Siegel, A. Vardy, and J. Wolf, \u201cMultiple error-correcting wom-codes,\u201d IEEE Trans. Inf. Theor., vol. 58, no. 4, pp. 2220-2230, April 2012, and G. Zemor and G. D. Cohen, \u201cError-correcting wom-codes,\u201d IEEE Trans. Inf. Theor., vol. 37, no. 3, pp. 730-734, May 1991, which are incorporated herein by reference."
                    ],
                    "subsections": [],
                    "outline_long": [
                        "introduce coding for rewriting",
                        "motivate coding for rewriting",
                        "summarize prior art on coding for rewriting",
                        "describe WOM model",
                        "discuss techniques for designing WOM codes",
                        "summarize recent works on WOM codes",
                        "discuss capacity achieving WOM codes",
                        "introduce error correction in WOM codes",
                        "summarize prior art on error-correcting WOM codes",
                        "motivate need for joint rewriting and error correction"
                    ],
                    "num_characters": 5122,
                    "outline_medium": [
                        "introduce coding for rewriting",
                        "discuss prior art on coding for rewriting",
                        "describe WOM model",
                        "discuss prior art on WOM codes",
                        "discuss prior art on error-correcting WOM codes"
                    ],
                    "outline_short": [
                        "motivate coding for rewriting",
                        "summarize prior art on WOM codes and error correction"
                    ]
                },
                {
                    "title": "SUMMARY",
                    "paragraphs": [
                        "Coding schemes that combine rewriting with error correction are discussed. In some embodiments, the schemes may support any number of rewrites and can correct a substantial number of errors. The code construction may use polar coding. In some embodiments, an analytical technique may be used which is based on frozen sets corresponding to the WOM channel and the error channel, respectively, including their common degrading and common upgrading channels. In some embodiments, lower bounds to the sum-rate may be achieved. The actual sum-rates may be further computed for various parameters. The analytical technique may focus on the binary symmetric channel (BSC). In practice, for relatively small error probabilities, the frozen set for BSC may be often contained in the frozen set for the WOM channel, which enables some embodiments to have a nested structure. The coding scheme can be further extended to multi-level cells (MLC) and more general noise models.",
                        "One aspect is a method of rewriting a memory. The method includes determining a current cell charge level of each of a plurality of cells of the memory, and generating a plurality of next cell charge levels according to a linear transformation, where each next cell charge level is generated based on a corresponding one of the current cell charge levels and based on input data. Each next cell charge level is greater than or equal to the corresponding current cell charge level, the plurality of next cell charge levels represent the input data, and the plurality of next cell charge levels include redundancy for error correction. The method also includes storing the next cell charge levels in the memory.",
                        "Another aspect is a method of reading a memory. The method includes determining current cell charge levels of a plurality of cells of the memory, where the current cell charge levels represent data and error correction information. The method also includes generating a plurality of data values, where the data values are generated based on a linear transformation of the current cell charge levels, and transmitting the data values to a data destination.",
                        "Another aspect is a memory system. The system includes a memory that includes a plurality of cells, a processor coupled to the memory and configured to determine current cell charge levels of the plurality of cells of the memory, and an encoder coupled to the memory and to the processor, and configured to generate a plurality of next cell charge levels according to a linear transformation, where each next cell charge level is generated based on a corresponding one of the current cell charge levels and based on input data. Each next cell charge level is greater than or equal to the corresponding previous cell charge level, the plurality of next cell charge levels represent the input data, and the plurality of next cell charge levels include redundancy for error correction. The system also includes a write device, configured to store the next cell charge levels in the memory.",
                        "Another aspect is a memory system. The system includes a memory that includes a plurality of cells, a processor coupled to the memory and configured to determine current cell charge levels of the plurality of cells of the memory, where the current cell charge levels represent data and error correction information. The system also includes a decoder coupled to the processor and to the memory, and configured to generate a plurality of data values, where the data values are generated based on a linear transformation of the current cell charge levels. The system also includes a transmitter coupled the decoder and configured to transmit the data values to a data destination.",
                        "The foregoing summary is illustrative and is not intended to be in any way limiting. In addition to the illustrative aspects, embodiments, and features described above, further aspects, embodiments, and features will become apparent by reference to the drawings and the following detailed description.",
                        "- All of the aspects and other features shown in the drawings are\n  arranged according to at least some embodiments presented herein."
                    ],
                    "subsections": [],
                    "outline_long": [
                        "introduce joint rewriting and error correction",
                        "describe code construction using polar coding",
                        "summarize analytical technique",
                        "discuss lower bounds to sum-rate",
                        "describe extension to MLC and general noise models",
                        "introduce method of rewriting a memory",
                        "introduce method of reading a memory",
                        "introduce memory system"
                    ],
                    "num_characters": 4138,
                    "outline_medium": [
                        "introduce joint rewriting and error correction",
                        "describe code construction using polar coding",
                        "discuss analytical technique for sum-rate bounds",
                        "outline embodiments of memory system"
                    ],
                    "outline_short": [
                        "introduce joint rewriting and error correction",
                        "outline embodiments of coding schemes"
                    ]
                },
                {
                    "title": "DETAILED DESCRIPTION",
                    "paragraphs": [
                        "- In the following detailed description, reference is made to the\n  accompanying drawings, which form a part hereof. In the drawings,\n  similar symbols typically identify similar components, unless context\n  dictates otherwise. The illustrative embodiments described in the\n  detailed description, drawings, and claims are not meant to be\n  limiting. Other embodiments may be utilized, and other changes may be\n  made, without departing from the spirit or scope of the subject matter\n  presented herein. The aspects of the present disclosure, as generally\n  described herein, and illustrated in the Figures, can be arranged,\n  substituted, combined, separated, and designed in a wide variety of\n  different configurations, all of which are explicitly contemplated\n  herein.\n- This disclosure is generally drawn, inter alia, to methods, apparatus,\n  systems, devices, and computer program products related to joint\n  rewriting and error correction in write-once memories.\n- Briefly stated, both rewriting and error correction are technologies\n  that may be used for non-volatile memories, such as flash memories.\n  This disclosure presents a coding scheme that combines rewriting and\n  error correction for the write-once memory model. In some embodiments,\n  code construction is based on polar codes, and supports any number of\n  rewrites and corrects a substantial number of errors. The code may be\n  analyzed for a binary symmetric channel. The results can be extended\n  to multi-level cells and more general noise models.",
                        "I. Introduction",
                        "This disclosure presents a code construction for error-correcting WOM codes. The code construction scheme may support any number of rewrites and can correct a substantial number of errors.",
                        "For example, a memory may have N binary cells, where every cell has two charge levels: 0 and 1. The cell-programming method can only change a cell from 0 to 1, but not from 1 to 0. However, noise can change a cell in both directions: from 0 to 1, and from 1 to 0.",
                        "The coding for the cell programming has two functions: (1) Rewrite data, which means to store new data that replace old data, and (2) Correct errors. In some embodiments, a coding method may support t writes, where each write is also called a rewrite, and where t is an integer parameter greater than or equal to two.",
                        "After a write of data, noise may appear in the cell levels, and certain embodiments of cell programming can correct errors and recover the data stored by the latest write. In some embodiments, each of the writes may use substantially the same process.",
                        "As an example, let (s1, s2, . . . , sN) be a binary vector that represent the levels of the N binary cells before a write. Let (s\u20321, s\u20322, . . . , s\u2032N) be a binary vector that represent cell levels of the N binary cells after this write. In addition, let (b1, b2, . . . , bM) be a binary vector that represents the data to be written, where the data has M bits. Note the following constraints or conditions:\n\n\n- - 1) For i=1, 2, . . . ,N, s\u2032i is greater than or equal to si. This is\n    because the cell-programming method increases a cell's level, but\n    may not decrease it.\n  - 2) M is an integer parameter known to the system. Its value can be\n    the same or different for the writes.\n  - 3) The cell levels (s**1**, s**2**, . . . , sN) can be different\n    from the cell levels right after the previous rewrite, because noise\n    may have changed the cell levels since the previous rewrite.",
                        "To write the data (b1, b2, . . . , bM), the method may have the following inputs:\n\n\n- - (1) The current cell levels (s**1**, s**2**, . . . , sN), and\n  - (2) The new data to store (b**1**, b**2**, . . . , bM).",
                        "Based on the inputs from (1) and (2), the method computes the output (s\u20321, s\u20322, . . . , s\u2032N), and programs the cells to the new levels with the following constraints:\n\n\n- - 1) For i=1,2, . . . ,N, s\u2032i is greater than or equal to si.\n  - 2) The new cell levels (s\u2032**1**, s\u2032**2**, . . . , siN) represents\n    the new data (b**1**, b**2**, . . . , bM), according to the mapping\n    specified by the method.",
                        "FIG. 1 is a block diagram illustrating an example write process in accordance with some embodiments. The write process of FIG. 1 includes error correction, for example, as described above. Data to be stored in the memory is included with the frozen set for WOM channel 26, and is provided to the polar encoder 27. The polar encoder 27 generates a polar codeword 28, which is provided to a set of WOM channel device 29. The WOM channel devices 29 determine cell levels to be written into the WOM.",
                        "Data to be stored in the memory is included with the frozen set for WOM channel 26, and data of the frozen set for WOM channel 26 is provided to the polar encoder 27. In addition, additional data 31 is provided to the polar encoder 27. In the embodiment of FIG. 1, the additional data 31 is a frozen set for a binary symmetric channel (BSC) channel. The polar encoder 27 generates the polar codeword 28 based on the data of the frozen set for WOM channel 26 and the additional data 31 of the frozen set for the BSC channel. The additional data 31 allows for the polar encoder 27 to generate a polar codeword 28 which includes data for error correction. The poplar encoder 27 generates the polar codeword 28 according to embodiments and example features of encoding schemes discussed in further detail below. As discussed below, the encoding schemes allow for the WOM to be written with error correction.",
                        "The polar codeword 28 is provided to a set of WOM channel devices 29, which determine cell levels to be written into the WOM. The WOM channel devices 29 determine the cell levels such that the new state of the WOM includes the data of the frozen set and such that the only cell level changes in the WOM are from the 0 state to the 1 state. Embodiments of WOM channel devices are described below in further detail.",
                        "FIG. 2 is a flow diagram that shows example operations of a method that may be performed by a device for encoding a data value to be encoded into a codeword for rewriting the WOM in accordance with some embodiments. The device may comprise an external data storage device such as a flash memory device that receives data from a host device, such as a computer, and stores the data in accordance with error correction encoding schemes discussed below. For example, the device may comprise an encoder for the purpose of processing data values and producing corresponding codewords.",
                        "The method of FIG. 2 may include one or more operations, functions, or actions as illustrated by one or more of blocks 1002, 1004, and/or 1006. Although the blocks are illustrated in a sequential order, these blocks may also be performed in parallel, and/or in a different order than those described herein. Also, the various blocks may be combined into fewer blocks, divided into additional blocks, and/or eliminated based upon the particular implementation. Additional blocks may be provided that represent other operations, functions, or actions.",
                        "The method shown in FIG. 2 may begin in block 1002 \u201cdetermine current cell levels.\u201d Block 1002 may be followed by block 1004 \u201cgenerate next cell levels,\u201d and block 1004 may be followed by block 1006 \u201cwrite next cell levels into memory.\u201d",
                        "In the first operation, represented by the flow diagram block 1002, current cell charge levels are determined. As discussed above, writing data into memory causes cell levels to change unidirectionally, for example, 0 to 1, but not 1 to 0. Accordingly, to determine which memory cells to change from 0 to 1, the current cell levels are determined.",
                        "In the next encoding operation, indicated by block 1004, next cell charge levels are generated based on the data to be written and on the current cell levels. Examples of techniques for determining next cell levels are discussed in further detail below. At block 1006, the next cell charge levels are written into the memory. For example, the next cell levels may be stored into memory cells of a data device, or maybe provided to a memory of a host device, or may be transmitted to an external destination.",
                        "As a result, the rewriting method enable new data to be stored in cells (to replace old data) two or more times without decreasing cell levels. In addition, an error correction method enables the most recently written data to be recovered even though noise may have changed the levels of some of the cells.",
                        "In particular, the rewriting operation takes the current cell levels (s1, . . . , sN) and the new data (b1, . . . , bM) as input, and computes new cell levels (s\u20321, . . . , s\u2032N), where For i=1, . . . , N, s\u2032i is greater than or equal to si. In addition, the new cell-level vector (s\u20321, . . . , s\u2032N) represents the new data (b1, b2, . . . , bM), according to the mapping specified by the method. Accordingly, given the new cell levels (s\u20321, . . . , s\u2032N), the decoding algorithm can uniquely determine the value of the new data (b1, . . . , bM).)",
                        "In some embodiments, to generate the next cell levels such as in block 1004, the method may use a binary matrix AN\u00d7N=(ai,j)N\u00d7N of N rows and N columns, whose value is fixed and known to the system. For example, for i=1, . . . ,N and j=1, . . . ,N, ai,j\u2208{0,1} is the bit in the i-th row and j-th column of the matrix AN\u00d7N. Furthermore, the method may use a subset of {1, 2, . . . ,N} denoted by FWOM, and another subset of {1,2, . . . ,N} denoted by FC to generate the next cell levels, such that:",
                        "FC contains at least one element. That is, |FC| is greater than or equal to 1,",
                        "There are M elements in FWOM but not in FC, that is, |FWOM\u2212FC|=M,",
                        "At least one element of {1, 2, . . . ,N} is neither in FWOM nor in FC. That is, |{1, 2, . . . ,N}\u2212FWOM\u2212FC| is greater than or equal to 1.",
                        "FC is a subset of FWOM. That is, FC \u2208FWOM.",
                        "Furthermore, in some embodiments, to generate the next cell levels, the method may use a binary vector (g1, g2, : : : , gN) called a dither, whose value is known to the system. The value of the dither can be the same or different for each of the rewrites. Two other binary vectors (v1, v2, . . . , vN) and (v\u20321, v\u20322, . . . , v\u2032N ) may be determined as follows:",
                        "For i=1, . . . ,N, vi=si\u2295gi is called the value of the i-th cell before the write. Here \u2295 is the exclusive-OR operation.",
                        "For i=1, . . . ,N, v\u2032i=s\u2032i\u2295gi is called the value of the i-th cell after the write.",
                        "Furthermore, let A\u22121N\u00d7N be the inverse of the matrix AN\u00d7N, and let (u1, u2, . . . , uN) be the binary vector (u1, u2, . . . , uN)=(v\u20321, v\u20322, . . . , v\u2032N) A\u22121N\u00d7N. In addition, the vector (u1, u2, . . . , uN) may have the following properties:",
                        "The value of the bits {ui|1\u2266i\u2266N, i\u2208FWOM\u2212FC}\u2014namely those bits in (u1, . . . , uN) whose indices are in FWOM FC\u2014equals the value of the data (b1, , bM).",
                        "The value of the bits {ui|i\u2208FC} is a constant (such as all 0s or any other fixed value) known to the system.",
                        "The value of the bits {ui|1\u2266i\u2266N, i\u2260FWOM\u2212FC} is computed by the method for rewriting.",
                        "In some embodiments, the number of cells whose levels are change from 0 to 1 by the rewriting method is minimized or otherwise reduced. Accordingly, the method may minimize or otherwise reduce the value of \u03a3i=1N s\u2032i\u2212si.",
                        "In some embodiments, the method may use the following 1st probabilistic model to describe the relationship between cell levels (s1, . . . , sN) and (s\u20321, . . . s\u2032N). Let",
                        "\\({\\alpha = {1 - {\\sum\\limits_{i = 1}^{N}\ue89e\\; \ue89e\\frac{s_{1}}{N}}}},\\)\n\n\n- and let \u2208\u2208\\[0, 1\\] be a real-number parameter whose value is known to\n  the system. For i=1, . . . ,N,",
                        "\\({{{\\Pr \ue89e\\left\\{ {s_{i} = {{0\ue85cs_{i}^{\\prime}} = 0}} \\right\\}} = 1},{and}}\ue89e\\mspace{14mu}\\)\n\\({\\Pr \ue89e\\left\\{ {s_{i} = {{1\ue85cs_{i}^{\\prime}} = 0}} \\right\\}} = 0.\\)\n\\({{{\\Pr \ue89e\\left\\{ {s_{i} = {{0\ue85cs_{i}^{\\prime}} = 1}} \\right\\}} = \\frac{\\alpha \ue89e\u025b}{{\\alpha \u025b} + 1 - \\alpha}}\ue89e\\mspace{11mu},\\; \ue89e{and}}\ue89e\\mspace{14mu}\\)\n\\({\\Pr \ue89e\\left\\{ {s_{i} = {{1\ue85cs_{i}^{\\prime}} = 1}} \\right\\}} = {\\frac{1 - \\alpha}{{\\alpha \u025b} + 1 - \\alpha}.}\\)",
                        "In some embodiments, the method may use the new cell levels (s\u20321, . . . , s\u2032N) as the vector that maximizes or otherwise increases the value Pr{(s\u20321, . . . , s\u2032N)|(s1, . . . , sN)}.",
                        "In some embodiments, the method may choose the new cell levels (s\u20321, . . . , s\u2032N) as the vector that maximizes or otherwise increases the value Pr{(s1, . . . , sN)|(s\u20321, . . . , s\u2032N)}.",
                        "In some embodiments, to generate the next cell levels, the method may compute the value of bits u1, u2, . . . , uN sequentially, and subsequently computes the value of cell levels (s\u20321, . . . , s\u2032N) as (s\u20321, . . . , s\u2032N)=(v\u20321, . . . , v\u2032N)\u2295(g1, . . . , gN)=(u2, . . . , uN)\u00b7A\u22121N\u00d7N\u2295(g1, . . . , gN). For i=1, . . . , N, the method computes the following:",
                        "1: If i\u2208FWOM\u2212FC and i is the j-th element in FWOM\u2212FC ( for j\u2208{1, 2, . . . M}), let ui=bj (the j-th bit in the new data). Otherwise, go to step 2.",
                        "2. If i\u2208FC, let \u03bci be the constant value specified previously (such as the value 0). Otherwise, go to step 3.",
                        "3. If i\u2208{1, 2, . . . , N}\u2212FWOM, let \u03bci take the value that maximizes the value of Pr{\u03bci|(s1, \u03bd1), . . . , (sN, \u03bdN), \u03bc1, . . . , \u03bci\u22121} assuming that each of \u03bci+1, . . . , \u03bcN is equally likely to be 0 and 1.",
                        "In some embodiments, the method may use the following 2nd probabilistic model to describe the relationship between vectors (v\u20321, . . . , v\u2032N) and ((s1,v1), . . . , (sn,vn)). For I=1, . . . , N.\n\n\n- Pr((s_(i), \u03bd_(i))=(1,0)\\|\u03bd\u2032_(i)=0)=1\u2212\u03b1, Pr((s_(i),\n  \u03bd_(i))=(0,0)\\|\u03bd\u2032_(i)=0)=\u03b1(1\u2212\u03b5), Pr((s_(i), \u03bd_(i))=(0,1)\\|\u03bd\u2032_(i)=0)=\u03b1\u2208,\n  Pr((s_(i), \u03bd_(i))=(1,1)\\|\u03bd\u2032_(t)=0)=0,\n- Pr((s_(i), \u03bd_(i))=(1,0)\\|\u03bd\u2032_(t)=1)=0, Pr((s_(i),\n  \u03bd_(i))=(0,0)\\|\u03bd\u2032_(i)=1)=\u03b1\u2208, Pr(s_(i), \u03bd_(i))=(0,1)\\|\u03bd_(i)=1=\u03b1(1\u2212\u03b5),\n  Pr((s_(i), \u03bd_(i))=(1,1)\\|\u03bd\u2032_(i)=1)=1\u2212\u03b1.",
                        "In some embodiments, the method may choose the new cell levels (s\u20321, . . . , s\u2032N) as the vector that maximizes or otherwise increases the value Pr{(s\u20321, . . . , s\u2032N)|(s1, . . . , sN)}.",
                        "In some embodiments, the method may choose the new cell levels (s\u20321, . . . , s\u2032N) as the vector that maximizes or otherwise increases the value Pr{(s1, . . . , sN)|(s\u20321, . . . , s\u2032N)}.",
                        "In some embodiments, the method may compute the value of bits u1, u2, . . . , uN sequentially, and subsequently computes the value of levels (s\u20321, . . . , s\u2032N) as (s\u20321, . . . , s\u2032N)=(v\u20321, . . . , v\u2032N) \u2295(g1, . . . , gN)=(u2, . . . , uN)\u00b7A\u22121N\u00d7N\u2295\u2295(g1, . . . , gN). For i=1, . . . , N the method may compute the following:",
                        "1: If i\u2208FWOM\u2212FC and i is the j-th element in FWOM\u2212FC (for j\u2208{1,2, . . . , M}), let ui=bj (the j-th bit in the new data). Otherwise, go to step 2.",
                        "2: If i\u2208FC, let ut be the constant value specified previously (such as the value 0. Otherwise, go to step 3.",
                        "3: If i\u2208{1,2, . . . , N}\u2212FWOM, let \u03bci take the value that maximizes the value of Pr{\u03bci|(s1, \u03bd1), . . . , (sN, \u03bdN), \u03bc1, . . . , \u03bci\u22121} assuming that each of \u03bci+1, . . . , \u03bcN is equally likely to be 0 and 1.",
                        "In some embodiments, the matrix AN\u00d7N, may be specified as follows. Let m be a positive integer, and let N=2m, Let G2=",
                        "\\({{G\ue89e\\; \ue89e2} = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}},\\)\n\n\n- and let A_(N\u00d7N)=G\u2082^(\u2295m) be the m-th Krobecker product of G\u2082.",
                        "In some embodiments, the dither may be a pseudo-random number, which can be generated by a pseudo-random-number generator using a seed number as input. The seed number may be stored in the system.",
                        "In some embodiments, the method may compute the value of bits u1, u2, . . . ,uN sequentially, and subsequently computes the value of cell levels (s\u20321, . . . , s\u2032N) as (s\u20321, . . . s\u2032N) \u20321, . . . , v\u2032N)\u2295(g1, . . . ,gN)=(u2, . . . , uN)\u00b7A\u22121N\u00d7N\u2295\u2295(g1, . . . , gN). For i=1, . . . , N, the method may compute the following::\n\n\n- Step 1: Let y=(y\u2081, y\u2082. . . , y_(N))=((s\u2081, \u03bd\u2081), (s\u2082, \u03bd\u2082, . . . . ,\n  (s_(N), \u03bd_(N))) be a vector of N elements, where every element\n  y_(i)=(s_(i), \u03bd_(i)) is a pair of bits.\n- Step 2: Let J=(j\u2081, j\u2082), . . . j_(M))=F_(WOM)\u2212F_(C) where j\u2081\\<j\u2082\\< . .\n  . \\<j_(m). Let u_(FWOM\u2212FC)=(u_(j1), u_(j2), . . . , u_(jM)).\n- For I=1, . . . , M, let u_(ji)=b_(t).\n- Step 3: For every i\u2208F_(C), let u_(i)=0.\n- Step 4: Compute the values of W_(N)^(i)(y, (u\u2081, u\u2082, . . . ,\n  u_(i\u22121))\\|u_(i\u22121)\\|u_(i)=0) and W_(N)^(i)(y, (u_(j1), u_(j2), . . . ,\n  u_(i\u22121)\\|u_(i)=1) for i=1,2, . . . , N as follows:\n- Depending on the parity of i, the value of W_(N)^(i) is recursively\n  evaluated through one of the formulae below (beginning with n=N/2):",
                        "\\(\\begin{matrix}\n{W_{2\ue89en}^{{2\ue89ei} - 1}\ue8a0\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{{\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)\ue89e\\left. \uf603u_{{2\ue89ei} - 1} \\right)} = {\\sum\\limits_{u_{{2\ue89ei} \\in {({0,1})}}}^{\\;}\ue89e\\; \ue89e{{\\frac{1}{2}\ue89e{W_{n}^{i}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{n}} \\right),{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\ominus \\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)}}\uf604 \\right.}\ue89eu_{{2\ue89ei} - 1}} \\ominus u_{2\ue89ei}}}}} \\right)} & (1) \\\\\n{{W_{n}^{i}\ue8a0\\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603u_{2\ue89ei} \\right)},{{W_{2\ue89en}^{2\ue89ei}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)}\uf604 \\right.}\ue89eu_{2\ue89ei}}} \\right)} = {\\frac{1}{2}\ue89e{W_{n}^{i}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\oplus {\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603{u_{{2\ue89ei} - 1} \\oplus u_{2\ue89ei}} \\right)\ue89e{W_{n}^{i}\ue8a0\\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e{\uf603u_{2\ue89ei}}}} \\right)}}}} \\right.}}} & (2)\n\\end{matrix}\\)\n\n\n- with the base cases",
                        "W11((1,0), (*)|0)=1\u2212\u03b1",
                        "W11((0,0), (*)|0)=\u03b1(1\u2212\u2208)",
                        "W11((0,1), (*)|0)=\u03b1\u2208",
                        "W11((1,1), (*)|0)=0",
                        "W11((1,0), (*)|1)=0",
                        "W11((0,0), (*)|1)=\u03b1\u2208",
                        "W11((0,1), (*)|1)=\u03b1(1\u2212\u2208)",
                        "W11((1,1), (*)|1)=1\u2212\u03b1.\u2003\u2003(3)\n\n\n- where (\\*) denotes an empty vector. The operator {circle around (l)}\n  between two binary vectors denotes the element-wise exclusive-OR\n  computation. The operator \u2296 between two bits denotes the binary\n  exclusive-OR computation.  \n  Step 5: For i=1, 2, . . . N, if i\u2209F_(WOM), then do the following:\n- Step 5.1: Let L_(N)^(i) (y, (u\u2081, u\u2082, . . . , u_(i\u22121))) take the value\n- W_(N)^(i) (y, (u\u2081, u\u2082, . . . , u_(i\u22121))\\|u_(i)=0)/W_(N)^(i)(y, (u\u2081,\n  u\u2082, . . . u_(i\u22121))\\|u_(i)=1).\n- Step 5.2: Let u_(i) take the value 0 with probability",
                        "\\(\\frac{L_{i}^{N}\ue8a0\\left( {y,\\left( {u_{1},{u_{2,}\ue89e\\ldots}\ue89e\\mspace{14mu},u_{i - 1}} \\right)} \\right)}{1 + {L_{N}^{i}\ue8a0\\left( {y,\\left( {u_{1},{u_{2,}\ue89e\\ldots}\ue89e\\mspace{14mu},u_{i - 1}} \\right)} \\right)}}\\)\n\n\n- and take the value 1 probability",
                        "\\(\\frac{1}{1 + {L_{N}^{i}\ue8a0\\left( {y,\\left( {u_{1},{u_{1,}\ue89e\\ldots}\ue89e\\mspace{14mu},u_{i - 1}} \\right)} \\right)}}.\\)\n\n\n- Step 6: Let (\u03bd\u2032\u2081, \u03bd\u2032\u2082, . . . , \u03bd\u2032_(N))=(u\u2081, u\u2082, . . . , u_(N))\n  A_(N\u00d7N);\n- Step 7: Let (s\u2032\u2081, s\u2032\u2082, . . . , s\u2032_(N))=(\u03bd\u2032\u2081\u2295g\u2081, \u03bd\u2032\u2082\u2295g\u2082, . . . ,\n  \u03bd\u2032_(N)\u2295g_(N)).\n- Step 8: Check if s\u2032\u2081\u2267s_(i) for i=1, . . . , N. If yes, store the seed\n  number used to generate the dither (g\u2081, . . . , g_(N)) in the system,\n  and let (s\u2032\u2081, . . . , s\u2032_(N)) be the new cell levels; otherwise, use a\n  new seed number to generate a new value for the dither (g\u2081, . . . ,\n  g_(N)), and return to Step 1 to repeat the computation.",
                        "In some embodiments, the matrix AN\u00d7N may be the generating matrix of a polar code, and FWOM may be contained in the frozen set of the polar code corresponding to the channel described by the transition 2nd probabilistic model, where the channel has v\u2032i as the channel input and (si, vi) as the channel output.",
                        "In some embodiments, FWOM may be determined as follows:",
                        "For i=1,2, ,N, let z denote ((y1, y2, , yN), (u1, u2, , ui\u22121)), and compute a value",
                        "\\({{FER}\ue8a0\\left( W_{N}^{i} \\right)} = {{\\sum\\limits_{z:{{W_{N}^{i}\ue8a0{({z\ue85c0})}} < {W_{N}^{i}\ue8a0{({z\ue85c1})}}}}^{\\;}\ue89e\\; \ue89e{W_{N}^{i}\ue8a0\\left( {z\ue85c0} \\right)}} + {\\sum\\limits_{{z:{W_{N}^{i}\ue8a0{({z\ue85c0})}}} = {W_{N}^{i}\ue8a0{({z\ue85c1})}}}^{\\;}\ue89e{\\frac{1}{2}\ue89e{{W_{N}^{i}\ue8a0\\left( {z\ue85c0} \\right)}.}}}}\\)\n\n\n- Where W_(N)^(i)(z\\|0) and W_(N)^(i)(z\\|1) computed as discussed below.\n  In addition, let \u0394R be a real number parameter greater than zero.\n  Furthermore, let\n- F_(WOM)={j\u2081, j\u2082, . . . , j_(N)(\u03b1H(\u03b5)\u2212\u0394R)} be a subset of {1,2, . . . ,\n  N} with cardinality N((\u03b1H(\u03b5)\u2212\u0394R), such that all values in\n  {FER(W_(N)^(i))\\|i\u2208F_(WOM) } are greater than or equal to each value\n  in {FER(W_(N)^(i))\\|i\u2208{1, . . . , N}\u2212F_(WOM)}.",
                        "In some embodiments, the matrix AN\u00d7N may be the generating matrix of a polar code.",
                        "After the rewrite described above, which changes cell levels to (s\u20321, s\u20322, . . . , s\u2032N) to store the data (b1, b2, . . . , bM), noise may appear in the cells and change the cell levels to (c1, c2, . . . , CM), where ci is a bit that is not necessarily equal to s\u2032i. The error-correction method takes the noisy cell levels (c1, c2, . . . , CM) as input, and outputs the stored data (b1, b2, . . . , bM).",
                        "FIG. 3 is a flow diagram that shows example operations of a method performed by a device for decoding cell level values received from the WOM to generate a data value as part of a read operation, in accordance with some embodiments. The device may comprise an external data storage device such as a flash memory device that receives data from a host device, such as a computer, and stores the data in accordance with an error correction encoding and decoding scheme schemes discussed below. For example, the device may comprise a decoder for the purpose of processing cell level values and producing corresponding data values.\n\n\n- The method of FIG. 3 may include one or more operations, functions, or\n  actions as illustrated by one or more of blocks **2002**, **2004**,\n  and/or **2006**. Although the blocks are illustrated in a sequential\n  order, these blocks may also be performed in parallel, and/or in a\n  different order than those described herein. Also, the various blocks\n  may be combined into fewer blocks, divided into additional blocks,\n  and/or eliminated based upon the particular implementation. Additional\n  blocks may be provided that represent other operations, functions, or\n  actions.\n- The method shown in FIG. 3 may begin in block **2002** \u201creceive cell\n  level values.\u201d Block **2002** may be followed by block **2004**\n  \u201cgenerate data value,\u201d and block **2004** may be followed by block\n  **2006** \u201cprovide data value to data destination.\u201d",
                        "In the first operation, represented by the flow diagram block 2002, a set of cell level values to be decoded is retrieved from the WOM.",
                        "In the next decoding operation, indicated by block 2004, the set of values is decoded to generate the corresponding data value. Examples of techniques for decoding are discussed in further detail below. At block 2006, the data value is provided to a data destination, such as a host computer. For example, the data value may be transmitted by a transmitter to the data destination.",
                        "In particular, to generate the data value, the decoding or error correction function may use a binary vector (u\u20321, . . . , 1\u2032N) and has the following properties:\n\n\n- Property 1: For any i\u2208F_(C), u\u2032_(i) is given the fixed bit value that\n  has been assigned to u_(i) (which is know in the system).\n- Property 2: Among all the values that satisfy Property 1, the value\n  assigned to (u\u2032\u2081, . . . , u\u2032_(N)) maximizes the probability that \u201cthe\n  noise changed the codeword from (s\u2032\u2081, . . . , s\u2032_(N))=(u\u2032\u2081, . . . ,\n  u\u2032_(N))A_(N\u00d7N)\u2295(g\u2081, . . . , g_(N)) to (c\u2081, . . . , c_(N)).\u201d",
                        "The probability may be determined by the errors' probabilistic characteristic. Accordingly, for every i\u2208FWOM\u2212FC a data bit bj is recovered as u\u2032i, where bj was assigned to ui for the most recent rewrite.",
                        "In some embodiments, to generate the data value, the method may use a binary matrix AN\u00d7N=(ai,j)N\u00d7N of N rows and N columns, whose value is fixed and known to the system. For example, for i=1, . . . ,N and j=1, ,N ai,j\u2208{0,1} is the bit in the i-th row and j-th column of the matrix AN\u00d7N. Furthermore, the method may use a subset of {1,2, . . . , N} denoted by FWOM, and another subset of {1,2, ,N} denoted by FC, such that:",
                        "FC contains at least one element. That is, |FC| is greater than or equal to 1,",
                        "There are M elements in FWOM but not in FC, that is, |FWOM\u2212FC|=M,",
                        "At least one element of {1,2, . . . ,N} is neither in FWOM nor in FC. That is, |{1, 2, . . . ,N}\u2212FWOM\u2212FC| is greater than or equal to 1.",
                        "FC is a subset of FWOM. That is, FC\u2208FWOM.",
                        "Furthermore, in some embodiments, the errors in the cells may have the following distribution:\n\n\n- Let p\u2080 and p\u2081 be two real-number parameters between 0 and 1. For i=1,\n  . . . , N, we have Pr{c_(i)=0\\|s\u2032_(i)=0}\u2250Pr{0\\|0}=1\u2212p\u2080,\n  Pr{c_(i)=1\\|s\u2032_(i)=0}\u2250Pr{1\\|0}=p\u2080, Pr{c_(i)=0\\|s\u2032_(i)=1}\u2250Pr{0\\|1}=p\u2081\n  and Pr{c_(i)=1\\|s\u2032_(i)=1}\u2250Pr{1\\|1}=1\u2212p\u2081.",
                        "In such embodiments, binary vector ((u\u20321, . . . , 1\u2032N) may have the following properties:\n\n\n- Property 1: For any i\u2208F_(C), u\u2032_(i) is given the fixed bit value that\n  has been assigned to u_(i) (which is know to the system).\n- Property 2: Among all the values that satisfy Property 1, the value\n  assigned to (u\u2032\u2081, . . . u\u2032_(N)) maximizes the value of \u03a0_(i=1)^(N)\n  Pr{c_(i)\\|\u03b1_(i)}, where \u03b1_(t) denotes the ith bit in the vector (u\u2032\u2081,\n  . . . u\u2032_(N)) A_(N\u00d7N)\u2295(g\u2081, . . . g_(N)).",
                        "In some embodiments, the matrix AN\u00d7N may be the generating matrix of a polar code, and p is a real number parameter between zero and one. The method may correct errors and may recover the data values (b1, b2, . . . , bM) as follows:",
                        "1: Recovering the value of (\u03bd\u20321, . . . , \u03bd\u2032N) using a decoding algorithm of an error-correcting polar code based on the following setting:\n\n\n- The polar code's generating matrix is A_(N\u00d7N).\n- The polar code encodes the user data (u\u2081, . . . , u_(N)) into the\n  codeword (\u03bd\u2032\u2081, . . . , \u03bd\u2032_(N)) via the formula (\u03bd\u2032\u2081, . . . ,\n  \u03bd\u2032_(N))=(u\u2081, . . . , u_(N))A_(N\u00d7N).\n- For i=1, . . . , N, the codeword bit \u03bd\u2032\u2081 is transmitted through a\n  binary-symmetric channel with transition probability p; and the output\n  of that binary-symmetric channel is the noisy codeword bit c_(i).\n- The frozen set of the polar code corresponding to the binary-symmetric\n  channel is contained in F_(C); and when encoding user data into the\n  codeword, the user-data bits in F_(C) are fixed at known values (such\n  as all 0's).\n- The decoding algorithm considers (c\u2081, . . . , c_(N)) as the noisy\n  codeword, and recovers the correct value of the original codeword\n  (\u03bd\u2032\u2081, . . . , \u03bd\u2032_(N)).",
                        "2: Let (u\u20321, . . . , u\u2032N)=(\u03bd\u20321, . . . , \u03bd\u2032N)AN\u00d7N\u22121. For every i\u2208FWOM\u2212FC, \u2014say bj was assigned to ui for the most recent rewrite, \u2014we recover the data bit bj as u\u2032i.",
                        "In some embodiments, to generate the data value, the decoding algorithm also may include computing the value of ui for i=1, . . . , N as follows:\n\n\n- If i\u2208F_(C), let u_(i) be the constant value that was assigned to it by\n  the previous rewrite.\n- If i\u2209F_(C), let u_(i) take the value that maximizes the value of\n  Pr{u_(i)\\|c\u2081, . . . , c_(N), u\u2081, . . . , u_(i\u22121)} assuming that each\n  of u_(i+1), . . . , u_(N) is equally likely to be 0 and 1.",
                        "In some embodiments, the decoding algorithm may be a list-decoding algorithm that is further specified as follows: Let L be a positive integer parameter that indicates the size of a list, where each clement in the list is an assignment of value to (u1, u2, . . . , ui\u22121) before the value of ui is computed. For i=1, . . . , N, the decoding algorithm computes the value of ui with the following:\n\n\n- If i\u2208F_(C), let u_(i) be constant value that was assigned to it by the\n  previous rewrite.\n- If i\u2209F_(C), for each element in the list (which is an assignment of\n  value to (u\u2081, u\u2082, . . . , u_(i\u22121))), append to it the value assignment\n  u_(i)=0, and also append to it the value assignment u_(i)=0, and also\n  append to it the value assignment u_(i)=1, thus converting that\n  element into two new elements in the list. If the list now contains\n  more than L elements, keep only the L elements that are most likely in\n  the list. The likelihood of an element in the list may be computed as\n  Pr{c\u2081, . . . c_(N)\\|u\u2081, . . . , u_(i)} assuming that each of u_(i+1),\n  . . . , u_(N) is equally likely to be 0 and 1.",
                        "The most likely element in the list may then be chosen as the recovered value for (u1, . . . , uN).",
                        "In some embodiments, the stored data (b1, . . . , bM) may itself be an error-correcting code C and therefore may contain redundancy. The decoding algorithm, in 1 may be further specified as follows:\n\n\n- Let L be a positive integer parameter that indicates the size of a\n  list, where each element in the list is an assignment of value to\n  (u**1**, u**2**, . . . , ui\u22121) before the value of ui is computed .\n  For i=1, . . . , N, the decoding algorithm computes the value of ui\n  with the following:",
                        "If i\u2208FC, let ui be the constant value that was assigned to it by the previous write.",
                        "If i\u2209FC, for each element in the list (which is an assignment of value to (u1, u2, . . . , ui\u22121)), append to it the value assignment ui=0, and also append to it the value assignment ui=0, thus converting that element into two new elements in the list. If the list now contains more than L elements, keep only the L elements that are most likely in the list. The likelihood of an element in the list may be computed as Pr{c1, . . . , cN|u1, . . . , ui} assuming that each of ui+1, . . . , uN is equally likely to be 0 and 1.",
                        "Then, for each element in the list, the method checks if its value assignment to (ui|i\u2208FWOM\u2212FC), which should equal (b1, . . . , bM), is a valid codeword in the error-correcting code C; and if not, remove it from the list. Then, the method may choose the most likely element in the remaining list as the recovered value for (u1, . . . , uN).",
                        "In some embodiments, the decoding algorithm may be based on a belief-propagation decoding algorithm for polar error-correcting codes.",
                        "In some embodiments, the matrix AN\u00d7N may be specified as follows. Let m be a positive integer, and let N=2m. Let G2=",
                        "\\({{G\ue89e\\; \ue89e2} = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}},\\)\n\n\n- , and let A_(N\u00d7N)=G\u2082^(\u2295m) be the m-th Kronecker product of G\u2082.",
                        "In some embodiments, recovering the value action discussed above may further include the following:",
                        "1: Let y=(y1, y2, . . . , yN)=((c1\u2295g1), (c2\u2295g2) . . . , (cN \u2295gN)) be a vector of N elements, where every element yi=ci\u2295gi is a bit.",
                        "2: For every i\u2208FC, let ui32 0.",
                        "3: Compute the values of WNi(y,(u1, u2, . . . , u1\u22121)|ui=0) and WNi(y, (u1, u2, . . . , ui\u22121)|ui=1) for i=1,2, . . . N as follows:\n\n\n- Depending on the parity of i, the value of W_(N)^(i) is recursively\n  evaluated through one of the formulae below (beginning with n=N/2):",
                        "\\(\\begin{matrix}\n{W_{2\ue89en}^{{2\ue89ei} - 1}\ue8a0\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{{\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)\ue89e\\left. \uf603u_{{2\ue89ei} - 1} \\right)\ue89e{\\sum\\limits_{u_{{2\ue89ei} \\in {({0,1})}}}^{\\;}\ue89e\\; \ue89e{\\frac{1}{2}\ue89eW_{n}^{i}}}} = {{\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{n}} \\right),{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\ominus \\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)}}\uf604 \\right.\ue89eu_{{2\ue89ei} - 1}} \\ominus u_{2\ue89ei}}}} \\right)} & (5) \\\\\n{{W_{n}^{i}\ue8a0\\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603u_{2\ue89ei} \\right)},{W\ue89e\\frac{2\ue89ei}{2\ue89en}\ue89e\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)}\uf604 \\right.\ue89eu_{2\ue89ei}}} \\right)} = {\\frac{1}{2}\ue89e{W_{n}^{i}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\oplus {\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603{u_{{2\ue89ei} - 1} \\oplus u_{2\ue89ei}} \\right)\ue89e{W_{n}^{i}\ue8a0\\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e{\uf603u_{2\ue89ei}}}} \\right)}}}} \\right.}}} & (6)\n\\end{matrix}\\)\n\n\n- with the base cases",
                        "W11((0), (.)|0)=1\u2212p",
                        "W11((1), (.)|0)=p",
                        "W11((0), (.)|1)=p",
                        "W11((1), (.)|1)=1\u2212p\u2003\u2003(7)\n\n\n- where (.) denotes an empty vector. The operator \u2295 between two binary\n  vectors denotes the element-wise exclusive-OR computation. The\n  operator \u2295 between two bits denotes the binary exclusive-OR\n  computation. 4: For each i\u2208F_(WOM)\u2212F_(C), if\n- W_(N)^(i)(y\u2081, y\u2082, . . . , y_(N)), (u\u2081, u\u2082, . . .\n  u_(i\u22121))\\|u_(i)=0)\u2267W_(N)^(i)(y\u2081, y\u2082, . . . y_(N)), (u\u2081, u\u2082, . . . ,\n  u_(i\u22121))\\|u_(i)=1), let u_(i)=0; otherwise, let u_(i)=1",
                        "5: Let {ui|i\u2208FWOM\u2212FC} be the recovered value for the data (b1, . . . , bM), where the mapping from the bits in {ui|i\u2208FWOM\u2212FC} to the bits in (b1, . . . , bM) is as specified in the previous rewrite operation.",
                        "In some embodiments, the method may be a list-decoding algorithm further specified as follows:\n\n\n- Let L be a positive integer parameter that indicates the size of a\n  list, where each element in the list is an assignment of value to\n  (u**1**, u**2**, . . . ,ui\u22121) before the value of ui is computed. In\n  addition, the method may include the following:",
                        "1: Let y=(y1y2, . . . , yn)=((c1\u2295g1), (c2\u2295g2), . . . , (cN\u2295gN)) be a vector on N elements, where every element yi=ci\u2295gi is a bit.",
                        "2: For every i\u2208FC, let ui=0.",
                        "3: Compute the values of WNi(y,(u1, u2, . . . , ui\u22121)|ui=0) and WNi(y,(u1, u2, . . . , ui\u22121)|ui=1) for i=1,2, . . . , N as follows:\n\n\n- - Depending on the parity of i, the value of W_(N)^(i) is recursively\n    evaluated through one of the formulae below (beginning with n=N/2):",
                        "\\(\\begin{matrix}\n{W_{2\ue89en}^{{2\ue89ei} - 1}\ue8a0\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{{\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)\ue89e\\left. \uf603u_{{2\ue89ei} - 1} \\right)\ue89e{\\sum\\limits_{u_{{2\ue89ei} \\in {({0,1})}}}^{\\;}\ue89e\\; \ue89e{\\frac{1}{2}\ue89eW_{n}^{i}}}} = {{\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{n}} \\right),{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\ominus \\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)}}\uf604 \\right.\ue89eu_{{2\ue89ei} - 1}} \\ominus u_{2\ue89ei}}}} \\right)} & (8) \\\\\n{{W_{n}^{i}\ue8a0\\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603u_{2\ue89ei} \\right)},{{W_{2\ue89en}^{2\ue89ei}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)}\uf604 \\right.}\ue89eu_{2\ue89ei}}} \\right)} = {\\frac{1}{2}\ue89e{W_{n}^{i}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\oplus {\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603{u_{{2\ue89ei} - 1} \\oplus u_{2\ue89ei}} \\right)\ue89eW_{n}^{i}}} = \\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e{\uf603u_{2\ue89ei}}}} \\right)}} \\right.}}} & (9)\n\\end{matrix}\\)\n\n\n- with the base cases",
                        "W11((0), (.)|0)=1\u2212p",
                        "W11((1), (.)|0)=p",
                        "W11((0), (.)|1)=p",
                        "W11((1), (.)|1)=1\u2212p\u2003\u2003(10)\n\n\n- where (.) denotes an empty vector. The operator \u2295 between two binary\n  vectors denotes the element-wise exclusive-OR computation. The\n  operator \u2295 between two bits denotes the binary exclusive-OR\n  computation.",
                        "4: For i=1,2, . . . , N, do:\n\n\n- - If i\u2208F_(C), for each element in the list (which is an assignment of\n    value to (u\u2081, u\u2082, . . . , u_(i\u22121)), append it to the value\n    assignment u_(i)=0, and also append it to the value assignment\n    u_(i)=1, thus converting that element into two new elements in the\n    list. If the list now contains more than L elements, keep only the L\n    elements that are most likely in the list. The likelihood of an\n    element in the list may be computed as W_(N)^(i)((y\u2081, . . . . ,\n    y_(N)), (u\u2081, . . . , u_(i\u22121))\\|u_(i)).",
                        "5: Choose the most likely element in the list as the recovered value for (u1, . . . uN). The likelihood of an element in the list here may be computed as\n\n\n- W_(N)^(N)((y_(t), . . . , y_(N)), (u\u2081, . . . ,u_(N\u22121))\\|u_(N)). Then\n  let {u\u2081\\|i\u2208F_(WOM)\u2212F_(C)} be the recovered value for the data (b\u2081, . .\n  . , b_(M)) where the mapping from the bits in {u\u2081\\|\u2208F_(WOM)\u2212F_(C)} to\n  the bits in (b\u2081, . . . , b_(M)) is as specified in the previous\n  rewrite operation.",
                        "In some embodiments, the stored data (b1, . . . , bM) may itself be an error-correcting code C and therefore may contain redundancy and the method may include:\n\n\n- Let L be a positive integer parameter that indicates the size of a\n  list, where each, element in the list is an assignment of value to\n  (u**1**, u**2**, . . . , ui\u22121) before the value of ui is computed. The\n  method further includes the following:",
                        "1: Let y=(y1y2, . . . , yn)=((c1\u2295g1), (c2\u2295g2), . . . , (cN\u2295gN)) be a vector of N elements, where every element yi=ct\u2295gt is a bit.",
                        "2: For every i\u2208FC, let ui=0.",
                        "3: Compute the values of WNi(y,(u1, u2, . . . , ui\u22121)|ui=0) and WNi(y,(u1, u2, . . . , ui\u22121)|ui=1) for i=1,2, . . . , N as follows:\n\n\n- - Depending on the parity of i, the value of W_(N)^(i) is recursively\n    evaluated through one of the formulae below (beginning with n=N/2):",
                        "\\(\\begin{matrix}\n{W_{2\ue89en}^{{2\ue89ei} - 1}\ue8a0\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{{\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)\ue89e\\left. \uf603u_{{2\ue89ei} - 1} \\right)\ue89e{\\sum\\limits_{u_{{2\ue89ei} \\in {({0,1})}}}^{\\;}\ue89e\\; \ue89e{\\frac{1}{2}\ue89eW_{n}^{i}}}} = {{\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{n}} \\right),{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\ominus \\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)}}\uf604 \\right.\ue89eu_{{2\ue89ei} - 1}} \\ominus u_{2\ue89ei}}}} \\right)} & (11) \\\\\n{{W_{n}^{i}\ue8a0\\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603u_{2\ue89ei} \\right)},{{W_{2\ue89en}^{2\ue89ei}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),\\left( {u_{1},u_{2},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - n}} \\right)}\uf604 \\right.}\ue89eu_{2\ue89ei}}} \\right)} = {\\frac{1}{2}\ue89e{W_{n}^{i}\\left( {\\left( {y_{1},y_{2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{{\\left( {u_{1},u_{3},u_{5},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 3}} \\right) \\oplus {\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e\\left. \uf603{u_{{2\ue89ei} - 1} \\oplus u_{2\ue89ei}} \\right)\ue89eW_{n}^{i}}} = \\left( {\\left( {y_{n + 1},y_{n + 2},\\ldots \ue89e\\mspace{14mu},y_{2\ue89en}} \\right),{\\left( {u_{2},u_{4},u_{6},\\ldots \ue89e\\mspace{14mu},u_{{2\ue89ei} - 2}} \\right)\ue89e{\uf603u_{2\ue89ei}}}} \\right)}} \\right.}}} & (12)\n\\end{matrix}\\)\n\n\n- with the base cases",
                        "W11((0),(.)|0)=1\u2212p",
                        "W11((1),(.)|0)=p",
                        "W11((0),(.)|1)=p",
                        "W11((1),(.)|1)=1\u2212p\u2003\u2003(13)\n\n\n- where (.) denotes an empty vector. The operator \u2295 between two binary\n  vectors denotes the element-wise exclusive-OR computation. The\n  operator \u2295 between two bits denotes the binary exclusive-OR\n  computation.",
                        "4: For i=1,2, . . . , N, do:\n\n\n- - If i\u2208F_(C), let u_(i)=0.\n  - If i\u2209F_(C), for each element in the list (which is an assignment of\n    value to (u\u2081, u\u2082, . . . , u_(i\u22121)), append it to the value\n    assignment u_(i)=0, and also append it to the value assignment\n    u_(i)=1, thus converting that element into two new elements in the\n    list. If the list now contains more than L elements, keep only the L\n    elements that are most likely in the list. The likelihood of an\n    element in the list may be computed as W_(N)^(i)((y\u2081, . . . ,\n    y_(N)), (u\u2081, . . . , u_(i\u22121))\\|u_(i)).",
                        "5: Then, for each element in the list, check if its value assignment to (ui|i\u2208FWOM\u2212FC), which should equal (b1, . . . , bM), is a valid codeword in the error-correcting code C; and if not, remove it from the list. Then, choose the most likely element in the remaining list as the recovered value for (u1, . . . uN). The likelihood of an element in the list here may be computed as WNN ((y1. . . , uN), (u1, . . . , uN\u22121). Then let {ui|i\u2208FWOM\u2212FC} be the recovered value for the data (bi, . . . , bM), where the mapping from the bit in {ui|i\u2208FWOM\u2212FC} to the bits in (b1, . . . , bM) is as specified in the previously rewrite operation.",
                        "In some embodiments, FC may be determined as follows:\n\n\n- Let the target block error rate be B, a non-negative real-number\n  parameter between 0 and 1. Let (j**1**, j**2**, . . . , jN) be a\n  permutation of {1, 2, . . . , N} such that the decoding error\n  probability of the bit uj**1** is the greatest, the decoding error\n  probability of the bit uj**2** is the second greatest, and so on, and\n  the decoding error probability of the bit ujN is the smallest. Let the\n  size of FC, \\|FC\\|, be chosen as the smallest integer such that the\n  summation of the decoding error probabilities of the bits\n  u_(j)\\|F_(C)\\|+1, u_(j)\\|F_(C)\\|+2, . . . , u_(jN) is no greater\n  than B. Let FC={j**1**, j**2**, . . . j\\|FC\\|}.",
                        "In some embodiments, FC FWOM. In alternative embodiments, FC is not a subset of FWOM. That is, FC\u2212FWOM is not empty.",
                        "In some embodiments, the rewriting or encoding methods described above are modified to include storing the value of the bits {ui|i\u2208FC\u2212FWOM} in Nadditional additional cells, using an error-correcting code of length Nadditional that encodes |FC\u2212FWOM| bits. (Those additional cells are disjoint for the rewrites.)",
                        "In some embodiments, the error correction of decoding methods described above are modified to include recovering the value of the bits in {ui|i\u2208FC\u2212FWOM} by decoding the error-correcting code stored in the Nadditional additional cells. In addition, the error correction or decoding method described above may be such that the value of the bits in {ui|i\u2208FC\u2212FWOM} is fixed as the above recovered value.",
                        "In some embodiments, for j=1, 2, . . . , t, FCj denotes the set FC for the j-th rewrite. FWOMj denotes the set FWOM for the j-th rewrite, and Nadditional additional cells are used for a code that supports t rewrites and error-correction processes. In such, embodiments, for j=1, . . . , t, M=|FCj\u2212FWOMj| bits are stored in the j-th rewrite. The code can be any code described herein.",
                        "In some embodiments, methods of encoding discussed above may be modified such that for j=1, 2, .. . . , t, and for the j-th rewrite, the value of the bits {ui|i\u2208FC,j\u2212FWOM,j} in the Nadditional additional cells, are stored using the code specified above for the Nadditional additional cells.",
                        "In some embodiments, for j=1, . . . , t, M=|FC,j\u2212FWOMj| bits are stored in the j-th rewrite, and methods of decoding discussed above may be modified such that the value of the bits in {ui|i\u2208FC,j\u2212FWOM,j} are recovered by decoding the rewrite-and error-correction code stored in the Nadditional additional cells. In addition, methods of decoding discussed above may be modified such that the value of the bits in {ui|i\u2208FC,j\u2212FWOM, j} is fixed as the above value.",
                        "In some embodiments, the WOM cells are binary. In alternative or additional embodiments, every cell has q-levels: level 0, level 1, . . . , and level q-1,\n\n\n- and the exclusive-OR operation is generalized to the modular-q\n  summation.",
                        "In such embodiments, methods for rewriting and error-correction or encoding may use the cells in the following level-by-level approach:\n\n\n- The methods may first use level **0** and level **1** and apply the\n  previously described features for binary cells;\n- The methods may then use level **1** and level **2** (as if they were\n  level **0** and level **1**) and apply the previously described\n  features for binary cells;\n- The methods may then use level **2** and level **3** (as if they were\n  level **0** and level **1**) and apply the previously described\n  features for binary cells;\n- The above process(es) may continue, until finally, the methods may use\n  level q-**2** and level q-**1** (as if they were level **0** and level\n  **1**) and apply the previously described features for binary cells.",
                        "In some embodiments, methods for rewriting and error correction or encoding may be modified such that each ui, si, gi, vi, s\u2032i or v\u2032i takes its value from the set {0,1, . . . , q-1}, and the exclusive-OR operation may be generalized to the modular-q summation.",
                        "An example, as discussed with reference to FIGS. 4 and 5.",
                        "FIG. 4 illustrates an embodiment of an encoder. Let the code have N=8 cells. Let the AN\u00d7N=A8\u00d78 matrix 41 be:",
                        "\\(\\quad\\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 \\\\\n1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\n\\end{pmatrix}\\)",
                        "Consider a rewrite (encode) operation and the subsequent error-correction (decode) operation. For the rewrite, let the dither be (g1, . . . , gN)=(g1, . . . , g8)=(1,0,1,0,1,0,0,1). Let a=0:87. Let e=0:29. Let FWOM={1, 2, 4, 5, 6}. Let FC={2, 6}. Let M=|FWOM\u2212FC|=|{1, 4, 5}|=3. And let the data to be stored be (b1, b2, . . ., bM)=(b1, b2, b3)=(1, 0, 1). Assume the cell levels before this rewrite are (s1, . . . , sN)=(s1, . . ., sN)=(0, 0, 1, 0, 0, 0, 0, 0). As a result (v1, . . . , vn)=(v1, . . . , v8)=(s1 \u2295g1, . . . , s8\u2295g8)=(1, 0, 0, 0, 1, 0, 0, 1).",
                        "Consider the rewrite where (v1, . . . , v8)=(u1, . . . , u8) A8\u00d78 and the transition probabilities of the WOM channels 42 are shown in FIG. 4. The method of rewriting calculates that (u1, . . . , u8)=(1, 0, 0, 0, 1, 0, 0, 0) (note that u1=b1=1, u4=b2=0, u5=b3=1, and u2=u6=0); therefore (v\u20321, . . ., v\u20328)=(u1, . . . , u8) A8\u00d78=(0, 0, 0, 0, 1, 0, 0, 0) and (s\u20321. . . , s\u20328)=(v\u20321\u2295g1, . . . v\u20328\u2295g8)=(1,0, 1, 0, 0, 0, 0, 1). As a result the cells are programmed to level (s\u20321, . . . s\u20328)=(1, 0, 1, 0, 0, 0, 0, 1).\n\n\n- To write the data (b\u2081, b\u2082, . . . , b_(M)), our method has the\n  following inputs: (1) The current cell levels (s\u2081, s\u2082, . . . , s_(N)),\n  and (2) the new data to store (1, b\u2082, . . . b_(M)). It then computes\n  the output (s\u2032\u2081, s\u2032\u2082, . . . , s\u2032_(N)), and programs the cells to those\n  new levels. Here are our constraints:\n  - 1) As mentioned before, for i=1, 2, . . . , N, we have the\n    constraint that is s\u2032_(i)\u2267s_(i).\n  - 2) The new cell levels (s\u2032\u2081, s\u2032\u2082, . . . , s\u2032_(N)) represents the new\n    data (b\u2081, b\u2082, . . . , b_(M)), via the mapping specified by our\n    method.",
                        "Next, consider the error correction (decode). FIG. 5 illustrates an embodiment of a decoder. The noise channels 52 are each a binary-symmetric channel with error probability p. Assume that after the above rewrite, noise changes the cell levels from (s\u20321, . . . , s\u20328)=(1, 0, 1, 0, 0, 0, 0, 1) to (c1, . . . , c8)=(0, 1, 1, 0, 0, 0, 0, 1). The method of error correction recovers the value of (u1, . . . u8) as (1, 0, 0, 0, 1, 0, 0, 0) using the matrix 51. Therefore the stored data is correctly received as (b1, b2, b3)=(u1, u4, u5)=(1, 0, 1). 65540656V.1",
                        "The remainder of the description is organized as follows. Section II includes a basic model and notations. Section III includes an embodiment of code construction. Section IV includes embodiments of code. Section V includes embodiments of code extensions. Section VI includes an analysis of actual sum-rates achieved by a code embodiment. Section VII includes further example embodiments. Section VIII includes concluding remarks.",
                        "II. Basic Model",
                        "A memory may have N(=2m) WOM cells that are used to store data, where each cell has two levels; 0 and 1. The cells can change only from level 0 to level 1, but not vice versa.",
                        "A sequence of t messages M1, M2, . . . , Mt may be written into the WOM cells, and when Mi is written, the value of the previous messages need not be remembered. (Let Mj denote the number of bits in the message Mj, and let Mj\u2208{0,1}M.) For simplicity, let the cells be all at level 0 before the first write happens.",
                        "After cells are programmed, noise may appear in the cell levels. Noise may be considered to be a BSC with error probability p, denoted by BSC(p). These errors may be hard errors, namely, they physically change the cell levels from 0 to 1 or from 1 to 0. For flash memories, such errors can be caused by read/write disturbs, interference and charge leakage, for example, and may be quite common.",
                        "A. The Model for Rewriting",
                        "A code for rewriting and error correction may comprise of t encoding functions E1, E2, . . . , Et and t decoding functions D1,D2, . . . , Dt. For i=1,2, . . . , N and j=1,2, . . . , t, let si,j\u2208{0,1} and s\u2032i,j\u2208{0,1} denote the level of the i-th cell right before and after the j-th write, respectively. As discussed above, s\u2032i,j\u2267si,j. Let ci,j\u2208{0,1} denote the level of the i-th cell at any time after the j-th write and before the (j+1)-th write, when reading of the message Mj can happen. The error ci,j\u2295s\u2032i,j\u2208{0,1} is the error in the i-th cell caused by the noise channel BSC(p). (Here \u2295 is an XOR function.) For j=1,2, . . . , t, the encoding function",
                        "Ej:{0,1}N\u00d7{0,1}M\u2192{0,1}8 \n\n\n- changes the cell levels from s_(j)=(s_(1,j), s_(2,j), . . . , s_(N,j))\n  to s\u2032j=(s\u2032_(1,j), s\u2032_(2,j), . . . , s\u2032_(N,j)) given the initial cell\n  state s_(j) and the message to store M_(j). (Namely,\n  E_(j)(s_(j),M_(j))=s\u2032_(j).) When the reading of M_(j) happens, the\n  decoding function",
                        "Dj:{0,1}N\u2192{0,1}M\n\n\n- recovers the message M_(j) given the noisy cell state\n  c_(j)=(c_(1,j),c_(2,j), . . . c_(N,j)). Namely, D_(j)(c\u2081)=M_(j).)",
                        "For j=1, . . . ,t,",
                        "\\(R_{j} = \\frac{M_{j}}{N}\\)\n\n\n- is called the rate of the j-th write. R_(sum)=\u03a3_(j=1)^(t) R_(j) is\n  called the sum-rate of the code. When there is no noise, the maximum\n  sum-rate of WOM code is known to be log\u2082(t+1), however, for noisy WOM,\n  the maximum sum-rate is still largely unknown.",
                        "B. Polar Codes",
                        "A short introduction to polar codes follows due to its relevance to the code construction embodiments discussed herein. A polar code is a linear block error correcting code proposed by Arkan, See, e.g. E. Arkan, \u201cChannel polarization: A method for constructing capacity-achieving codes for symmetric binary-input memoryless channels,\u201d IEEE Trans. Inf. Theor., vol. 55, no. 7, pp. 3051-3073, July 2009. It is the first known code with an explicit construction that provably achieves the channel capacity of symmetric binary-input discrete memoryless channels (B-DMC). The encoder of a polar code transforms N input bits u=(u1, u2, . . . , uN) to N codeword bits x=(x1, x2, . . . , xN) through a linear transformation. (e.g. x=u where G2=",
                        "\\(\\begin{pmatrix}\n1 & 0 & \\; \\\\\n1 & 1 & \\; \\\\\n\\; & \\; & \\;\n\\end{pmatrix},\\)",
                        "and  is the m-th Kronecker product of G2.) The N codeword bits (x1, x2, . . . , xN) are transmitted through N independent copies of a B-DMC. For decoding, N transformed binary input channels {WN(1), WN(2), . . . , WN(N)} can be synthesized for u1, u2, . . . , uN, respectively. The channels are polarized such that for large N, the fraction of indices i for which I(WN(t)) is nearly 1 approaches the capacity of the B-DMC, while the values of I(WN(i)) for the remaining indices i are nearly 0. The latter set of indices are called the frozen set. For error correction, the ui\u2032s with i in the frozen set take fixed values, and the other ui\u2032s are used as information bits. A successive cancellation (SC) decoding algorithm achieves diminishing block error probability as N increases.",
                        "Polar code can also be used for optimal lossy source coding, which has various applications. See, e.g. S. Korada and R. Urbanke, \u201cPolar codes are optimal for lossy source coding,\u201d IEEE Trans. Inf. Theor. , vol. 56, no. 4, pp. 1751-1768, April 2010. In particular the idea may be used to build capacity achieving WOM codes. See, e.g., D. Burshtein and A. Strugatski, \u201cPolar write once memory codes,\u201d in Proc. IEEE international Symposium on Information Theory, July 2012, pp., 1972-1976.",
                        "The presented code analysis uses the concept of upgrading and degrading channels, defined based on frozen sets. As taught by Tal and Vardy, a channel W\u2032: X\u2192Z is called \u201cdegraded with respect to a channel W: X\u2192Y\u201d if an equivalent channel of W\u2032 can be constructed by concatenating W with an additional channel Q: Y\u2192Z, where the inputs of Q are linked with the outputs of W. See, e.g. I. Tal and A. Vardy, \u201cHow to construct polar codes,\u201d CoRR, vol. abs/1105.6164, 2011. That is,",
                        "W\u2032(z|x)=\u03a3y\u2208yW(y|x)Q(z|y)",
                        "It may be denoted as W\u2032\u2266W. Equivalently, the channel W is called \u201can upgrade with respect to W\u2032\u201d, denoted by W\u2267W\u2032.",
                        "III. Code Construction",
                        "In this section, embodiments of code construction are described that combine rewriting with error correction.",
                        "A. Basic Code Construction with a Nested Structure",
                        "1) General: First, consider a single rewrite (namely, one of the t writes). Let s=(s1, s2, . . . , sN)\u2208{0,1}N and s\u2032=(s\u20321, s\u20322, . . . , s\u2032N)\u2208{0,1}N denote the cell levels right before and after this rewrite, respectively. Let g=(g1, g2, . . . , gn) be a pseudo-random, bit sequence with independent and identically distributed bits that are uniformly distributed. The value of g is known to both the encoder and the decoder, and g is called a dither.",
                        "For i=1,2, . . . , N, let \u03bdi=si\u2295gi\u2295gi\u2208{0,1} and \u03bd\u2032i=s\u2032i\u2295gi\u2208{0,1} be the value of the i-th cell before and after the rewrite, respectively. The WOM channel is built, such as shown in FIG. 6, for this rewrite, denoted by WOM (\u03b1, \u03b5).",
                        "Here \u03b1\u2208[0,1] and",
                        "\\(\u025b \\in \\left\\lbrack {0,\\frac{1}{2}} \\right\\rbrack\\)\n\n\n- are given parameters, with",
                        "\\(\\alpha = {1 - {\\Sigma_{i = 1}^{N}\ue89e\\frac{s_{i}}{N}}}\\)\n\n\n- representing the fraction of cells, at level **0** before the rewrite,\n  and",
                        "\\(\u025b = \\frac{\\Sigma_{i = 1}^{N}\ue89es_{i}^{\\prime}\ue89es_{i}}{N - {\\Sigma_{i = 1}^{N}\ue89es_{i}}}\\)\n\n\n- representing the fraction of cells that are changed from level **0**\n  to level **1** by the rewrite. Let F_(WOM(\u03b1,\u03b5))*\u2282*{1,2, . . . , N} be\n  the frozen set of the polar code corresponding to this channel WOM(\u03b1,\n  \u03b5). It is known that",
                        "\\({\\lim_{N->\\infty}\ue89e\\frac{\uf603F_{{WOM}\ue8a0{({\\alpha,\u025b})}}\uf604}{N}} = {\\alpha \ue89e\\; \ue89e{{H\ue8a0(\u025b)}.}}\\)\n\n\n- See, e.g. I. Tal and A. Vardy, \u201cHow to construct polar codes,\u201d CoRR,\n  vol. abs/1105.61.64,2011.",
                        "For the noise channel BSC(p), let FBSC(p){1,2, . . . , N} be the frozen set of the polar code corresponding to the channel BSC(p). It is known that",
                        "\\({\\lim_{N->\\infty}\ue89e\\frac{\uf603F_{{BSC}\ue8a0{(p)}}\uf604}{\uf603N\uf604}} = {{H\ue8a0(p)}.}\\)",
                        "In this subsection, FBSC(p)FWOM(\u03b1,\u03b5). This case is as illustrated in FIG. 7(a). In this case, the code has a nice nested structure: for any message M\u2208{0,1}M, the set of cell values VM{0,1}N that represent the message M is a linear subspace of a linear error correcting code (ECC) for the noise channel BSC(p), and {VM|M\u2208{0,1}M} form a partition of the ECC. Later the code may be extended to more general cases.",
                        "2) The encoder: Let E: {0,1}N\u00d7{0,1}M\u2192{0,1}N be the encoder for this rewrite. Namely, given the current cell state s and the message to write M\u2208{0,1}M, the encoder is configured to find a new cell state s\u2032=E(s, M) that represents M and is above s (that is, cell levels only increase).",
                        "The encoding function in Algorithm 1 follows. Here y and u are two vectors of length",
                        "\\(N,{u_{F_{{WOM}\ue8a0{({\\alpha,\u025b})}} - F_{{BSC}\ue8a0{(p)}}}\ue89e\ue89e\\left\\{ u_{i} \\middle| {i \\in {F_{{WOM}\ue8a0{({\\alpha,\u025b})}} - F_{{BSC}\ue8a0{(p)}}}} \\right\\}}\\)\n\n\n- are all the bits u_(i) in the frozen set F_(WOM(\u03b1, \u03b5)) but not",
                        "\\(F_{{BSC}\ue8a0{(p)}},{u_{F_{{BSC}\ue8a0{(p)}}}\ue89e\ue89e\\left\\{ u_{i} \\middle| {i \\in F_{{BSC}\ue8a0{(p)}}} \\right\\}}\\)\n\n\n- are all the bits u_(i) in F_(BSC(p)), and\n  is the m-th Kronecker product of",
                        "\\(G_{2} = {\\begin{pmatrix}\n1 & 0 & \\; \\\\\n1 & 1 & \\; \\\\\n\\; & \\; & \\;\n\\end{pmatrix}.}\\)",
                        "3) The decoder: The decoder D: {0,1}N\u2192{0,1}M M now follows. Let c=(c1, c2, . . . , cN)\u2208{0,1}N be the noisy cell levels after the message is written. Given c, the decoder should recover the message as D(c)=M.",
                        "The decoder may be configured to operate the same way as a polar error correcting code. The decoding operation of one embodiment is presented as Algorithm 2.",
                        "- As is clear from the polar error-correcting code, the encoding and the\n  decoding algorithms may have time complexity O(NlogN).",
                        "4) Nested code for t writes: In the above, the operations of the encoder and the decoder for one rewrite have been described. The operations can be applied to a t-write error correcting WOM code as follows. For j=1,2, . . . , t, for the j-th write, replace \u03b1, \u03b5, s, s\u2032, v, v\u2032, M, M, E, D, c, {circumflex over (M)}, {circumflex over (v)}, by \u03b1j\u22121, \u03b5j, sj, s\u2032j, vj, v\u2032j, Mj, Mj, Ej, Dj, cj, {circumflex over (M)}j, {circumflex over (v)}j, respectively, and apply the above encoder and decoder.",
                        "Note that when N\u2192\u221e, the values of \u03b11, \u03b12, . . . , \u03b1t\u22121 can be computed using \u03b51, \u03b52, . . . , \u03b5t\u22121; for BSC(p), \u03b1j=\u03b1j\u22121(1\u2212\u03b5j)(1\u2212p)+(1\u2212\u03b1j\u22121(1\u2212\u03b5j))p. Improving the code may include choosing other values for \u03b51,\u03b52, . . . , \u03b5t that maximize or otherwise increases the sum-rate.",
                        "B. Extended Code Construction",
                        "Code for the case FBSC(p)FWOM(\u03b1,\u03b5) has so far been discussed. For relatively small p and typical values of (\u03b10, \u03b51), (\u03b11, \u03b52, . . . , (\u03b1t\u22121, \u03b5t) , the above condition holds. Now consider the general case where FBSC(p) is not necessarily a subset of FWOM(\u03b1,\u03b5).",
                        "The encoder in Algorithm 1 may be revised as follows. The bits are then stored in uFFusing Nadditional,j cells (for the j-th write). (This implementation is illustrated in FIG. 7(b).) In this disclosure, for simplicity, assume the bits in uFFare stored using just an error correcting code designed for the noise channel BSC(p). (The bits can be stored using an error-correcting WOM code, such as the one presented above, for higher rates.)",
                        "Therefore,",
                        "\\({\\lim_{N->\\infty}\ue89e\\frac{N_{{additional},j}}{\uf603{F_{{BSC}\ue8a0{(p)}} - F_{{WOM}\ue8a0{({\\alpha_{j - 1},\u025b_{j}})}}}\uf604}} = {\\frac{1}{1 - {H\ue8a0(p)}}.}\\)\n\n\n- And the sum-rate becomes",
                        "\\(R_{sum} = {\\frac{\\Sigma_{j = 1}^{t}\ue89eM_{j}}{N + {\\Sigma_{j = 1}^{t}\ue89eN_{{additional},j}}}.}\\)",
                        "The decoder in Algorithm 2 may be revised as follows. First recover the bits in uFusing the decoding algorithm of the ECC for the Nadditional,j additional cells. Then carry out Algorithm 2, except that the bits in FBSC(p)-FWOM(\u03b1,\u03b5) are known to the decoder as the above recovered values instead of 0s.",
                        "IV. Code Analysis",
                        "In this section, the correctness of the above code construction is shown, and its performance is analyzed.",
                        "A. Correctness of the Code",
                        "The correctness of the code is addressed first. The encoder in Algorithm 1 works similarly to the WOM code encoder in D. Burshtein and A. Strugatski, \u201cPolar write once memory codes.\u201d In Proc. IEEE International Symposium on Information Theory, July 2012, pp. 1972-1976, with an exception that the bits in FWOM(\u03b1,\u03b5) are not all occupied by the message M, instead, the bits in its subset FWOM(\u03b1,\u03b5)\u2229FBSC(p) are set to be constant values: all 0s. Therefore, the encoder successfully rewrites data in the same way as the code in D. Burshtein and A. Strugatski, \u201cPolar write once memory codes,\u201d in Proc. IEEE International Symposium on Information Theory, July 2012, pp. 1972-1976. Next, the decoder in Algorithm 2 recovers the cell values from noise in the same way as the standard polar ECC. Then, the stored message M is extracted from it.",
                        "One item to note is that although the physical noise may act on the cell levels s=(s1, s8, . . . , sN), the error correcting code used in the construction is actually for the cell values v=(\u03bd1, \u03bd2, . . . , \u03bdn)=(s1\u2295g1, s2\u2295g2, . . . , sN\u2295gN). However, the pseudo-random dither g has independent and uniformly distributed elements, and so when the noise channel for s is BSC(p), the corresponding noise channel for v is also BSC(p).",
                        "B. The Size of FWOM(\u03b1,\u03b5)\u2229FBSC(p)",
                        "It may be seen that if FBSC(p)FWOM(\u03b1,\u03b5), the code has a nested structure. In general, it is observed how large the intersection FWOM(\u03b1,\u03b5)\u2229FBSC(p) can be. For convenience of presentation, consider one rewrite as in Section III-A, where the parameters are \u03b1 and \u03b5 (instead of \u03b1j\u22121, \u03b5j).",
                        "\\({{{Lemma}\ue89e\\mspace{14mu} \ue89e1.\ue89e\\mspace{14mu} \ue89e{When}\ue89e\\mspace{14mu} \ue89e{H\ue8a0(p)}} \\leq {\\alpha \ue89e\\; \ue89e{H\ue8a0(\u025b)}}},{{{\\lim_{N->\\infty}\ue89e\\frac{\uf603F_{{BSC}\ue8a0{(p)}}\uf604}{N}} \\leq {\\lim_{N->\\infty}\ue89e{{\\frac{\uf603F_{{WOM}\ue8a0{({\\alpha,\u025b})}}\uf604}{N}.\ue89e\\mspace{20mu} \ue89e{Proof}}\ue89e\\text{:}\ue89e\\mspace{14mu} \ue89e{\\lim_{N->\\infty}\ue89e\\frac{\uf603F_{{BSC}\ue8a0{(p)}}\uf604}{N}}}}} = {{{H\ue8a0(p)} \\leq {\\alpha \ue89e\\; \ue89e{H\ue8a0(\u025b)}}} = {{\\lim_{N->\\infty}\ue89e{{\\frac{\uf603F_{{WOM}\ue8a0{({\\alpha,\u025b})}}\uf604}{N}.\ue89e\\mspace{20mu} \ue89e{Lemma}}\ue89e\\mspace{14mu} \ue89e2.\ue89e\\mspace{14mu} \ue89e{When}\ue89e\\mspace{14mu} \ue89ep}} \\leq {\\alpha \u025b}}}},\ue89e\\mspace{20mu} \ue89e{F_{{WOM}\ue8a0{({\\alpha,\\frac{p}{\\alpha}})}} \\subseteq \\left( {F_{{BSC}\ue8a0{(p)}}\\bigcap F_{{WOM}\ue8a0{({\\alpha,\u025b})}}} \\right)},\ue89e\\mspace{20mu} \ue89e{{{and}\ue89e\ue89e\\mspace{20mu}\\left( {F_{{WOM}\ue8a0{({\\alpha,\u025b})}}\\bigcup F_{{BSC}\ue8a0{(p)}}} \\right)} \\subseteq {F_{{BSC}\ue8a0{({\\alpha \u025b})}}.}}\\)",
                        "Proof: (1) In FIG. 8, by setting",
                        "\\({\u025b^{*} = \\frac{p}{\\alpha}},\\)\n\n\n- note that",
                        "\\({{BSC}\ue8a0(p)} \\leq {{{WOM}\ue8a0\\left( {\\alpha,\\frac{p}{\\alpha}} \\right)}.}\\)\n\n\n- Therefore",
                        "\\(F_{{WOM}\ue8a0{({\\alpha,\\frac{p}{\\alpha}})}} \\subseteq {F_{{BSC}\ue8a0{(p)}}.}\\)",
                        "(2) In FIG. 9, it can be seen that",
                        "\\({{WOM}\ue8a0\\left( {\\alpha,\u025b} \\right)} \\leq {{{WOM}\ue8a0\\left( {\\alpha,\\frac{p}{\\alpha}} \\right)}.}\\)\n\n\n- Therefore,",
                        "\\(F_{{WOM}\ue8a0{({\\alpha,\\frac{p}{\\alpha}})}} \\subseteq {F_{{WOM}\ue8a0{({\\alpha,\u025b})}}.}\\)",
                        "(3) In FIG. 8, by setting \u03b5*=\u03b5, it is seen that BSC(\u03b1\u03b5)\u2266WOM(\u03b1, \u03b5). Therefore FWOM(\u03b1,\u03b5)FBSC(\u03b1\u03b5).",
                        "(4) Since p\u2266\u03b1\u03b5, clearly BSC(\u03b1\u03b5)\u2266BSC(p). Therefore FBSC(p)FBSC(\u03b1\u03b5).",
                        "The meaning of Lemma 2 is illustrated in FIG. 10.",
                        "\\(\\mspace{85mu} \ue89e{{Lemma}\ue89e\\mspace{14mu} \ue89e3.}\\)\n\\(\\mspace{79mu} \ue89e{{{{When}\ue89e\\mspace{14mu} \ue89ep} \\leq {\\alpha \u025b}},{{{\\lim_{N\\rightarrow\\infty}\ue89e\\frac{\uf603{F_{{WOM}\ue8a0{({\\alpha \u025b})}}\\bigcap F_{{BSC}\ue8a0{(p)}}}\uf604}{N}} \\geq {\\lim_{N\\rightarrow\\infty}\ue89e\\frac{\uf603F_{{WOM}\ue8a0{({\\alpha,\\frac{p}{\\alpha}})}}\uf604}{N}}} = {\\alpha \ue89e\\; \ue89e{{H\ue8a0\\left( \\frac{p}{\\alpha} \\right)}.\ue89e\\mspace{85mu} \ue89e{Lemma}}\ue89e\\mspace{14mu} \ue89e4.}}}\\)\n\\(\\mspace{79mu} \ue89e{{{{When}\ue89e\\mspace{14mu} \ue89ep} \\leq {\\alpha \u025b}},\ue89e{{{\\lim_{N\\rightarrow\\infty}\ue89e\\frac{\uf603{F_{{WOM}\ue8a0{({\\alpha,\u025b})}}\\bigcap F_{{BSC}\ue8a0{(p)}}}\uf604}{N}} \\geq {\\lim_{N\\rightarrow\\infty}\ue89e\\frac{{\uf603F_{{WOM}\ue8a0{({\\alpha,\u025b})}}\uf604} + {\uf603F_{{BSC}\ue8a0{(p)}}\uf604} - {\uf603F_{{BSC}\ue8a0{({\\alpha \u025b})}}\uf604}}{N}}} = {{\\alpha \ue89e\\; \ue89e{H\ue8a0(\u025b)}} + {H\ue8a0(p)} - {{H\ue8a0({\\alpha \u025b})}.}}}}\\)",
                        "Proof: |FWOM(\u03b1,\u03b5)\u2229FBSC(p)|=FWOM(\u03b1,\u03b5)|+|FBSC(p)|\u2212|FWOM(\u03b1,\u03b5)\u222aFBSC(p)|\u2267|FWOM(\u03b1,\u03b5)|+FBSC(p)|\u2212FBSC(\u03b1, \u03b5)| (by Lemma 2).",
                        "C. Lower Bound to Sum-Rate",
                        "The sum-rate of the general code construction is analyzed as N\u2192\u221e. Let",
                        "\\(x_{j}\ue89e\\overset{\\Delta}{=}\ue89e{\\frac{\uf603{F_{{WOM}\ue8a0{({\\alpha_{j - 1},\u025b_{j}})}}\\bigcap F_{{BSC}\ue8a0{(p)}}}\uf604}{\uf603F_{{BSC}\ue8a0{(p)}}\uf604} \\leq 1.}\\)\n\n\n- For j=1,2, . . . , t, the number of bits written in the j-th rewrite\n  is",
                        "{ j = \ue89e \uf603 F WOM \ue8a0 ( \u03b1 j - 1 , \u025b j ) \uf604 - \uf603 F WOM \ue8a0 ( \u03b1 j - 1 , \u025b j ) \u22c2 F\nBSC \ue8a0 ( p ) \uf604 = \ue89e N \ue89e \ue89e \u03b1 j - 1 \ue89e H \ue8a0 ( \u025b j ) - x j \ue89e \uf603 F BSC \ue8a0 ( p ) \uf604\n= \ue89e N \ue8a0 ( \u03b1 j - 1 \ue89e H \ue8a0 ( \u025b j ) - x j \ue89e H \ue8a0 ( p ) ) }\n\n\n- and the number of additional cells used to store the bits in\n  F_(BSC(p))\u2212F_(WOM) _((\u03b1j\u22121\u22128j)) is",
                        "\\(N_{{additional},j} = \\frac{{{NH}\ue8a0(p)}\ue89e\\left( {1 - x_{j}} \\right)}{1 - {H\ue8a0(p)}}\\)",
                        "Therefore, the sum-rate is",
                        "{ R sum \ue89e = \u0394 \ue89e \u2211 j = 1 t \ue89e j N + \u2211 j = 1 t \ue89e N additional , j }",
                        "\\(\\begin{matrix}\n{= \ue89e\\frac{{\\sum_{j = 1}^{t}\ue89e{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \u025b_{j} \\right)}}} - {{H\ue8a0(p)}\ue89e{\\sum_{j = 1}^{t}\ue89ex_{j}}}}{1 + {\\frac{H\ue8a0(p)}{1 - {H\ue8a0(p)}}\ue89e{\\sum_{j = 1}^{t}\ue89e\\left( {1 - x_{j}} \\right)}}}} \\\\\n{= \ue89e\\frac{{\\left( {1 - {H\ue8a0(p)}} \\right)\ue89e{\\sum_{j = 1}^{t}\ue89e{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \u025b_{j} \\right)}}}} - {{H\ue8a0(p)}\ue89e\\left( {1 - {H\ue8a0(p)}} \\right)\ue89e{\\sum_{j = 1}^{t}\ue89ex_{j}}}}{\\left( {1 - {H\ue8a0(p)} + {{H\ue8a0(p)}\ue89et}} \\right) - {{H\ue8a0(p)}\ue89e{\\sum_{j = 1}^{t}\ue89ex_{j}}}}} \\\\\n{= \ue89e{{{\\left( {1 - {H\ue8a0(p)}} \\right) \\cdot {\\frac{{\\frac{1}{H\ue8a0(p)}\ue89e{\\sum_{j = 1}^{t}\ue89e{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \u025b_{j} \\right)}}}} = {\\sum_{j = 1}^{t}\ue89ex_{j}}}{\\frac{1 - {H\ue8a0(p)} + {{H\ue8a0(p)}\ue89et}}{H\ue8a0(p)} - {\\sum_{j = 1}^{t}\ue89ex_{j}}}.\ue89e{Let}}}\ue89e\\mspace{14mu} \ue89e\\gamma_{i}}\ue89e\\overset{\\Delta}{=}\ue89e{\\max \ue89e{\\left\\{ {\\frac{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \\frac{p}{\\alpha_{j - 1}} \\right)}}{H\ue8a0(p)},\\frac{{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \u025b_{j} \\right)}} + {H\ue8a0(p)} - {H\ue8a0\\left( {\\alpha_{j - 1}\ue89e\u025b_{j}} \\right)}}{H\ue8a0(p)}} \\right\\}.}}}}\n\\end{matrix}\\)",
                        "Lemma 5. Let 0<p\u2266\u03b1j\u22121\u03b5j. Then xj\u2267\u03b3j.",
                        "Proof: By Lemma 3,",
                        "\\(\\begin{matrix}\n\\begin{matrix}\n{x_{j} = \ue89e\\frac{\uf603{F_{{WOM}\ue8a0{({\\alpha_{j - 1},\u025b_{j}})}}\\bigcap F_{{BSC}\ue8a0{(p)}}}\uf604}{\uf603F_{{BSC}\ue8a0{(p)}}\uf604}} \\\\\n{{\\geq \ue89e\\frac{\uf603F_{{WOM}\ue8a0{({\\alpha_{j - 1} \\cdot \\frac{p}{\\alpha_{j - 1}}})}}\uf604}{\uf603F_{{BSC}\ue8a0{(p)}}\uf604}} = {\\frac{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \\frac{p}{\\alpha_{j - 1}} \\right)}}{H\ue8a0(p)}.}} \\\\\n{\ue89e{{{By}\ue89e\\mspace{14mu} \ue89e{Lemma}\ue89e\\mspace{14mu} \ue89e4},{{we}\ue89e\\mspace{14mu} \ue89e{also}\ue89e\\mspace{14mu} \ue89e{have}}}}\n\\end{matrix} & \\; \\\\\n\\begin{matrix}\n{x_{j} = \ue89e\\frac{\uf603{F_{{WOM}\ue8a0{({\\alpha_{j - 1},\u025b_{j}})}}\\bigcap F_{{BSC}\ue8a0{(p)}}}\uf604}{\uf603F_{{BSC}\ue8a0{(p)}}\uf604}} \\\\\n{\\geq \ue89e\\frac{{\uf603F_{{WOM}\ue8a0{({\\alpha_{j - 1},\u025b_{j}})}}\uf604} + {\uf603F_{{BSC}\ue8a0{(p)}}\uf604} - {\uf603F_{{BSC}\ue8a0{({\\alpha_{j - 1},\u025b_{j}})}}\uf604}}{\uf603F_{{BSC}\ue8a0{(p)}}\uf604}} \\\\\n{= \ue89e{\\frac{{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \u025b_{j} \\right)}} + {H\ue8a0(p)} - {H\ue8a0\\left( {\\alpha_{j - 1}\ue89e\u025b_{j}} \\right)}}{H\ue8a0(p)}.}}\n\\end{matrix} & \\;\n\\end{matrix}\\)",
                        "Theorem 6 Let 0<p\u2266\u03b1j\u22121\u03b5j for j=1,2, . . . , t. If \u03a3j\u22121t \u03b1j\u22121H(\u03b5j)\u22671\u2212H(p)+H (p)t, then the sum-rate Rsum is lower bounded by",
                        "\\(\\left( {1 - {H\ue8a0(p)}} \\right)\ue89e{\\frac{\\sum_{j = 1}^{t}\ue89e\\left( {{\\alpha_{j - 1}\ue89e{H\ue8a0\\left( \u025b_{j} \\right)}} - {{H\ue8a0(p)}\ue89e\\gamma_{j}}} \\right)}{1 - {H\ue8a0(p)} + {{H\ue8a0(p)}\ue89et} - {{H\ue8a0(p)}\ue89e{\\sum_{j = 1}^{t}\ue89e\\gamma_{j}}}}.}\\)",
                        "If \u03a3j=1t \u03b1j\u22121H(\u03b5j)<1\u2212H(p)+H(p)t, and H(p)\u2266\u03b1j\u22121H(\u03b5j) for j=1,2, . . . , t, then Rsum is lower bounded by",
                        "(\u03a3j=1t\u03b1j\u22121H(\u03b5j))\u2212H(p)t.",
                        "Proof: If \u03a3j=1t \u03b1j\u22121H(\u03b5j)\u22671\u2212H(p)+H(p)t, the sum-rate is minimized when xj (j=1,2, . . . , t) takes the minimum value, and xj\u2267\u03b3j. Otherwise, the sum-rate is minimized when xj takes the maximum value 1.",
                        "Some numerical results of the lower bound are shown to sum-rate Rsum in FIG. 11, where",
                        "\\({\u025b_{i} = \\frac{1}{2 + t - i}},\\)\n\n\n- The curve for p=0 is the optimal sum-rate for noiseless WOM code. The\n  other four curves are the lower bounds for noisy WOM with p=0.001,\n  p=0.005, p=0.010 and p=0.016, respectively, given by Theorem 6. Note\n  that it is possible to further increase the lower bound values by\n  optimizing \u03b5_(t).",
                        "V. Extensions",
                        "More general noise models are now described. For simplicity, an erasure channel is described. But the principles or other features can be extended to other noise models. Let the noise be a binary erasure channel (BEC) with erasure probability p, denoted by BEC(p). After a rewrite, noise may appear in some cell levels (both level 0 and level 1) and may change the cell levels to erasures. An erasure represents a noisy cell level between 0 and 1. Erasures may be handled as follows: before a rewrite, all the erased cell levels are increased to 1, and then rewriting is performed as before.",
                        "Note that although the noise for cell levels is BEC(p), when rewriting happens, the equivalent noise channel for the cell value v=s\u2295g is a",
                        "\\({{BSC}\ue8a0\\left( \\frac{p}{2} \\right)},\\)\n\n\n- because all the erased cell levels have been pushed to level **1**,\n  and dither has a uniform distribution. Therefore, the code\n  construction and its performance analysis can be carried out the same\n  way as before, except that p is replaced by",
                        "\\(\\frac{p}{2}.\\)",
                        "The code can also be extended to multi-level cells (MLC), by using q-ary polar codes.",
                        "VI. Additional Information",
                        "In this section, example achievable rates of the error correcting WOM code are discussed, using polar codes of finite lengths. In the following, assume the noise channel is BSC(p), and search is performed for parameters \u03b51,\u03b52, . . . , \u03b5t that achieve high sum-rate for rewriting. When the code can have a nested structure is also discussed. This simplifies the code construction.",
                        "A. Finding BSCs Satisfying FBSC(p)FWOM(\u03b1\u03b5)",
                        "The first consideration is when BSC(p) satisfies the condition FBSC(p)FWOM(\u03b1,\u03b5), which leads to a particular nested code structure. Let N=8192. Let the polar codes be constructed using the method(s) described herein. To obtain the frozen sets, let |FWOM(\u03b1\u03b5)|=N(\u03b1H(\u03b5)\u2212\u0394R), where \u0394R=0.025 is a rate loss considered for the polar code of the WOM channel, and let FBSC(p) be chosen with the target block error rate 10\u22125.",
                        "Example results are shown in FIG. 12. The four curves correspond to \u03b1=0.4, 0.6, 0.8, and 1.0, respectively. The x-axis is \u03b5, and the y-axis is the maximum value of p that satisfies FBSC(p)FWOM(\u03b1,\u03b5). Clearly, the maximum value of p increases with both \u03b1 and \u03b5 and has nontrivial values (namely, p is comparable to or higher than the typical error probabilities in memories).",
                        "B. Achievable Sum-Rates for Nested Code",
                        "Achievable sum-rates of codes with a nested structure may be found. Accordingly, the condition FBSC(p)FWOM(\u03b1\u03b5may be satisfied for all j=1,2, . . . , t. Given p, \u03b51, \u03b52, . . . , \u03b5t that maximize or otherwise increase the sum-rate Rsum may be found.",
                        "Results for t-write error-correcting WOM codes\u2014for t=2,3,4,5\u2014are shown in FIG. 13. (In one example, let N=8192, \u0394R=0.025, and the target block error rate be 10\u22125.) The x-axis is p and the y-axis is the maximum sum-rate found in the algorithmic search. Accordingly, the achievable sum-rate increases with the number of rewrites t.",
                        "C. Achievable Sum-Rate for General Code",
                        "The achievable sum-rates of the general code, when FBSC(p) is not necessarily a subset of FWOM (\u03b1\u03b5, is now described. When p is given, the general code can search a larger solution space for \u03b51, \u03b52, . . . , \u03b5t than the nested-code case, and therefore achieve higher sum-rates. However, for relatively small p (e.g. p<0.016), the gain in rate that is obtained may be quite small. This indicates that the nested code is already performing well for this parameter range.",
                        "The lower bound to sum-rate Rsum is discussed with reference to FIG. 10. of Note that one embodiment may actually be higher than the rates found in other embodiments. This is because the lower bound is for N\u2192\u221e, while the codes in the other embodiments may be still short so far and may consider the rate loss \u0394R. Better rates can be provided as the code length is increased and as the search algorithm is further improved due to the results indicated by the lower bound."
                    ],
                    "subsections": [
                        {
                            "title": "VII. Additional Example Embodiments",
                            "paragraphs": [
                                "FIG. 14 is an illustration of one embodiment of a data device constructed/configured so as to perform the methods and operations discussed herein. FIG. 14 shows a memory 1602 that is accessed by a memory controller 1604 that communicates with a host device 1606. The memory 1602 is used for storing data that is represented in accordance with an encoding and decoding scheme discussed herein. The memory may be implemented, for example, as a Flash memory having multilevel cells. The memory 1602 and memory controller 1604 together at least partly form a data storage device 1608 that may be external to the host device or may be integrated with the host device into a single component or system. For example, the data storage device 1608 may comprise a Flash memory device (often referred to as a \u201cthumb drive\u201d) that communicates with a host computer 1606 via a USB connection, or the data storage device may comprise a solid state drive (SSD) that stores data for a host computer system. Alternatively, the data storage device may integrated with a suitable host device to comprise a single system or component with memory employing an embodiment of a encoding and decoding scheme as discussed herein, such as a smart phone, network router, MP3 player, or the like.",
                                "The memory controller 1604 operates under control of a microcontroller 1610, which manages communications with the memory 1602 via a write device, such as memory interface 1612 and manages communications with the host device via a host interface 1614. Thus, the memory controller supervises data transfers from the host 1606 to the memory 1602 and from the memory 1602 to the host 1606. The memory controller 1604 also includes a data buffer 1616 in which data values may be temporarily stored for transmission over the data channel controller 1617 between the memory 1602 and the host 1606. They memory controller also includes an Error Correcting code (ECC) block 1618 in which data for the ECC is maintained. For example, the ECC block 1618 may comprise data and program code to perform error correction operations for a an embodiment of a encoding and decoding scheme as discussed herein. Some embodiments of such error correction operations are described, for example, in U.S. Patent Application entitled \u201cError Correcting Codes for Rank Modulation\u201d by Anxiao Jiang et al. filed Nov. 20, 2008, and incorporated herein by reference. The ECC block 1618 may contain parameters for the error correction code to be used for the memory 1602, such as programmed operations for translating between received symbols and error-corrected symbols, or the ECC block may contain lookup tables for codewords or other data, or the like. The memory controller 1604 of one embodiment may perform the operations described above for decoding data and for encoding data.",
                                "The operations described above for operating a data storage device, for reading data from a device, for programming a data storage device, and encoding and decoding, can be carried out by the operations discussed above which can be performed by the microcontroller 1610 and associated components of the data storage device 1608.",
                                "The processing components such as the controller 1604 and microcontroller 1610 to perform the various operations described herein may be implemented in some embodiments in the form of control logic in software (or other computer-readable instruction stored on a non-transitory computer-readable storage medium and executable by one or more processors) or hardware or a combination of both, and may comprise the processor(s) that execute software program instructions from program memory, or as firmware, or the like. The host device 1606 may comprise a computer apparatus. A computer apparatus also may carry out the operations depicted in the various figures herein or otherwise described above.",
                                "FIG. 15 is a block diagram illustrating an example computing device 900 that includes elements that pertain to the encoding and decoding operations, error correction operation, memory cells, etc. discussed herein in connection with a read and write data from a memory. In a very basic configuration 901, computing device 900 typically includes one or more processors 910 and system memory 920. A memory bus 930 can be used for communicating between the processor 910 and the system memory 920.",
                                "Depending on the desired configuration, processor 910 can be of any type including but not limited to a microprocessor (\u03bcP), a microcontroller (\u03bcC), a digital signal processor (DSP), or any combination thereof. Processor 910 can include one more levels of caching, such as a level one cache 911 and a level two cache 912, a processor core 913, and registers 914. The processor core 913 can include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof. A memory controller 915 can also be used with the processor 910, or in some implementations the memory controller 915 can be an internal part of the processor 910.",
                                "Depending on the desired configuration, the system memory 920 can be of any type including but not limited to volatile memory (such as RAM), non-volatile memory (such as ROM, flash memory, etc.) or any combination thereof. System memory 920 typically includes an operating system 921, one or more applications 922, and program data 924. Applications 922 include encoding and decoding algorithms 923 that is arranged to encode and decode, for example, program data 924 as discussed below. In some embodiments, applications 922 can be arranged to operate with program data 924 on an operating system 921. This described basic configuration is illustrated in FIG. 9 by those components within dashed line 901. In some embodiments, one or more of the memories or other storage devices shown in FIG. 15 can include WOM that is written to and read from using the various features and operations described above. In some embodiments, the applications(s) 922 can include one or more algorithms 923 having computer-readable instructions that are stored on a non-transitory (such as hardware) computer-readable medium and that are executable by one or more processors (such as the processor 910) to perform the joint rewriting and error correction of a WOM as described herein. The program data 924 of one embodiment may include various data 925, such as the data written to or read from the WOM, the data for the various\n\n\n- equations/variable/vectors/algorithms/etc. described above, or other\n  data.",
                                "Computing device 900 can have additional features or functionality, and additional interfaces to facilitate communications between the basic configuration 901 and any required devices and interfaces. For example, a bus/interface controller 940 can be used to facilitate communications in accordance with the present disclosure between the basic configuration 901 and one or more data storage devices 950 via a storage interface bus 941. The data storage devices 950 can be removable storage devices 951, non-removable storage devices 952, or a combination thereof. Examples of removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HHDs), optical disk drives such as compact disk (CD) drives or digital versatile disk (DVD) drives, solid state drives (SSDs), and tape drives to name a few. Example computer storage media can include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data.",
                                "System memory 920, removable storage 951 and non-removable storage 952 are all examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVDs) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 900. Any such computer storage media can be part of device 900.",
                                "Computing device 900 can also include an interface bus 942 for facilitating communication from various interface devices (e.g., output interfaces, peripheral interfaces, and communication interfaces) to the basic configuration 901 via the bus/interface controller 940. Example output devices 960 include a graphics processing unit 961 and an audio processing unit 962, which can be configured to communicate to various external devices such as a display or speakers via one or more A/V ports 963. Example peripheral interfaces 970 include a serial Interface controller 971 or a parallel interlace controller 972, which can be configured to communicate with external devices such as input devices (e.g., keyboard, mouse, pen, voice input device, touch input device, etc.) or other peripheral devices (e.g. printer, scanner, etc.) via one or more I/O ports 973. An example communication device 980 includes a network controller 981, which can be arranged to facilitate communications with one or more other computing devices 990 over a network communication via one or more communication ports 982. The communication connection is one example of a communication media. Communication media may typically be embodied by computer readable instructions, data structures, program modules,, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media. A \u201cmodulated data signal\u201d can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media can include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media. The term computer readable media as used herein can include both storage media and communication media.",
                                "Computing device 900 can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions. Computing device 900 can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.",
                                "The operations of encoding and decoding data according to the error correction encoding schemes discussed above can be illustrated ad in FIG. 16, which shows data flow in a memory device 1302, such as data storage device 1608 discussed above with reference to FIG. 14, that operates according to the error correction encoding schemes described herein. In FIG. 16, the memory device 1302 includes an encoder and decoder 1308 tor encoding data values into codewords and decoding codewords into data values. The encoder and decoder 1308 encodes data values and provides codewords to the source/destination block 1310, and decodes codewords from the source/destination and provides corresponding data values. The two-way nature of the data flow is indicated by the double-ended arrows labeled \u201cdata values\u201d and \u201ccodewords\u201d. The encoder and decoder 1308 includes interfaces through which the encoder and decoder 1308 receives and provides the data values and the information values (codewords). For the sake of brevity, further details of such interfaces are not provided herein. While represented as a single block/unit that is labeled as 1308 in FIG. 16, the encoder and decoder can comprise discrete and separate blocks/units in other embodiments.",
                                "The information values 1306 comprise a physical representation of the data values and codewords. For example, the information values 1306 may represent charge levels of memory cells, such that multiple cells are configured to operate as virtual cell in which charge levels of the cells determine a representation of the data values with error correction. Data values are received and encoded to represent the data values with error correction and charge levels of cells are adjusted accordingly, and codewords are determined according to cell charge levels, from which a corresponding data value is determined. Alternatively, the information values 1306 may represent features of a transmitted signal, such as signal frequency, magnitude, or duration, such that the cells or bins are defined by the signal features and represent a data value having error correction. For example, frequency changes over time can determine a data value having error correction. Other schemes for physical representation of the cells are possible in view of the description herein.",
                                "For information values 1306 in the case of cell charge levels, the source/destination 1310 comprises memory cells in which n memory cells provide n cell values whose charge levels define data values having error correction. For storing a codeword, the memory cells receive an encoded codeword and comprise a destination, and for reading a code word, the memory cells provide a codeword for decoding and comprise a source. In the case of data transmission, the source/destination 1310 may comprise a write device, such as a transmitter/receiver that processes a signal with signal features such as frequency, magnitude, or duration that define cells or bins such that the signal features determine a data value having error correction. For example, signal components comprising signal frequency, magnitude, or duration may be controlled and modulated by the transmitter such that data values having error correction are represented. When the source/destination 1310 receives a codeword from the controller 1304, the source/destination comprises a transmitter of the device 1302 for sending an encoded signal. When the source/destination provides a codeword to the controller 1304 from a received signal, the source/destination comprises a receiver of the device for receiving an encoded signal. Signal components of the transmitted signal can be suitable modulated to define data values having error correction, in view of the description herein.",
                                "The various aspects discussed herein can be implemented in the form of control logic in software or hardware or a combination of both. The control logic may be stored in an information storage medium as a plurality of instructions adapted to direct an information-processing device to perform the operations discussed herein. Based on the disclosure and teachings provided herein, other ways and/or methods to implement the discussed features are possible.",
                                "The methods and operations described herein can be implemented in a variety of systems for encoding and decoding data for transmission and storage. For example, codewords may be received from a source over an information channel according to a memory writing scheme and are decoded into their corresponding data values and provided to a destination, such as a memory or a processor, and data values for storage or transmission are received from a source over an information channel and are encoded according to the memory writing scheme.",
                                "The coding scheme can be further extended to multi-level cells (MLC). For example, using aspects of the coding scheme described above, multilevel cell memories can be written level by level. Alternatively or additionally, aspects of the coding scheme described above may be used for writing multilevel cell memories using a multilevel polar code.",
                                "VIII. Concluding Remarks",
                                "This application presents a code construction for error-correcting WOM codes. The embodiment(s) described herein supports any number of rewrites and can correct a substantial number of errors. In some embodiments, construction may be based on polar coding to achieve improved performance for both rewriting and error correction.",
                                "The present disclosure is not to be limited in terms of the particular embodiments described in this application, which are intended as illustrations of various aspects. Many modifications and variations can be made without departing from its spirit and scope, as will be apparent to those skilled in the art. Functionally equivalent methods and apparatuses within the scope of the disclosure, in addition to those enumerated herein, will be apparent to those skilled in the art from the foregoing descriptions. Such modifications and variations are intended to fall within the scope of the appended claims. The present disclosure is to be limited only by the terms of the appended claims, along with the full scope of equivalents to which such claims are entitled. It is to be understood that this disclosure is not limited to particular methods, systems, or devices which can, of course, vary. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only, and is not intended to be limiting.",
                                "With respect to the use of substantially any plural and/or singular terms herein, those having skill in the art can translate from the plural to the singular and/or from the singular to the plural as is appropriate to the context and/or application. The various singular/plural permutations may be expressly set forth herein for sake of clarity.",
                                "It will be understood by those within the art that, in general, terms used herein, and especially in the appended claims (e.g., bodies of the appended claims) are generally intended as \u201copen\u201d terms (e.g., the term \u201cincluding\u201d should be interpreted as \u201cincluding but not limited to,\u201d the term \u201chaving\u201d should be interpreted as \u201chaving at least,\u201d the term \u201cincludes\u201d should be interpreted as \u201cincludes but is not limited to,\u201d etc.). It will be further understood by those within the art that if a specific number of an introduced claim recitation is intended, such an intent will be explicitly recited in the claim, and in the absence of such recitation no such intent is present. For example, as an aid to understanding, the following appended claims may contain usage of the introductory phrases, \u201cat least one\u201d and \u201cone or more\u201d to introduce claim recitations. However, the use of such phrases should not be construed to imply that the introduction of a claim recitation by the indefinite articles \u201ca\u201d or \u201can\u201d limits any particular claim containing such introduced claim recitation to embodiments containing only one such recitation, even when the same claim includes the introductory phrases \u201cone or more\u201d or \u201cat least one\u201d and indefinite articles such as \u201ca\u201d or \u201can\u201d (e.g., \u201ca\u201d and/or \u201can\u201d should be interpreted to mean \u201cat least one\u201d or \u201cone or more\u201d); the same holds true for the use of definite articles used to introduce claim recitations. In addition, even if a specific number of an introduced claim recitation is explicitly recited, those skilled in the art will recognize that such recitation should be interpreted to mean at least the recited number (e.g., the bare recitation of \u201ctwo recitations,\u201d without other modifiers, means at least two recitations, or two or more recitations). Furthermore, in those instances where a convention analogous to \u201cat least one of A, B, and C, etc.\u201d is used, in general such a construction is intended in the sense one having skill in the art would understand the convention (e.g., \u201ca system having at least one of A, B, and C\u201d would include but not be limited to systems that have A along, B alone, C alone, A and B together, A and C together, B and C together, and/or A, B, and C together, etc.). In those instances where a convention analogous to \u201cat least one of A, B, or C, etc.\u201d is used, in general such a construction is intended in the sense one having skill in the art would understand the convention (e.g., \u201ca system having at least one of A, B, or C\u201d would include but not be limited to systems that have A along, B alone, C alone, A and B together, A and C together, B and C together, and/or A, B, and C together, etc.). It will be further understood by those within the art that virtually any disjunctive word and/or phrase presenting two or more alternative terms, whether in the description, claims, or drawings, should be understood to contemplate the possibilities of including one of the terms, either of the terms, or both terms. For example, the phrase \u201cA and B\u201d will be understood to include the possibilities of \u201cA\u201d or \u201cB\u201d or \u201cA and B.\u201d",
                                "In addition, where features or aspects of the disclosure are described in terms of Markush groups, those skilled in the art will recognize that the disclosure is also thereby described in terms of any individual member or subgroup of members of the Markush group.",
                                "As will be understood by one skilled in the art, for any and all purposes, such as in terms of providing a written description, all ranges disclosed herein also encompass any and all possible subranges and combinations of subranges thereof. Any listed range can be easily recognized as sufficiently describing and enabling the same range being broken down into at least equal halves, thirds, quarters, fifths, tenths, etc. As a non-limiting example, each range discussed herein can be readily broken down into a lower third, middle third and upper third, etc. As will also be understood by one skilled in the art all language such as \u201cup to,\u201d \u201cat least,\u201d \u201cgreater than,\u201d \u201cless than,\u201d and the like include the number recited and refer to oranges which can be subsequently broken down into subranges as discussed above. Finally, as will be understood by one skilled in the art, a range includes each individual member. Thus, for example, a group having 1-3 cells refers to groups having 1, 2, or 3 cells. Similarly, a group having 1-5 cells refers to groups having 1, 2, 3, 4, and 5 cells, and so forth.",
                                "While various aspects and embodiments have been disclosed herein, other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting, with the true scope and spirit being indicated by the following claims."
                            ],
                            "subsections": [],
                            "outline_long": [
                                "illustrate data device constructed/configured to perform methods and operations",
                                "show memory accessed by memory controller",
                                "describe memory controller operating under control of microcontroller",
                                "manage communications with memory via write device",
                                "manage communications with host device via host interface",
                                "supervise data transfers from host to memory",
                                "supervise data transfers from memory to host",
                                "include data buffer for temporarily storing data values",
                                "include Error Correcting code (ECC) block for maintaining ECC data",
                                "perform error correction operations for encoding and decoding scheme",
                                "describe operations for operating data storage device",
                                "describe operations for reading data from device",
                                "describe operations for programming data storage device",
                                "describe encoding and decoding operations",
                                "implement processing components in software or hardware",
                                "implement processing components as control logic",
                                "execute software program instructions from program memory",
                                "describe host device as computer apparatus",
                                "illustrate example computing device",
                                "describe basic configuration of computing device",
                                "include processor and system memory",
                                "describe memory bus for communicating between processor and system memory",
                                "describe processor as microprocessor, microcontroller, or digital signal processor",
                                "include levels of caching, processor core, and registers",
                                "describe memory controller as part of processor or separate component",
                                "describe system memory as volatile or non-volatile memory",
                                "include operating system, applications, and program data",
                                "describe applications as encoding and decoding algorithms",
                                "operate with program data on operating system",
                                "include WOM that is written to and read from using various features",
                                "describe applications as including algorithms with computer-readable instructions",
                                "execute algorithms by one or more processors",
                                "describe program data as including various data",
                                "include bus/interface controller for facilitating communications",
                                "describe data storage devices as removable or non-removable",
                                "include examples of computer storage media",
                                "describe system memory, removable storage, and non-removable storage",
                                "include interface bus for facilitating communication from interface devices",
                                "describe output devices as graphics processing unit and audio processing unit",
                                "describe peripheral interfaces as serial interface controller or parallel interface controller",
                                "describe communication device as network controller",
                                "facilitate communications with other computing devices over network",
                                "describe computing device as portion of small-form factor portable electronic device",
                                "describe computing device as personal computer"
                            ],
                            "num_characters": 22320,
                            "outline_medium": [
                                "illustrate data device constructed/configured to perform methods and operations",
                                "describe memory and memory controller components",
                                "detail microcontroller and data buffer operations",
                                "explain error correcting code (ECC) block operations",
                                "describe data storage device components and operations",
                                "illustrate computing device components and operations",
                                "detail processor and system memory components",
                                "explain memory controller and interface bus operations",
                                "describe output devices and peripheral interfaces",
                                "detail communication device and network controller operations",
                                "illustrate computing device implementation as a portable electronic device",
                                "describe encoding and decoding data according to error correction encoding schemes",
                                "illustrate data flow in a memory device",
                                "detail encoder and decoder operations",
                                "explain information values and physical representation of data values and codewords",
                                "describe source/destination block operations",
                                "illustrate control logic in software or hardware or a combination of both",
                                "describe methods and operations for encoding and decoding data",
                                "explain coding scheme extension to multi-level cells (MLC)",
                                "summarize code construction for error-correcting WOM codes",
                                "describe embodiment(s) supporting any number of rewrites and error correction",
                                "provide concluding remarks and scope of the disclosure"
                            ],
                            "outline_short": [
                                "illustrate data device constructed/configured to perform methods and operations",
                                "describe memory and memory controller components",
                                "detail microcontroller and data buffer operations",
                                "explain error correcting code (ECC) block operations",
                                "illustrate computing device with encoding and decoding algorithms",
                                "describe system memory and applications components",
                                "detail data storage devices and interfaces",
                                "illustrate output devices and peripheral interfaces",
                                "describe communication device and network controller",
                                "illustrate data flow in memory device with encoder and decoder",
                                "conclude with remarks on code construction for error-correcting WOM codes"
                            ]
                        }
                    ],
                    "outline_long": [
                        "introduce detailed description",
                        "explain purpose of drawings",
                        "describe illustrative embodiments",
                        "outline scope of disclosure",
                        "introduce joint rewriting and error correction",
                        "motivate rewriting and error correction",
                        "present coding scheme",
                        "analyze code for binary symmetric channel",
                        "extend results to multi-level cells and general noise models",
                        "introduce code construction for error-correcting WOM codes",
                        "describe cell programming method",
                        "outline constraints for cell programming",
                        "introduce example write process",
                        "describe polar encoder and WOM channel devices",
                        "illustrate write process with block diagram",
                        "outline operations of encoding method",
                        "determine current cell levels",
                        "generate next cell levels",
                        "write next cell levels into memory",
                        "describe rewriting operation",
                        "outline error correction method",
                        "define rewriting method",
                        "minimize cell level changes",
                        "introduce 1st probabilistic model",
                        "compute new cell levels",
                        "introduce 2nd probabilistic model",
                        "compute new cell levels",
                        "specify matrix AN\u00d7N",
                        "generate dither",
                        "compute new cell levels",
                        "define vector y",
                        "compute u_FWOM\u2212FC",
                        "compute u_FC",
                        "compute W_N^(i)",
                        "define base cases for W_N^(i)",
                        "compute L_N^(i)",
                        "define WOM cell levels",
                        "describe error correction method",
                        "introduce polar code generating matrix",
                        "determine FWOM",
                        "compute FER values",
                        "describe error correction decoding",
                        "introduce binary vector properties",
                        "describe data value generation",
                        "introduce binary matrix AN\u00d7N",
                        "describe subsets FWOM and FC",
                        "describe error distribution",
                        "describe binary vector properties",
                        "introduce polar code decoding algorithm",
                        "recover data values",
                        "describe list-decoding algorithm",
                        "compute ui values",
                        "describe list management",
                        "choose most likely element",
                        "describe stored data error-correcting code",
                        "introduce list size parameter",
                        "compute ui values with list",
                        "choose most likely element",
                        "specify matrix AN\u00d7N",
                        "recover value action",
                        "compute WNi values",
                        "determine ui values",
                        "recover data bits",
                        "specify list-decoding algorithm",
                        "compute WNi values (again)",
                        "update list of value assignments",
                        "choose most likely element",
                        "recover data bits (again)",
                        "specify error-correcting code",
                        "compute WNi values (again)",
                        "update list of value assignments (again)",
                        "choose most likely element (again)",
                        "recover data bits (again)",
                        "specify error-correcting code (again)",
                        "recover data bits (again)",
                        "define WOM cells and operations",
                        "describe rewriting method",
                        "explain error correction method",
                        "introduce FC and FWOM",
                        "describe embodiment of encoding method",
                        "describe embodiment of decoding method",
                        "introduce Nadditional cells",
                        "describe modified encoding method",
                        "describe modified decoding method",
                        "introduce q-level cells",
                        "describe level-by-level approach",
                        "provide example of encoder and decoder",
                        "outline organization of description",
                        "introduce basic model and notations",
                        "describe embodiment of code construction",
                        "describe embodiment of code",
                        "describe embodiment of code extensions",
                        "analyze actual sum-rates achieved by code embodiment",
                        "provide further example embodiments",
                        "include concluding remarks",
                        "define model for rewriting",
                        "introduce polar codes",
                        "define polar code properties",
                        "describe encoder transformation",
                        "explain decoding process",
                        "introduce concept of upgrading and degrading channels",
                        "define channel degradation",
                        "describe code construction with nested structure",
                        "introduce WOM channel parameters",
                        "explain encoding function",
                        "describe decoding operation",
                        "discuss time complexity of encoding and decoding",
                        "extend code to t-write error correcting WOM code",
                        "describe application of encoder and decoder for t writes",
                        "note on computing \u03b1 values for BSC(p)",
                        "introduce code construction",
                        "revise encoder and decoder",
                        "derive sum-rate equation",
                        "analyze correctness of code",
                        "discuss nested structure of code",
                        "prove Lemma 1",
                        "prove Lemma 2",
                        "prove Lemma 3",
                        "prove Lemma 4",
                        "analyze lower bound to sum-rate",
                        "derive equation for number of bits written",
                        "derive sum-rate equation",
                        "prove lemma 5",
                        "state theorem 6",
                        "prove theorem 6",
                        "show numerical results",
                        "introduce erasure channel",
                        "describe handling erasures",
                        "extend to multi-level cells",
                        "discuss achievable rates",
                        "find BSCs satisfying condition",
                        "show achievable sum-rates for nested code",
                        "show achievable sum-rates for general code",
                        "discuss lower bound to sum-rate",
                        "conclude with remarks on code performance"
                    ],
                    "num_characters": 69976,
                    "outline_medium": [
                        "introduce patent application structure",
                        "motivate joint rewriting and error correction in write-once memories",
                        "summarize code construction for error-correcting WOM codes",
                        "define WOM code constraints and conditions",
                        "describe write process with error correction",
                        "illustrate example write process with block diagram",
                        "outline method for encoding data value into codeword",
                        "detail operations for determining current cell levels, generating next cell levels, and writing next cell levels into memory",
                        "explain rewriting operation and error correction method",
                        "describe generation of next cell levels using binary matrix and dither vector",
                        "define rewriting method",
                        "minimize cell level changes",
                        "introduce 1st probabilistic model",
                        "compute new cell levels",
                        "introduce 2nd probabilistic model",
                        "specify matrix AN\u00d7N",
                        "compute cell levels sequentially",
                        "define WOM cell levels",
                        "describe error correction method",
                        "introduce polar code generating matrix",
                        "determine FWOM",
                        "describe decoding operation",
                        "generate data value",
                        "provide data value to destination",
                        "describe error distribution",
                        "recover data values",
                        "describe list-decoding algorithm",
                        "specify decoding algorithm for error-correcting code",
                        "specify matrix AN\u00d7N",
                        "recover value action",
                        "compute values of WNi",
                        "specify list-decoding algorithm",
                        "compute values of WNi (again)",
                        "specify method for error-correcting code",
                        "compute values of WNi (again)",
                        "specify method for error-correcting code (again)",
                        "define WOM cells and operations",
                        "describe rewriting method",
                        "describe error correction method",
                        "introduce example embodiment",
                        "outline remaining sections",
                        "introduce basic model and notations",
                        "describe rewriting model",
                        "describe error correction model",
                        "define rate and sum-rate of code",
                        "mention unknown maximum sum-rate for noisy WOM",
                        "introduce polar codes",
                        "describe polar code construction",
                        "motivate code construction embodiments",
                        "describe basic code construction with nested structure",
                        "detail encoder and decoder operations",
                        "extend code to multiple writes",
                        "discuss code improvement",
                        "revise encoder algorithm",
                        "derive sum-rate equation",
                        "prove correctness of code",
                        "analyze size of FWOM(\u03b1,\u03b5)\u2229FBSC(p)",
                        "derive lower bound to sum-rate",
                        "derive sum-rate equation",
                        "prove lemma 5",
                        "prove theorem 6",
                        "describe extensions to other noise models",
                        "discuss additional information on achievable rates",
                        "find BSCs satisfying FBSC(p)FWOM(\u03b1\u03b5)",
                        "discuss achievable sum-rates for nested and general codes"
                    ],
                    "outline_short": [
                        "introduce joint rewriting and error correction in write-once memories",
                        "motivate coding scheme for error-correcting WOM codes",
                        "describe cell programming method with rewriting and error correction functions",
                        "illustrate example write process with error correction using polar encoder and WOM channel devices",
                        "outline method for encoding data value into codeword for rewriting WOM",
                        "define probabilistic models",
                        "describe rewriting method",
                        "compute new cell levels",
                        "describe error correction method",
                        "detail decoding algorithm",
                        "specify properties of binary vector",
                        "outline error distribution and correction",
                        "illustrate flow diagram of decoding method",
                        "specify matrix AN\u00d7N",
                        "recover value action",
                        "describe list-decoding algorithm",
                        "handle error-correcting code C",
                        "define WOM cells and rewriting process",
                        "describe error correction and decoding methods",
                        "introduce example embodiment of encoder and decoder",
                        "outline organization of remainder of description",
                        "introduce basic model and notations",
                        "introduce polar codes",
                        "describe code construction embodiments",
                        "detail encoder and decoder operations",
                        "revise encoder and decoder algorithms",
                        "analyze code correctness and performance",
                        "derive sum-rate equation",
                        "prove lemmas and theorem",
                        "discuss extensions and additional information"
                    ]
                }
            ],
            "outline_long": [],
            "num_characters": 0,
            "outline_medium": [],
            "outline_short": []
        }
    ],
    "claims": [
        "1. A method to rewrite a memory, the method comprising:\ndetermining respective current cell charge levels of a plurality of cells of the memory;\ngenerating a plurality of next cell charge levels for the plurality of cells according to a linear transformation that includes multiplication of an input vector that includes input data by a matrix of N rows and N columns, wherein each next cell charge level is generated based on a corresponding one of the current cell charge levels and based on the input data, wherein each next cell charge level is greater than or equal to the corresponding one of the current cell charge levels, wherein the plurality of next cell charge levels represent the input data, and wherein the plurality of next cell charge levels include redundancy for error correction; and\nstoring the plurality of next cell charge levels in the memory.",
        "2. (canceled)",
        "3. The method of claim 1, wherein the matrix is equal to a m-th Kronecker\nproduct of G2, wherein\n\n\n\\({G_{2} = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}},\\)\nand N=2m.",
        "4. (canceled)",
        "5. The method of claim 1, wherein generating the plurality of next cell charge levels according to the linear transformation comprises:\ngenerating a first subset of the input vector which are equal to a value of the input data, and a second subset of the input vector which are equal to a constant.",
        "6. The method of claim 5, further comprising:\nindexing the input vector such that each bit of the input vector has an index indicating a position within an order of the bits of the input vector, wherein the bits of the first subset of the input vector have indices in a set defined by dataset FWOM-dataset FC , and the bits of the second subset of the input vector have indices in a set defined by dataset FC, wherein dataset FC is a set including at least one element, wherein dataset FWOM is a set including M elements which are not in dataset FC, wherein M is an integer, wherein at least one index is in neither dataset FWOM nor dataset FC, and wherein dataset FC is a subset of dataset FWOM.",
        "7. The method of claim 6, wherein generating the plurality of next cell charge levels according to the linear transformation further comprises:\ncalculating a plurality of before write values, each based on a corresponding current cell charge level and on a corresponding dither value of a plurality of dither values, wherein each before write value is equal to the corresponding current cell charge level XOR'd with the corresponding dither value; and\ncalculating a plurality of after write values, each based on the corresponding next cell charge level and the corresponding dither value of the plurality of dither values, wherein each after write value is equal to the corresponding next cell charge level XOR'd with the corresponding dither value.",
        "8. The method of claim 7, wherein the plurality of after write values is equal to the input vector multiplied by the matrix, and the plurality of next cell charge levels is equal to a bit-wise XOR of the plurality of after write values and the plurality of dither values.",
        "9. The method of claim 7, wherein the plurality of dither values includes a plurality of pseudo-random numbers.",
        "10. The method of claim 6, wherein generating the plurality of next cell charge levels according to the linear transformation comprises generating the bits in the input vector according to a linear transformation that includes calculation of the bits in the input vector having an index which is in neither dataset FWOM nor dataset FC.",
        "11. The method of claim 6, wherein the matrix is a generating matrix of a polar code and dataset FWOM is in a frozen set of the polar code.",
        "12. (canceled)",
        "13. A method to read a memory, the method comprising:\ndetermining respective current cell charge levels of a plurality of cells of the memory, wherein the current cell charge levels represent data and error correction information;\ngenerating a plurality of data values based on a linear transformation that includes a multiplication of an input vector by a matrix of N rows and N columns of the current cell charge levels; and\ntransmitting the plurality of data values to a data destination.",
        "14. The method of claim 13, wherein the input vector equals a bit-wise XOR of the current cell charge levels and a plurality of dither values.",
        "15. (canceled)",
        "16. The method of claim 13, wherein multiplying the input vector by the matrix includes multiplying the input vector by an inverse of a generating matrix of a polar code.",
        "17.-18. (canceled)",
        "19. The method of claim 13, wherein the current cell charge levels define an error-correcting code that pertains to the error correction information, and wherein generating the plurality of data values comprises:\ndetermining a set of data values; and\nverifying that the set of data values is consistent with the error-correcting code.",
        "20. The method of claim 13, further comprising:\ngenerating the input vector wherein:\nthe input vector comprises a first subset of bits which correspond with the plurality of data values, and a second subset of bits which are equal to a constant,\nthe bits of the input vector are indexed such that each bit has an index indicating a position within the input vector; and\nthe first subset of bits have indices in dataset FWOMdataset FC, and the second subset of bits have indices in dataset FC, wherein dataset FC is a set including at least one element, wherein dataset FWOM is a set including M elements which are not in dataset FC, wherein M is an integer, wherein at least one index is in neither dataset FWOM nor dataset FC, and wherein dataset FC is a subset of dataset FWOM, and\nwherein the linear transformation comprises calculating a plurality of bit values, wherein the bit values comprise a first subset of bit values which correspond with the plurality of data values, and a second subset of bit values which are equal to the constant.",
        "21. A memory system, comprising:\na memory that includes a plurality of cells;\na processor coupled to the memory and configured to determine respective current cell charge levels of the plurality of cells of the memory;\nan encoder coupled to the memory and to the processor, and configured to generate a plurality of next cell charge levels according to a linear transformation that includes multiplication of an input vector that includes input data, by a matrix of N rows and N columns, wherein each next cell charge level is generated based on a corresponding one of the current cell charge levels and based on the input data, wherein each next cell charge level is greater than or equal to the corresponding one of the current cell charge levels, wherein the plurality of next cell charge levels represent the input data, and wherein the plurality of next cell charge levels include redundancy for error correction; and\na write device coupled to the encoder and memory, and configured to store the plurality of next cell charge levels in corresponding cells of the plurality of cells of the memory.",
        "22.-24. (canceled)",
        "25. The system of claim 21, wherein the input vector comprises bits and wherein:\na first subset of the bits of the input vector are equal to a value of the input data, and a second subset of the bits of the input vector are equal to a constant.",
        "26. The system of claim 25, wherein the bits of the input vector indexed such that each bit has an index indicating a position within an order of bits, wherein the bits of the first subset have indices in dataset FWOM-dataset FC, and the bits of the second subset have indices in dataset FC, wherein dataset FC is a set including at least one element, wherein dataset FWOM is a set including M elements which are not in dataset FC, wherein M is an integer, wherein at least one index is in neither dataset FWOM nor dataset FC, and wherein dataset FC is a subset of dataset FWOM.",
        "27. The system of claim 26, wherein the linear transformation comprises:\na calculation of a plurality of before write values, each based on a corresponding current cell charge level and on a corresponding dither value of a plurality of dither values, wherein each before write value is equal to the corresponding current cell charge level XOR'd with the corresponding dither value; and\na calculation of a plurality of after write values, each based on a corresponding next cell charge level and the corresponding dither value, wherein each after write value is equal to the corresponding next cell charge level XOR'd with the corresponding dither value.",
        "28. The system of claim 27, wherein the plurality of after write values is equal to the input vector multiplied by the matrix, and the plurality of next cell charge levels is equal to the bit-wise XOR of the plurality of after write values and the plurality of dither values.",
        "29. The system of claim 27, wherein the plurality of dither values includes a plurality of pseudo-random numbers.",
        "30. The system of claim 26, wherein the linear transformation comprises a calculation of the input vector having an index which is in neither dataset FWOM nor dataset FC.",
        "31. The system of claim 26, wherein the matrix is a generating matrix of a polar code and dataset FWOM is in a frozen set of the polar code.",
        "32. The system of claim 21, wherein a number of the plurality of next cell charge levels which have different values from the corresponding one of the current cell charge levels is minimized.",
        "33. A memory system, comprising:\na memory that includes a plurality of cells;\na processor coupled to the memory and configured to determine respective current cell charge levels of the plurality of cells of the memory, wherein the current cell charge levels represent data and error correction information;\na decoder coupled to the processor and to the memory, and configured to generate a plurality of data values, wherein the plurality of data values are generated based on a linear transformation that includes a multiplication of an input vector by a matrix of N rows and N columns of the current cell charge levels; and\na transmitter coupled the decoder and configured to transmit the plurality of data values to a data destination.",
        "34. (canceled)",
        "35. The system of claim 33, wherein the matrix is equal to a m-th Kronecker product of G2, wherein\n\n\\({G_{2} = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}},\\)\nand N=2m.",
        "36. The system of claim 33, wherein the matrix includes a generating matrix of a polar code.",
        "37. The system of claim 33, wherein the linear transformation implements one of a list-decoding algorithm and a belief-propagation algorithm.",
        "38.-40. (canceled)",
        "41. The system of claim 33, wherein the data and error correction information of the current cell charge levels are encoded such that a bit-wise XOR of the current cell charge levels and a plurality of dither values equals the the input vector, wherein the input vector includes a first subset of positions representing the data, and a second subset of subset having constant values."
    ]
}