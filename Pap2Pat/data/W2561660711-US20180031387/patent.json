{
    "id": "US20180031387",
    "authors": [
        "Sebastian Scherer",
        "Song Yu",
        "Stephen Nuske"
    ],
    "title": "STATE ESTIMATION FOR AERIAL VEHICLES USING MULTI-SENSOR FUSION",
    "date": "2017-07-31 00:00:00",
    "abstract": "A state estimation system that utilizes long-range stereo visual odometry that can degrade to a monocular system at high-altitude, and integrates GPS, Barometer and IMU measurements. The system has two main parts: An EKF that is loosely fused and a long-range visual odometry part. For visual odometry, the system takes the EKF information for robust camera pose tracking, and the visual odometry outputs will be the measurement for EKF state update.",
    "sections": [
        {
            "title": "DESCRIPTION",
            "paragraphs": [],
            "subsections": [
                {
                    "title": "TECHNICAL FIELD",
                    "paragraphs": [
                        "Embodiments herein generally relate to the field of aerial vehicles, and, more particularly, micro-aerial vehicles using multiple absolute and relative sensors for state estimation."
                    ],
                    "subsections": [],
                    "outline_long": [
                        "define technical field of aerial vehicles"
                    ],
                    "num_characters": 181,
                    "outline_medium": [
                        "define technical field of aerial vehicles"
                    ],
                    "outline_short": [
                        "define technical field of aerial vehicles"
                    ]
                },
                {
                    "title": "BACKGROUND OF THE INVENTION",
                    "paragraphs": [
                        "Light weight Micro-Aerial Vehicles (MAVs) equipped with sensors can autonomously access environments that are difficult to access for ground robots. Due to this capability, MAVs have become popular in many robot missions, e.g., structure inspection, environment mapping, reconnaissance and large-scale data gathering. Compared with ground robots, there are two main challenges for MAV autonomous navigation: (1) limited payload, power and onboard computing resources, allowing only light-weight compact sensors (like cameras) to be integrated for MAV applications; and (2) MAVs usually move with fast and aggressive six degrees of freedom (DoF) motions. Accordingly, their state estimation, environment perception and obstacle avoidance are more difficult than ground robots.",
                        "For aerial vehicles, and, in particular, for micro-aerial vehicles (MAVs), state estimation is the most critical capability for localization, autonomous obstacle avoidance, robust flight control and 3D environmental mapping. There are three main challenges for a MAV state estimator: (1) it must be able to deal with aggressive 6 degree of freedom (DoF) motion; (2) it should be robust to intermittent global positioning system (GPS) situations, and even to GPS-denied situations; and (3) it should work well both for low- and high-altitude flight.",
                        "Robust, accurate and smooth high-rate state estimation is the most critical capability to realize truly autonomous flight of MAVs. The state estimator reports the six DoF MAV position, orientation and the velocity, so the output of the estimator serves as the input for environment mapping, motion planning and trajectory-following control. Global positioning system (GPS) combined with the inertial measurement unit (IMU) state estimation technique has been widely utilized for providing MAV high-rate state information. However, applications of low-rate GPS are limited to open environments. Furthermore, GPS cannot provide accurate positioning information for MAVs, especially in terms of altitude.",
                        "As a complimentary sensor for GPS, the IMU measures tri-axis accelerations and rotation rates in the IMU body frame, and the velocity and orientation are calculated as the integral of accelerations and rotation rates over time. For low-cost commercial IMUs, the inertia integral will drift very fast without global rectification information. As a result, the integration of additional sensing is a way to further improve state estimation redundancy, accuracy and robustness.",
                        "Because of the low cost, low energy consumption and satisfactory accuracy, camera-based visual odometry (VO) is an ideal choice for providing additional measurements. Stereo visual sensors reconstruct the environment features with the metric scale from the stereo baseline, so stereo-based VO easily generates six DoF pose measurements. The performance of stereo VO highly depends on the ratio between the stereo baseline and environmental depth, namely the baseline-depth ratio. The depth standard deviation from stereo is proportional to the quadratic of depth; thus, stereo VO is limited to short range measurements. At stereo disparities lower than 10 pixels, the depth triangulation from a single stereo rig tends to follow a non-Gaussian curve with a long tail. For cases with a large baseline-depth ratio (e.g., MAV high-altitude flights), the stereo effectively degenerates to a monocular system, thus losing the capability of pose measurements."
                    ],
                    "subsections": [],
                    "outline_long": [
                        "introduce micro-aerial vehicles",
                        "motivate state estimation",
                        "describe challenges of state estimation",
                        "discuss limitations of GPS",
                        "discuss limitations of IMU",
                        "discuss limitations of stereo visual odometry"
                    ],
                    "num_characters": 3459,
                    "outline_medium": [
                        "motivate MAV applications",
                        "describe challenges of MAV navigation",
                        "summarize importance of state estimation"
                    ],
                    "outline_short": [
                        "motivate state estimation for micro-aerial vehicles"
                    ]
                },
                {
                    "title": "SUMMARY OF THE INVENTION",
                    "paragraphs": [
                        "A novel state estimation technique is presented herein that is capable of fusing long-range stereo visual odometry (VO), GPS, barometric and inertial measurement unit (IMU) measurements. The integration is performed by an onboard processor executing software embodying the present invention.",
                        "The state estimation system utilizes long-range stereo visual odometry that can degrade to a monocular system at high altitude and integrates GPS, barometric and IMU measurements. The estimation system has two main parts: an EKF estimator that loosely fuses both absolute state measurements (for example, GPS and barometer) and the relative state measurements (for example, IMU and VO). A long-range stereo VO is designed both for low- and high-altitude odometry calculations.",
                        "The odometry takes the EKF prediction information for robust camera pose tracking and feature matching, and the stereo VO outputs serve as the relative measurements for the update of the EKF state. There are three main highlights for the system:",
                        "(1) The state estimation system utilizes both absolute state measurement sensors (GPS, barometer), the relative six DoF pose state measurement provided by VO. To deal with both absolute and relative state measurements effectively, a new stochastic cloning EKF state estimator to generate accurate and smooth state estimation both for GPS-available and GPS-denied environments is presented.",
                        "(2) A robust long-range stereo VO that works well both for low- and high-altitude cases is presented. At low altitude, the VO utilizes stereo images where the features are directly triangulated by stereo pairs with a fixed static stereo baseline. At high altitude, the ratio between the scene depth and stereo baseline becomes large, and the stereo pair effectively degenerates to a monocular system. In this situation, the additional stereo observations over time are fused by both multi-stereo triangulation and a multi-view stereo inverse depth filter for long-range feature depth generation.",
                        "(3) The EKF estimator and long-range VO coordinate to improve the robustness of the system. The IMU integral prediction information from the EKF estimator is used both for guiding image-feature matching and long-range VO optimization. Additionally, the VO is utilized as the relative measurement for the update of the EKF state."
                    ],
                    "subsections": [],
                    "outline_long": [
                        "introduce novel state estimation technique",
                        "describe system architecture",
                        "highlight stochastic cloning EKF state estimator",
                        "highlight robust long-range stereo VO"
                    ],
                    "num_characters": 2334,
                    "outline_medium": [
                        "introduce novel state estimation technique",
                        "outline system components and functionality"
                    ],
                    "outline_short": [
                        "introduce novel state estimation technique"
                    ]
                },
                {
                    "title": "DETAILED DESCRIPTION",
                    "paragraphs": [
                        "The following description is presented to enable any person skilled in the art to make and use the invention. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art, and the general principles defined herein may be applied to other embodiments and applications without departing from the scope of the present invention. Thus, the present invention is not intended to be limited to the embodiment shown. Although the invention is described in terms of micro-aerial vehicles, one of skill in the art should realize that the invention is applicable to any aerial vehicle.",
                        "In some embodiments of the invention, a technique for state estimation by fusing long-range stereo visual odometry, GPS, barometric and IMU are provided. In one embodiment of the invention, the system is realized utilizing an onboard processor running software implementing the functions of the invention however, it should be realized that any system capable of implementing the functions of the invention could be used. There are two main parts to the system.",
                        "In a first aspect of the invention, the state estimation system utilizes both absolute state measurement sensors (GPS, barometer), and relative sensors, (IMU and the six DoF pose state measurement provided by VO). A block diagram of the system is shown in FIG. 1. To incorporate both absolute and relative state measurements effectively, a new stochastic cloning EKF state estimator to generate accurate and smooth state estimation both for GPS-available and GPS-denied environments is presented.",
                        "In a second aspect of the invention, a robust long-range stereo VO that works well both for low- and high-altitude cases is provided. At low altitude, the VO utilizes stereo images, wherein features are directly triangulated by stereo pairs with a fixed static stereo baseline. At high altitude, the ratio between the scene depth and stereo baseline becomes large, and the stereo pair almost degenerates to a monocular system. In this situation, the additional stereo observations over time are fused by both multi-stereo triangulation and a multi-view stereo inverse depth filter for long-range feature depth generation.",
                        "A new stochastic cloning EKF system is presented to fuse both absolute measurements (GPS, and Barometer) and relative measurement (VO and IMU measurement) loosely for GPS-available and GPS-denied environments. To avoid the system state be overwhelmed by VO, a delayed pose and its covariance is kept in the EKF state estimation system, and the measurement Jacobian for VO measurement is derived and analyzed. As shown in FIG. 2(a-b), there are two key features for the system state after a relative VO update and a GPS (or barometer) absolute update, respectively.",
                        "FIG. 2a shows an EKF state estimation system updated by a relative measurement (e.g., VO relative measurement). After a VO relative measurement update, the updated covariance should have two important properties: (1) it should be lower than the IMU state propagation covariance, since VO information is available to the system; and (2) it must be increased compared with previous error covariance. Otherwise, the absolute measurement (GPS and barometer) will lose the ability to update the state estimation. Compared with pseudo absolute measurement VO update approaches, the covariance using delayed state cloning EKF can meet the two properties.",
                        "FIG. 2b shows an EKF state estimation system updated by absolute measurement (e.g., GPS measurement). After an absolute measurement update of the EKF state by the GPS or barometer, both the current pose covariance and the delayed pose covariance are decreased. Furthermore, the current pose covariance should be higher than the delayed pose covariance. Otherwise, the VO relative measurement will lose the ability to update the EKF state.",
                        "For IMU integral state prediction, the new uncertainty from the delayed pose to the current pose is Q. So, Q is expressed as:",
                        "FPlFT+Q=\u03a0FiPl(\u03a0Fi)T+",
                        "For a relative measurement update, the VO covariance should be balanced with Q. The relationship between current pose covariance and the delayed pose covariance is given in the current state covariance. The new uncertainty Q from system covariance is calculated, as shown in FIG. 3.",
                        "The relationship between the current pose covariance and the delayed pose covariance is:",
                        "FPlFT+Q=Ps",
                        "For covariance Psl:",
                        "FPl=Psl",
                        "As a result, the new uncertainty Q is calculated as:",
                        "Q=Ps\u2212Psl(Pl)\u22121PslT",
                        "On the basis of Q, the VO covariance is given by balancing the system \u201cweight,\u201d that is:",
                        "Rvo=kQ",
                        "where, k is a positive integer number, it can be initially set as k=1.",
                        "The Chi-square test at 0.95 is utilized to verify the compatibility of the VO relative measurement. If the test fails, that means VO covariance should be larger, and the VO covariance as can be smoothed as:",
                        "Rvo*=10",
                        "Current stereo VO algorithms are limited in short-range. In one embodiment provided herein a stereo VO implementation to make stereo VO robust for MAV long-range high-altitude applications is provided. The pipeline of the long-range stereo VO is shown in FIG. 4. It is a key-frame-based VO technique. The local map consists of a set of 3D sparse map points that is generated by selected key-frames. IMU information is integrated to improve the robustness for aggressive camera motion and repetitive texture environments. Based on the current stereo baseline-depth ratio, the VO system switches both key-frame and new map point generation strategies between stereo and monocular modes.",
                        "In short range mode (e.g., MAV low-altitude flight, as shown in FIG. 5a), the VO works in a stereo mode. For each new selected key-frame, most of the new features are directly triangulated by a stereo camera pair with a static stereo baseline. Some long-range points are triangulated using both the pseudo-baseline formed by the key-frame's poses and the static stereo baseline. In stereo mode, the environment structure is close to the camera; the image context easily changes, especially for camera rotation. Therefore, the key-frames and its features are inserted into the local map relatively densely.",
                        "In long range mode (e.g., high-altitude flight, as shown in FIG. 5b), the VO switches to monocular mode, as shown in FIG. 4. The key-frames are inserted sparsely to provide enough relative motion between the key-frames for long-range triangulation. When VO is in a long-range mode, no features will be directly triangulated by static stereo. Because most of the \u201cshort-range points\u201d will be outliers due to an incorrect matching from a low or repetitive texture area, such as sky, cloud and trees, the new features will first be triangulated using both a dynamic pseudo baseline and a static stereo baseline (multi-view stereo triangulation). New features that cannot be triangulated by the pseudo baseline are inserted into a \u201ccandidate queue\u201d. The feature depth will be iteratively refined by subsequently tracking stereo information with a multi-view inverse depth filter. If the inverse depth converges, the candidate feature will be added into the map and then used for camera pose tracking.",
                        "Long-range depth generation by multi-view stereo triangulation: New long-range points without depth will first be triangulated using both the pseudo-baseline and the static stereo baseline from multi-view stereo measurements. The pseudo baseline is formed by the \u201crelative pose\u201d between the neighboring key-frames. As shown in FIG. 6, the current left image feature is searched in the previous key-frame's left image feature set on the basis of an epipolar constraint, and for each key-frame, the matched feature pairs also have their own corresponding features in the right image. As shown in FIG. 6, between the two frames, the camera motions R and T provide a dynamic pseudo baseline, and for each stereo frame, the feature position is constrained by the static stereo baseline.",
                        "Long-range depth generation by multi-view stereo inverse depth filtering: The triangulation of the inter-key-frames is a delayed depth generation approach, as only features that can be viewed by at least two key-frames can be triangulated. For the exploration mode (e.g., the stereo moves forward), there are some new features that belong to the current key-frame. Thus, they cannot be triangulated in time. An illustrative example is shown in FIG. 7. To also apply these kinds of new features for subsequent camera pose tracking, an inverse depth filter is used for each new candidate.",
                        "FIG. 7 shows an example of the camera exploration mode. For the k-th key-frame; the dots indicate the \u201cold\u201d features that have been matched with the map; the triangles are the new features that await triangulation. For the (k+1)-th key-frame, triangle features can be triangulated, and some new features (red rectangle) wait for the next key-frame for triangulation. Between the (k+1)-th key-frame and the (k+2)-th key-frame, there is a set of tracking frames that also can provide useful measurements for the new features, represented by squares. All multi-view observations for the new feature are integrated using an inverse depth filter."
                    ],
                    "subsections": [
                        {
                            "title": "Long Range Stereo Odometry Pipeline",
                            "paragraphs": [
                                "As previously discussed, stereo depth reconstruction with a fixed static baseline is limited to a short range. For static stereo triangulation, the feature depth z is associated with the stereo matching disparity d. Suppose the stereo matching disparity has variance \u03c3d2; the triangulated depth variance \u03c3d2 by stereo is as Equation (1). It is clear that the stereo depth standard deviation \u03c3z is proportional to a quadratic of depth z. The depth error increases very quickly for the small disparity, long-range stereo measurements and, thus, cannot be utilized for VO optimization.",
                                "\\(\\begin{matrix}\n{\\sigma_{z}^{2} = {{\\left( \\frac{\\partial z}{\\partial d} \\right)^{2}\ue89e\\sigma_{d}^{2}} = {{\\frac{f_{x}^{2}\ue89eB^{2}}{d^{4}}\ue89e\\sigma_{d}^{2}} = {\\frac{z^{4}}{f_{x}^{2}\ue89eB^{2}}\ue89e\\sigma_{d}^{2}}}}} & (1)\n\\end{matrix}\\)",
                                "Long-range stereo depth error (bias) can be effectively reduced by introducing additional stereo observation over time, namely multi-view stereo with a dynamic pseudo baseline. The pseudo baseline between the stereo frames can be used for the triangulation of the long-range stereo points. The fixed stereo baseline can provide an absolute scale constraint. Based on this idea, a sparse feature-based stereo VO both for short- and long-range cases was developed. The pipeline of the proposed long-range stereo VO is shown in FIG. 4. It is a key-frame-based VO technique. The local map consists of a set of 3D sparse map points that is generated by selected key-frames. Furthermore, IMU information is integrated to further improve the robustness for aggressive camera motion and repetitive texture environments. Based on the current stereo baseline-depth ratio, the VO system switches both key-frame and new map point generation strategies between stereo and monocular modes:",
                                "For a short range (e.g., MAV low-altitude flight, as shown in FIG. 5(a), the VO works with a stereo mode. For each new selected key-frame, most of the new features are directly triangulated by the stereo camera pair with the static stereo baseline. For some long-range points, they are triangulated using both the pseudo-baseline formed by the key-frame's poses and the static stereo baseline. In stereo mode, the environment structure is close to the camera; the image context easily changes especially for camera rotation. Therefore, the key-frames and its features are inserted into the local map relatively densely.",
                                "For a long range (e.g., high-altitude flight, as shown in FIG. 5(b), the VO switches to monocular mode. The key-frames are inserted sparsely to provide enough relative motion between the key-frames for long-range triangulation. When VO is in a long-range mode, no features will be directly triangulated by static stereo. Because most of the \u201cshort-range points\u201d will be outliers due to an incorrect matching from a low or repetitive texture area, such as sky, cloud and trees, instead, the new will first be triangulated using both a dynamic pseudo baseline and a static stereo baseline. The new features that cannot be triangulated by the pseudo baseline are inserted into a \u201ccandidate queue\u201d. The feature depth will be iteratively refined by subsequently tracking stereo information with a multi-view inverse depth filter. If the inverse depth converges, the candidate feature will be added into the map and then used for camera pose tracking.",
                                "**Long-Range Point Generation Using Multi-View Stereo Triangulation**",
                                "The most critical aspect for long-range stereo is feature depth generation. For each new key-frame, its features can be classified into three groups: (1) the features have been matched with the map. (2) new features with an effective stereo depth (i.e, short-range points, with enough stereo disparity). (3) new features with small disparities (long-range points).",
                                "The new long-range points without depth will first be triangulated using both the pseudo-baseline and the static stereo baseline from multi-view stereo measurements. The pseudo baseline is formed by the \u201crelative pose\u201d between the neighboring key-frames. As shown in FIG. 6, the current left image feature is searched in the previous key-frame's left image feature set on the basis of an epipolar constraint, and for each key-frame, the matched feature pairs also have their own corresponding features in the right image. To make the matching more robust, the epipolar constraint between right image features is also checked. As a result, for each new map point, four matched features can be obtained between two key-frames, and the map point is triangulated as the intersection point of the four rays in the sense of least-squares.",
                                "**Long-Range Point Generation by Multi-View Stereo Inverse Depth Filtering**",
                                "The inter-key-frames' triangulation is a kind of delayed depth generation approach because only features that can be viewed by at least two key-frames can be triangulated. For the exploration mode (e.g., the stereo moves forward), there are some new features that belong to the current key-frame itself; thus, they cannot be triangulated in time. An illustrative example is shown in FIG. 7. To also apply these kinds of new features for subsequent camera pose tracking, an inverse depth filter for each new candidate was designed. For stereo, the inverse depth",
                                "\\(\\rho = {\\frac{1}{z} = \\frac{d}{f_{x}\ue89eB}}\\)",
                                "is proportional to disparity d; as a result, the inverse depth uncertainty is easily modeled by a Gaussian distribution:",
                                "\\(\\begin{matrix}\n{\\sigma_{\\rho}^{2} = {\\frac{1}{f_{x}^{2}\ue89eB^{2}}\ue89e\\sigma_{d}^{2}}} & (2)\n\\end{matrix}\\)",
                                "For each long-range candidate feature that belongs to the new inserted key-frame, its initial inverse depth prior is directly obtained from noisy static stereo depth triangulation, denoted as",
                                "\\(\ue89e\\left( {\\rho_{0}\ue89e\\frac{1}{f_{x}^{2}\ue89eB^{2}}\ue89e\\sigma_{d}^{2}} \\right)\\)",
                                "During the subsequent pose tracking, each new tracking frame is utilized to filter the initial distribution",
                                "\\({\ue89e\\left( {\\rho_{0}\ue89e\\frac{1}{f_{x}^{2}\ue89eB^{2}}\ue89e\\sigma_{d}^{2}} \\right)},\\)",
                                "and the new feature candidate will be added to the map until its inverse depth variance is smaller than a given threshold. Ideally, for each new tracking frame, two new observations can be obtained for the candidate feature: (1) the inverse depth observation distribution for the candidate is calculated from the tracking frame static stereo matching; and (2) the inverse depth observation distribution can also be obtained by the dynamic pseudo baseline formed by the motion between the current tracking frame and its reference key-frame. Therefore, the filtered inverse depth distribution can be updated by the two new observations.",
                                "Denote as the 3D coordinate of a candidate feature with z0=1 as P0=(x0, y0, 1)T in the key-frame coordinate and its corresponding matching point in the current tracking frame with z1=1 as P1=(x1, y1, 1)T. The motion from the key-frame to the current tracking frame is R10, t10=(tx, ty, tz)T, so the relationship of the two points is:",
                                "\\(\\begin{matrix}\n{{\\frac{1}{\\rho_{1}}\ue89eP_{1}} = {{\\frac{1}{\\rho_{0}}\ue89eR_{10}\ue89eP_{0}} + t_{10}}} & (3)\n\\end{matrix}\\)",
                                "where \u03c10 and \u03c11 represent the inverse depth measurements in the current tracking frame and key-frame, respectively.",
                                "For the current tracking frame, we observe the inverse depth stereo \u03c11 with its variance. Therefore, the new measured inverse depth and its variance in the key-frame coordinate are calculated by projecting the new measurement",
                                "\\(\ue89e\\left( {\\rho_{1}\ue89e\\frac{1}{f_{x}^{2}\ue89eB^{2}}\ue89e\\sigma_{d}^{2}} \\right)\\)",
                                "to the key-frame coordinate based on the last row of Equation (3):",
                                "\\(\\begin{matrix}\n{{\\rho_{0}^{s} = \\frac{\\frac{1}{\\rho_{1}} - t_{z}}{\\left| {{R_{10}\ue8a0(3)}\ue89eP_{0}} \\right.}}\ue89e\ue89e{\\sigma_{\\rho_{0}^{s}}^{2} = {\\left( \\frac{\\rho_{0}^{s}}{\\rho_{1}} \\right)^{4}\ue89e\\left( \\frac{1}{{R_{10}\ue8a0(3)}\ue89eP_{0}\ue89ef_{x}\ue89eB} \\right)^{2}\ue89e\\sigma_{d}^{2}}}} & (4)\n\\end{matrix}\\)",
                                "where R10 (3) represents the third row of rotation matrix R10 and \u03c3d2 is the new stereo disparity variance in the current tracking frame (set \u03c3d2=1).",
                                "The inverse depth triangulation distribution using the motion from the key-frame to the current tracking frame is also derived from Equation (3) (with the first row and the last row):",
                                "\\(\\begin{matrix}\n{{\\rho_{0}^{e} = \\frac{{{R_{10}\ue8a0(1)}\ue89eP_{0}} - {{R_{10}\ue8a0(3)}\ue89eP_{0}\ue89ex_{1}}}{{t_{z}\ue89ex_{1}} - t_{x}}}\ue89e\ue89e{\\sigma_{\\rho_{0}^{e}}^{2} = {\\left( \\frac{{{R_{10}\ue8a0(3)}\ue89eP_{0}\ue89et_{x}} - {{R_{10}\ue8a0(1)}\ue89eP_{0}\ue89et_{z}}}{\\left( {{t_{z}\ue89ex_{1}} - t_{x}} \\right)^{2}\ue89ef_{x}} \\right)^{2}\ue89e\\sigma_{u\ue89e\\; \ue89e1}^{2}}}} & (5)\n\\end{matrix}\\)",
                                "where R10 (1) represents the first row of rotation matrix R10 and \u03c3u12 describes the matching error variance along the epipolar line in the current tracking frame; for experimental purposes set \u03c3u12=4. To remove the outlier inverse depth measurements, the two new inverse depth hypotheses are further tested with prior (\u03c10, \u03c3\u03c12) using X2 compatibility testing at 0.95. After passing the test, the posterior of the inverse depth distribution for the candidate feature is updated by multiplying the prior with the new measurements (\u03c102, \u03c3\u03c12) and (\u03c10e, \u03c3\u03c12), that is:",
                                "(\u03c10+,\u03c3\u03c12)=(\u03c10,\u03c3\u03c12)(\u03c10s,\u03c3\u03c12)(\u03c10e,\u03c3\u03c12)\u2003\u2003(6)",
                                "**Local Bundle Adjustment for Multi-View Stereo Optimization**",
                                "The long-range stereo points generated by either triangulation or inverse depth filtering may still be noisy. An effective approach to further improve the feature 3D reconstruction accuracy is multi-view stereo local Bundle Adjustment (BA). During the local BA, the re-projection errors for both left and right images are considered. If the map points are reconstructed with an incorrect scale, the re-projection error on the right images will be large. Accordingly, the \u201cweak\u201d static stereo baseline can provide an absolute scale constraint for local BA optimization. The Jacobian Jpi of the rejection residual \u03b5reproj(i) w.r.t. the map point Pi=(Xi, Yi, Zi)T is:",
                                "\\(\\begin{matrix}\n{{Jp}_{i} = {\\begin{bmatrix}\n{\\frac{\\partial{\u025b_{reproj}\ue8a0(i)}}{\\partial u_{i}^{l}}\ue89e\\frac{\\partial u_{i}^{l}}{\\partial P_{i}}} \\\\\n{\\frac{\\partial{\u025b_{reproj}\ue8a0(i)}}{\\partial v_{i}^{l}}\ue89e\\frac{\\partial v_{i}^{l}}{\\partial P_{i}}} \\\\\n{\\frac{\\partial{\u025b_{reproj}\ue8a0(i)}}{\\partial u_{i}^{r}}\ue89e\\frac{\\partial u_{i}^{r}}{\\partial P_{i}}}\n\\end{bmatrix} = {{- {\\frac{1}{Z_{c}}\ue8a0\\begin{bmatrix}\nf_{x} & 0 & {{- f_{x}}\ue89e\\frac{X_{c}}{Z_{c}}} \\\\\n0 & f_{y} & {{- f_{y}}\ue89e\\frac{Y_{c}}{Z_{c}}} \\\\\nf_{x} & 0 & {{- f_{x}}\ue89e\\frac{X_{c} - B}{Z_{c}}}\n\\end{bmatrix}}}\ue89eR}}} & (7)\n\\end{matrix}\\)",
                                "where Pc=(Xc, Yc, Zc)T is the map point 3D coordinate in the left camera frame system. The first two rows are the residual Jacobian w.r.t. the left image and the last row is for right image. R is the camera rotation matrix. The factor graph for the long-range stereo is shown in FIG. 8, and a unary edge I4\u00d74 is added to each key-frame pose vertex. Consequently, the local BA will mainly focus on the map point optimization, and the key-frame's pose can only be changed in a small range. The factor graph is more like a structure-only bundle adjustment since the camera pose tracking has been fused with the IMU motion information).",
                                "**IMU Tightly-Coupled Odometry Calculation**",
                                "The integration of an IMU motion prior to stereo VO has two advantages: (1) it provides a good initial motion guess for feature guided matching; (2) it gives a motion prior constraint for odometry optimization. A tightly-coupled stereo VO was designed by adding an IMU integral constraint into the 3D-2D re-projection cost non-linear optimization framework. FIG. 9 shows the factor graph for the stereo VO; the camera pose tracking w.r.t. the local map can also be seen as a motion-only bundle adjustment. In this graph, map points and reference frame pose are fixed; only the current pose is set free for optimization. The cost function is:",
                                "\\(\\begin{matrix}\n{\\left. {\\left( {R,t} \\right) = {{argmin}\\left( {{{w\\left( {{\\underset{i = 1}{\\sum\\limits^{\u00a8}}\ue89e{\uf605{I_{i} - {\\pi^{t}\ue8a0\\left( {{P_{i};R},t} \\right)}}\uf606}^{2}} +}\uf606 \\right.}\ue89er_{i}} - {\\pi^{r}\ue8a0\\left( {{P_{i};R},t} \\right)}}\uf606 \\right.}^{2}} \\right) + {\\left( {1 - w} \\right)\ue89e\\left. \uf605\\left( {I_{imu} - \\left( {R,t} \\right)^{T}}\uf606 \\right.^{2} \\right)}} & (8)\n\\end{matrix}\\)",
                                "where the current camera pose (R, t) is calculated by minimizing a non-linear re-projection error cost function. The 3D point in the local map is Pc=(Xi, Yi, Z1); its matched 2D features in the current stereo rig are li=(uil, vil) and ri=(uir, vir) for left and right images; \u03c0l and \u03c0r are the 3D-2D re-projection model for left and right cameras, respectively. N indicates the number of matched features. Iimu denotes the IMU motion integral between the current stereo frame and the reference stereo frame. The term \u2225Iimu\u2212(R, t)T\u22252 represents the IMU integral residual. \u03c9\u2282[0,1] is the weight for the IMU integral constraint.",
                                "The optimal solution for the camera pose tracking is obtained by Levenberg-Marquardt iteration:",
                                "(JxTJx+\u03bbI)\u0394X=\u2212Jx\u03b5x\u2003\u2003(9)",
                                "where Jx and \u03b5x are the Jacobian and residual at current pose x for the stereo pose tracking system. It has the form:",
                                "\\(\\begin{matrix}\n{J_{x} = \\begin{bmatrix}\n{w\ue8a0\\left( J_{reproj} \\right)} \\\\\n{\\left( {1 - w} \\right)\ue89e\\left( I_{6 \\times 6} \\right)}\n\\end{bmatrix}} & (10) \\\\\n{\u025b_{x} = \\begin{bmatrix}\n{w\ue8a0\\left( \u025b_{reproj} \\right)} \\\\\n{\\left( {1 - w} \\right)\ue89e\\left( \u025b_{imu} \\right)}\n\\end{bmatrix}} & (11)\n\\end{matrix}\\)",
                                "where I6\u00d76 is a 6\u00d76 unit matrix. Jreproj is the Jacobian for feature re-projection error. \u03b5reproj is feature re-projection error. \u03b5imu indicates the IMU integral residual. For each map point Pi=(Xi, Yi, Zi)T, its 3D-2D reprojection error \u03b5reproj(i) is calculated as:",
                                "\\(\\begin{matrix}\n{{\u025b_{reproj}\ue8a0(i)} = {{m_{i} - {\\pi \ue8a0\\left( {{P_{i};R},t} \\right)}} = {m_{i} - {{\\frac{1}{Z_{c}}\ue8a0\\begin{bmatrix}\nf_{x} & 0 & u_{0} \\\\\n0 & f_{y} & v_{0}\n\\end{bmatrix}}\ue8a0\\left\\lbrack {{R\ue8a0\\begin{pmatrix}\nX_{i} \\\\\nY_{i} \\\\\nZ_{i}\n\\end{pmatrix}} + t - \\begin{pmatrix}\nB \\\\\n0 \\\\\n0\n\\end{pmatrix}} \\right\\rbrack}}}} & (12)\n\\end{matrix}\\)",
                                "Where mi\u03b5li, ri indicates the measured feature coordinate for the left or the right images. Zc is the feature depth by transforming the map point to the left camera coordinate frame. B=0 for the left camera, and B=\u2212baseline for right camera. fx, fy, u0, v0 are the stereo intrinsic parameters. For the optimization, the minimal parametrization for the camera pose R, t in Lie manifold SE(3) denoted as: X=(\u03b8x, \u03b8y, \u03b8z, tx, ty, tz,)T was used. The Jacobian Jreproj(i) for the 3D-2D re-projection error \u03b5reproj(i) w.r.t. the camera pose X is:",
                                "\\(\\begin{matrix}\n\\begin{matrix}\n{{J_{reproj}\ue8a0(i)} = \ue89e\\begin{bmatrix}\n{\\frac{\\partial{\u025b_{reproj}\ue8a0(i)}}{\\partial u_{i}^{l}}\ue89e\\frac{\\partial u_{i}^{l}}{\\partial X}} \\\\\n{\\frac{\\partial{\u025b_{reproj}\ue8a0(i)}}{\\partial v_{i}^{l}}\ue89e\\frac{\\partial v_{i}^{l}}{\\partial X}} \\\\\n{\\frac{\\partial{\u025b_{reproj}\ue8a0(i)}}{\\partial u_{i}^{r}}\ue89e\\frac{\\partial u_{i}^{r}}{\\partial X}}\n\\end{bmatrix}} \\\\\n{= \ue89e\\begin{bmatrix}\n{f_{x}\ue89e\\frac{X_{c}\ue89eY_{c}}{Z_{c}^{2}}} & {{- f_{x}}\ue89e\\frac{X_{c}^{2} + Z_{c}^{2}}{Z_{c}^{2}}} & {{- f_{x}}\ue89e\\frac{Y_{c}}{Z_{c}}} & {{- f_{x}}\ue89e\\frac{1}{Z_{c}}} & 0 & {f_{x}\ue89e\\frac{X_{c}}{Z_{c}^{2}}} \\\\\n{f_{y}\ue89e\\frac{Y_{c}^{2} + Z_{c}^{2}}{Z_{c}^{2}}} & {{- f_{y}}\ue89e\\frac{X_{c}\ue89eY_{c}}{Z_{c}^{2}}} & {{- f_{y}}\ue89e\\frac{X_{c}}{Z_{c}}} & 0 & {{- f_{y}}\ue89e\\frac{1}{Z_{c}}} & {f_{y}\ue89e\\frac{Y_{c}}{Z_{c}^{2}}} \\\\\n{{f_{x}\ue89e\\frac{X_{c}\ue89eY_{c}}{Z_{c}^{2}}} - {B\ue89e\\frac{Y_{c}}{Z_{c}^{2}}}} & {{{- f_{x}}\ue89e\\frac{X_{c}^{2} + Z_{c}^{2}}{Z_{c}^{2}}} + {B\ue89e\\frac{X_{c}}{Z_{c}^{2}}}} & {{- f_{x}}\ue89e\\frac{Y_{c}}{Z_{c}}} & {{- f_{x}}\ue89e\\frac{1}{Z_{c}}} & 0 & {{f_{x}\ue89e\\frac{X_{c}}{Z_{c}^{2}}} - {B\ue89e\\frac{1}{Z_{c}^{2}}}}\n\\end{bmatrix}}\n\\end{matrix} & (13)\n\\end{matrix}\\)",
                                "where Pc=(Xc, Yc, Zc)T is the map point 3D coordinate in the left camera frame, i.e., Pc=RPi+t. The first two rows are the residual Jacobian w.r.t. the left image, and the last row is for right image.",
                                "As a result, for N stereo features, the final system Jacobian Jx has 3N+6 rows. Additionally, based on the incremental solution \u0394X=(\u0394\u03b8, \u0394t) from Equation (9), the update of the current camera pose is expressed as:",
                                "R=exp([\u0394\u03b8]x)R",
                                "R=exp([\u0394\u03b8]x)t+\u0394t\u2003\u2003(14)",
                                "where [\u0394\u03b8], is the skew-symmetric matrix of the incremental rotation vector \u0394\u03b8 and exp([\u0394\u03b8]x) is an exponential map.",
                                "**Robust Multi-Sensor Fusion Base on a Stochastic Cloning EKF**",
                                "An EKF state estimator for the multi-sensor loosely-coupled state estimation is provided. In the EKF, IMU measurements are utilized to propagate the system state and covariance. For the update of the EKF state, both absolute measurements (GPS and barometer) and relative state measurements (stereo VO) are fused. The coordinate systems for the EKF estimator are shown in FIG. 10. The navigation frame is a local NED (North-East-Down) frame, and the initial position is determined by the first GPS measurement. The EKF estimates the IMU body frame pose w.r.t. the navigation frame. The transformation from the camera frame to the IMU body frame is denoted as Tis, and the GPS receiver coordinate in the IMU body frame is tig.",
                                "**IMU Integration**",
                                "The IMU sensor measures the tri-axis accelerations and tri-axis angular rates w.r.t. the IMU body frame. The measurements given by the IMU are corrupted by Gaussian noise and a slowly varying bias terms, which must be removed before state estimation processing. Furthermore, the IMU accelerometers measure the force, which must be compensated by gravity. The following continuous-time model expresses the relationship between the IMU measured signals and true ones:",
                                "\u03c9m=\u03c9+bg+ng",
                                "am=a+RTg+ba+na\u2003\u2003(15)",
                                "where \u03c9m \u03b53 and am \u03b53 are the measured acceleration and angular rate, respectively. \u03c9m\u03b53 and am \u03b53 indicate the true signals. ng and na are zero-mean Gaussian (0, \u03b8g2) and (0, \u03b8a2); bg \u03b53 and ba \u03b53 are slowly varying bias terms for the accelerometer and gyroscope, respectively.",
                                "Additionally, g\u03b53 is gravity acceleration; the rotation matrix R \u03b5SO(3) indicates the current IMU pose w.r.t. the navigation frame. The estimated angular rate and acceleration rate are denoted as {circumflex over (\u03c9)}\u03b53, \u00fb\u03b53 respectively. Additionally, the estimated bias terms for angular rate and acceleration are {circumflex over (b)}g and {circumflex over (b)}a:",
                                "{circumflex over (\u03c9)}=\u03c9m\u2212{circumflex over (b)}g,\u00e2=am\u2212{circumflex over (b)}a\u2003\u2003(16)",
                                "Denote \u03b4bg=bg\u2212{circumflex over (b)}g, \u03b4ba=ba\u2212{circumflex over (b)}a as the bias errors between the true bias bg, ba and the estimated bias {circumflex over (b)}g, {circumflex over (b)}a and the slowly varying motion for bias errors are modeled as:",
                                "\u03b4bg=rg,\u03b4ba=ra\u2003\u2003(17)",
                                "where rg\u02dc(0,\u03c3rg2) and ra\u02dc(0, \u03c3ra2) are zero-mean Gaussian.",
                                "**EKF State Definition and Jacobians**",
                                "Based on the above IMU kinematic model, the discrete IMU integral equations are:",
                                "\\(\\begin{matrix}\n{{{{p\ue8a0\\left( {k + 1} \\right)} = {{p\ue8a0(k)} + {{v\ue8a0(k)}\ue89e{dt}} + {\\frac{1}{2}\ue89e\\hat{a}\ue89e\\; \ue89e{dt}^{2}}}}\ue89e\ue89e{v_{b}\ue8a0\\left( {k + 1} \\right)} = {{v_{b}\ue8a0(k)} + {\\left( {\\hat{a} - {\\left\\lbrack \\hat{\\omega} \\right\\rbrack_{\\times}\ue89e{v_{b}\ue8a0(k)}}} \\right)\ue89e{dt}}}}\ue89e\ue89e{{R\ue8a0\\left( {k + 1} \\right)} = {{R\ue8a0(k)}\ue89e{\\exp \ue8a0\\left( \\left\\lbrack {\\hat{\\omega}\ue89e\\; \ue89e{dt}} \\right\\rbrack_{\\times} \\right)}}}} & (18)\n\\end{matrix}\\)",
                                "where p(k)\u03b53 indicates the three DoF position w.r.t. the navigation frame at instant k. vb(k) is the velocity defined in the IMU body frame, and r(k)\u03b5SO(3) is the rotation matrix w.r.t. the navigation frame. [{circumflex over (\u03c9)}dt]x is a skew-symmetric matrix of the angular rate integral rotation vector {circumflex over (\u03c9)}dt; exp([{circumflex over (\u03c9)}dt]x) is an exponential map in the Lie manifold SO(3). dt is the IMU sampling time. Based on the IMU integral equations and bias error model, the EKF system state S is defined as:",
                                "S=(p,\u03b4\u03b8,vb,\u03b4bg,\u03b4ba)T\u03b515\u2003\u2003(19)",
                                "where p\u03b53 indicates position w.r.t. the navigation frame, \u03b4\u03b8\u03b53 is the error rotation vector w.r.t. the IMU body frame, vb \u03b53 is the velocity w.r.t. the IMU body frame and \u03b4bg\u03b53, \u03b4ba\u03b53 are the current bias error terms. The estimated rotation matrix is defined as {circumflex over (R)}\u03b5SO(3), so the true rotation matrix R \u03b5SO(3) after the rotation error compensation is calculated by matrix right multiplication:",
                                "R={circumflex over (R)}exp([\u03b4\u03b8]x)\u2003\u2003(20)",
                                "where [\u03b4\u03b8]x is skew-symmetric matrix of error rotation vector \u03b4\u03b8.",
                                "Based on the above system state definition, the system state dynamics {dot over (S)} is derived as:",
                                "{circumflex over (p)}={circumflex over (R)}exp([\u03b4\u03b8]x)vb",
                                "\u03b4\u03b8=exp([\u03b4\u03b8]x)({circumflex over (\u03c9)}\u2212\u03b4bg\u2212ng)",
                                "vb=\u2212[{circumflex over (\u03c9)}\u2212\u03b4bg\u2212ng]xvb+({circumflex over (R)}exp([\u03b4\u03b8]x))Tg+\u00e2\u2212\u03b4ba\u2212na",
                                "\u03b4bg=rg",
                                "\u03b4ba=ra\u2003\u2003(21)",
                                "Therefore, the Jacobian matrix",
                                "\\(\\frac{d\ue89e\\; \ue89e\\overset{.}{S}}{dS}\ue89e{\\varepsilon\\mathbb{R}}^{15 \\times 15}\\)",
                                "for the system dynamics is obtained as:",
                                "\\(\\begin{matrix}\n{\\frac{\\partial\\overset{.}{S}}{\\partial S} = \\begin{pmatrix}\n0_{3 \\times 3} & {- {\\hat{R}\ue8a0\\left\\lbrack v_{b} \\right\\rbrack}_{\\times}} & {\\hat{R}\ue89e\\; \ue89e{\\exp \ue8a0\\left( \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta} \\right\\rbrack_{\\times} \\right)}} & 0_{3 \\times 3} & 0_{3 \\times 3} \\\\\n0_{3 \\times 3} & {- \\left\\lbrack {\\hat{\\omega} - {\\delta \ue89e\\; \ue89eb_{g}} - n_{g}} \\right\\rbrack_{\\times}} & 0_{3 \\times 3} & {- {\\exp \ue8a0\\left( \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta} \\right\\rbrack_{\\times} \\right)}} & 0_{3 \\times 3} \\\\\n0_{3 \\times 3} & \\left\\lbrack {{\\hat{R}}^{T}\ue89eg} \\right\\rbrack_{\\times} & {- \\left\\lbrack {\\omega - {\\delta \ue89e\\; \ue89eb_{g}} - n_{b}} \\right\\rbrack_{\\times}} & {- \\left\\lbrack v_{b} \\right\\rbrack_{\\times}} & {- I_{3 \\times 3}} \\\\\n0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} \\\\\n0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3}\n\\end{pmatrix}} & (22)\n\\end{matrix}\\)",
                                "where I3\u00d73 denotes the 3\u00d73 identity matrix and 03\u00d73 denotes the 3_3 zero matrix.",
                                "The system state noise input consists of IMU measurement noise and bias error noise, that is:",
                                "W=(ng,na,rg,ra)T\u03b512\u2003\u2003(23)",
                                "As a result, the Jacobian matrix",
                                "\\(\\frac{d\ue89e\\; \ue89e\\overset{.}{S}}{dW}\ue89e{\\varepsilon\\mathbb{R}}^{15 \\times 12}\\)",
                                "w.r.t. the system noise is:",
                                "\\(\\begin{matrix}\n{\\frac{\\partial\\overset{.}{S}}{\\partial W} = \\begin{pmatrix}\n0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} \\\\\n{- I_{3 \\times 3}} & 0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} \\\\\n{- \\left\\lbrack v_{b} \\right\\rbrack_{\\times}} & {- I_{3 \\times 3}} & 0_{3 \\times 3} & 0_{3 \\times 3} \\\\\n0_{3 \\times 3} & 0_{3 \\times 3} & I_{3 \\times 3} & 0_{3 \\times 3} \\\\\n0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} & I_{3 \\times 3}\n\\end{pmatrix}} & (24)\n\\end{matrix}\\)",
                                "Based on the relationship between the continuous-time and discrete-time systems, the final Jacobians for state covariance propagation are:",
                                "\\(\\begin{matrix}\n{{J_{S} = {{\\frac{\\partial\\hat{S}}{\\partial S}\ue89e{dt}} + I_{15 \\times 15}}},{J_{W} = {\\frac{\\partial\\hat{S}}{\\partial W}\ue89e{dt}}}} & (25)\n\\end{matrix}\\)",
                                "Treatment of VO Relative State Measurement Using Delayed State Stochastic Cloning",
                                "The state estimation system provided herein utilizes both absolute state measurements (GPS provides absolute position and velocity measurement in the NED coordinate system; the barometer provides absolute state measurement for altitude) and the relative six D.O.F pose measurement (between the two stereo frames) provided by long-range stereo VO. To deal-with both absolute and relative state measurements, the system state defined in Equation (19) is further augmented by stochastic cloning of a delayed pose p1, \u03b4\u03b81 which is updated with the previous VO measurement, namely:",
                                "{tilde over (S)}=(ST,pl,\u03b4\u03b81)T\u03b521\u2003\u2003(26)",
                                "During the system state propagation, the delayed pose p1, \u03b4\u03b81 is kept as constant; that means {dot over (p)}l=0 and {dot over (\u03b4)}\u03b8l=0. Therefore, the Jacobians for the augmented state {dot over (S)} are:",
                                "\\(\\begin{matrix}\n{{\\overset{\\sim}{J}}_{S} = {\\begin{pmatrix}\nJ_{S} & 0_{15 \\times 6} \\\\\n0_{6 \\times 15} & I_{6 \\times 6}\n\\end{pmatrix} \\in {\\mathbb{R}}^{21 \\times 21}}} & (27) \\\\\n{{\\overset{\\sim}{J}}_{W} = {\\begin{pmatrix}\nJ_{W} \\\\\n0_{6 \\times 12}\n\\end{pmatrix} \\in {\\mathbb{R}}^{21 \\times 12}}} & (28)\n\\end{matrix}\\)",
                                "The augmented state covariance is denoted as {tilde over (P)}(k+1|k)\u03b521\u00d721. Accordingly, the covariance propagation for the state augmented system is given as:",
                                "{tilde over (P)}(k+1|k)=\u00ceS{tilde over (P)}(k){tilde over (J)}ST+\u0134WQ(K)\u0134WT\u2003\u2003(29)",
                                "For the system initialization, the initial system state covariance is of the form:",
                                "\\(\\begin{matrix}\n{{\\overset{\\sim}{P}\ue8a0(0)} = \\begin{pmatrix}\n\\sum_{p}^{2} & 0 & 0 & 0 & 0 & \\sum_{p}^{2} & 0 \\\\\n0 & \\sum_{\\theta}^{2} & 0 & 0 & 0 & 0 & \\sum_{\\theta}^{2} \\\\\n0 & 0 & \\sum_{vb}^{2} & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & \\sum_{bg}^{2} & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sum_{ba}^{2} & 0 & 0 \\\\\n\\sum_{p}^{2} & 0 & 0 & 0 & 0 & \\sum_{p}^{2} & 0 \\\\\n0 & \\sum_{\\theta}^{2} & 0 & 0 & 0 & 0 & \\sum_{\\theta}^{2}\n\\end{pmatrix}} & (30)\n\\end{matrix}\\)",
                                "Long-range stereo VO generates the relative six DoF motion measurement between the two visual frames. The relative measurement model is defined as:",
                                "\u0394p=exp(\u2212[\u03b4\u03b8l]x)RlT(p\u2212pl)",
                                "\u0394\u03b8=log(exp(\u2212[\u03b4\u03b8l]x)RlT{circumflex over (R)}exp([\u03b4\u03b8]x))\u2003\u2003(31)",
                                "where \u0394p\u03b53 is a position increment from the current pose p, {circumflex over (R)} to the delay pose pl, Rl and \u0394\u03b8\u03b53 is the rotation increment. Rl\u03b5SO(3) is the rotation matrix for previous visual updated orientation (i.e., the delayed state orientation), and \u03b4\u03b8l indicates the error rotation vector for the delayed state. {circumflex over (R)}\u03b5SO(3) is the rotation matrix for the current orientation, and \u03b4\u03b8 is the current error rotation vector. The matrix logarithm log(RlT {circumflex over (R)}) maps the rotation matrix RlT {circumflex over (R)} to a rotation vector. For Jacobians with a relative translation \u0394p w.r.t. system state S:",
                                "\\(\\begin{matrix}\n{{{{\\frac{{\\partial\\Delta}\ue89e\\; \ue89ep}{\\partial p} = {\\exp \ue8a0\\left( {- \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta_{l}} \\right\\rbrack_{\\times}} \\right)}}\uf604}_{{\\delta \ue89e\\; \ue89e\\theta_{l}} = 0}\ue89eR_{l}^{T}} = R_{l}^{T}} & (32) \\\\\n{{{{\\frac{{\\partial\\Delta}\ue89e\\; \ue89ep}{\\partial p_{l}} = {- {\\exp \ue8a0\\left( {- \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta_{l}} \\right\\rbrack_{\\times}} \\right)}}}\uf604}_{{\\delta \ue89e\\; \ue89e\\theta_{l}} = 0}\ue89eR_{l}^{T}} = {- R_{l}^{T}}} & \\; \\\\\n{{{{\\frac{{\\partial\\Delta}\ue89e\\; \ue89ep}{{\\partial\\delta}\ue89e\\; \ue89e\\theta_{l}} = \\frac{\\partial{\\exp \ue8a0\\left( {- \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta_{l}} \\right\\rbrack_{\\times}} \\right)}}{{\\partial\\delta}\ue89e\\; \ue89e\\theta_{l}}}\uf604}_{{\\delta \ue89e\\; \ue89e\\theta_{l}} = 0}\ue89e\\; \ue89e{R_{l}^{T}\ue8a0\\left( {p - p_{l}} \\right)}} = \\left\\lbrack {R_{l}^{T}\ue8a0\\left( {p - p_{l}} \\right)} \\right\\rbrack_{\\times}} & \\;\n\\end{matrix}\\)",
                                "where the derivative",
                                "\\(\\frac{{\\partial\\Delta}\ue89e\\; \ue89ep}{{\\partial\\delta}\ue89e\\; \ue89e\\theta_{l}}\\)",
                                "is derived based on the first-order Taylor expansion for the exponential map at \u03b4\u03b8l=0. Additionally, the anti-commutativity rule for skew-symmetric matrix, namely: [\u03b4\u03b8l]xRlT(p\u2212pl)=\u2212[RlT (p\u2212pl)]x\u03b4\u03b8l.",
                                "The Jacobians for the \u0394\u03b8 are computed as:",
                                "\\(\\begin{matrix}\n{{{{{{\\frac{{\\partial\\Delta}\ue89e\\; \ue89e\\theta}{{\\partial\\delta}\ue89e\\; \ue89e\\theta} = \\frac{\\partial{\\log \ue8a0\\left( {R_{l}^{T}\ue89e\\hat{R}\ue89e\\; \ue89e{\\exp \ue8a0\\left( \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta} \\right\\rbrack_{\\times} \\right)}} \\right)}}{{\\partial\\delta}\ue89e\\; \ue89e\\theta}}\uf604}_{{\\delta \ue89e\\; \ue89e\\theta} = 0} = {{{Adj}\ue8a0\\left( {R_{l}^{T}\ue89e\\hat{R}} \\right)} = {R_{l}^{T}\ue89e\\hat{R}}}}\ue89e\ue89e{\\frac{{\\partial\\Delta}\ue89e\\; \ue89e\\theta}{{\\partial\\delta}\ue89e\\; \ue89e\\theta_{l}} = \\frac{\\partial{\\log \ue8a0\\left( {{\\exp \ue8a0\\left( {- \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta_{l}} \\right\\rbrack_{\\times}} \\right)}\ue89eR_{l}^{T}\ue89e\\hat{R}} \\right)}}{{\\partial\\delta}\ue89e\\; \ue89e\\theta_{l}}}}\uf604}_{{\\delta \ue89e\\; \ue89e\\theta_{l}} = 0} = {{- {{Adj}\ue8a0\\left( I_{3 \\times 3} \\right)}} = {- I_{3 \\times 3}}}} & (33)\n\\end{matrix}\\)",
                                "where Adj(R) is the adjoint map in R\u03b5SO(3), and it has the property of Adj(R)=R. The derivative for the matrix logarithm is derived by the first-order approximation of Campbell-Baker-Hausdorff formula. As a result, the VO relative measurement Jacobian is expressed as:",
                                "\\(\\begin{matrix}\n{H_{vo} = \\begin{pmatrix}\nR_{l}^{T} & 0_{3 \\times 12} & {- R_{l}^{T}} & \\left\\lbrack {R_{l}^{T}\ue8a0\\left( {p - p_{l}} \\right)} \\right\\rbrack_{\\times} \\\\\n0_{3 \\times 3} & {R_{l}^{T}\ue89e\\hat{R}} & 0_{3 \\times 12} & {- I_{3 \\times 6}}\n\\end{pmatrix}} & (34)\n\\end{matrix}\\)",
                                "Denote the VO relative measurement as (\u0394pvo, \u0394\u03b8vo)T; the measurement residual is given by:",
                                "\\(\\begin{matrix}\n{\\overset{\\sim}{r} = \\begin{pmatrix}\n{{\\Delta \ue89e\\; \ue89ep_{vo}} - {\\Delta \ue89e\\; \ue89ep}} \\\\\n{{\\Delta \ue89e\\; \ue89e\\theta_{vo}} \\ominus {\\Delta \ue89e\\; \ue89e\\theta}}\n\\end{pmatrix}} & (35)\n\\end{matrix}\\)",
                                "where the rotational vector residual \u0394\u03b8v0 \u2296\u0394\u03b8 is defined as log(\u0394R\u22121\u0394Rvo). \u0394R=exp ([\u0394\u03b8]x) is the predicted rotation matrix from the current state to the delayed state. Additionally, the \u0394R=exp([\u0394\u03b8]x) is the VO easured one.",
                                "It is worthwhile to note that, after each VO relative measurement update, the delayed portion vector of the state pl, \u03b4\u03b8l is set equal to the current updated pose p(k+1), \u03b4\u03b8(k+1), and the state covariance matrix is updated by \u201ccloning\u201d the corresponding covariance blocks from the current state covariance to delayed pose covariance. To update the EKF state, the VO measurement should be transformed from the visual frame to the IMU body frame using the visual-IMU relative pose Calibration Tis; suppose the VO measurement in visual frame is Zs; its corresponding measurement in the IMU body frame is:",
                                "Zi=TisZsTis\u22121\u2003\u2003(36)",
                                "The update of the EKF state is standard, that is:",
                                "K={tilde over (P)}(k+1|k)HT({tilde over (P)}(k+1|k)HT+R)\u22121",
                                "{tilde over (S)}(k+1)={tilde over (S)}(k)+K{tilde over (r)}\u2003\u2003(37)",
                                "The EKF covariance update uses Joseph's form to avoid the negative definition, that is:",
                                "{tilde over (P)}(k+1)=(I\u2212KH){tilde over (P)}(k+1|k)(I\u2212KH)T+KRKT\u2003\u2003(38)",
                                "**Update of EKF State Using Absolute State Measurements**",
                                "GPS provides absolute position and velocity measurement in the NED frame system; suppose the heading of the initial EKF navigation frame is aligned with the NED frame; the GPS measurement model is:",
                                "\\(\\begin{matrix}\n{Z_{gps} = \\begin{bmatrix}\n{p + {\\hat{R}\ue89e\\; \ue89e{\\exp \ue8a0\\left( \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta} \\right\\rbrack_{\\times} \\right)}\ue89et_{ig}}} \\\\\n{\\hat{R}\ue89e\\; \ue89e{\\exp \ue8a0\\left( \\left\\lbrack {\\delta \ue89e\\; \ue89e\\theta} \\right\\rbrack_{\\times} \\right)}\ue89e\\left( {v_{b} + {\\left\\lbrack {\\hat{\\omega} - {\\delta \ue89e\\; \ue89eb_{g}}} \\right\\rbrack_{\\times}\ue89et_{ig}}} \\right)}\n\\end{bmatrix}} & (39)\n\\end{matrix}\\)",
                                "where tig\u03b53 is the translation from the GPS receiver to the IMU body frame, as explained in FIG. 10. The GPS measurement Jacobian is derived as:",
                                "\\(\\begin{matrix}\n{H_{gps} = \\begin{pmatrix}\nI_{3 \\times 3} & {- {\\hat{R}\ue8a0\\left\\lbrack t_{ig} \\right\\rbrack}_{\\times}} & 0_{3 \\times 3} & 0_{3 \\times 3} & 0_{3 \\times 3} \\\\\n0_{3 \\times 3} & {- {\\hat{R}\ue8a0\\left\\lbrack v_{b} \\right\\rbrack}_{\\times}} & \\hat{R} & \\left\\lbrack t_{ig} \\right\\rbrack_{\\times} & 0_{3 \\times 3}\n\\end{pmatrix}} & (40)\n\\end{matrix}\\)",
                                "Since GPS measurement in altitude has a large uncertainty, the GPS height and velocity in altitude are not utilized to update the EKF state. Only the position and velocity for north and east are kept as GPS measurements, namely Zgps=(pn, pe, vn, ve)T\u03b54. Consequently, the third and the sixth rows for the GPS Jacobian Hgps are also removed.",
                                "The \u201cGPS health status\u201d, which reports how many satellites can be seen by the receiver, are utilized to determine the current GPS measurement covariance. For bad \u201cGPS health status\u201d, GPS will report a large covariance. It is worth mentioning that the X2 test at 0.95 is utilized to verify the compatibility between current GPS measurement and the system predicted state. If GPS measurement \u201cjumps\u201d due to perturbation (e.g., multipath), the system will reject the GPS measurement automatically. In fact, the sensor measurements are firstly checked by the X2 test before they are utilized for state estimation. As a result, the EKF state estimator is robust to any sensor failures.",
                                "The barometer provides absolute altitude measurements w.r.t. the navigation frame. The navigation frame is a local NED frame, so the barometer measures the negative altitude w.r.t. the NED coordinate. As a result, the barometer measurement model is:",
                                "Zbaro=\u2212pd\u2003\u2003(41)",
                                "where pd denotes the z component for current position. Its Jacobian is:",
                                "Hbaro=(0 0 \u22121 01\u00d718)\u2003\u2003(42)",
                                "For the EKF implementation, a ring buffer with a 2-s time is kept to save all of the incoming sensor data. As shown in FIG. 11, when a new VO measurement arrives, its time stamp is usually not the most up to date due to the image transmission and the stereo VO calculation delay. For this case, after the update of the EKF state on the VO time stamp, the subsequent IMU integral should be re-integrated to re-predict the current state. The same processing is also carried out for GPS and barometric measurements. To further decrease the computational cost of IMU re-integration, the IMU pre-integral technique in the IMU body frame can be utilized.",
                                "The foregoing descriptions of embodiments of the invention have been presented for purposes of illustration and description only. They are not intended to be exhaustive or to limit the invention to the forms disclosed. Accordingly, many modifications and variations will be apparent to the practitioner skilled in the art. The scope of the invention as defined by the appended claims not the preceding disclosure."
                            ],
                            "subsections": [],
                            "outline_long": [
                                "introduce limitations of static stereo triangulation",
                                "derive depth variance equation",
                                "motivate multi-view stereo with dynamic pseudo baseline",
                                "describe sparse feature-based stereo VO pipeline",
                                "introduce key-frame-based VO technique",
                                "explain local map generation",
                                "integrate IMU information",
                                "switch between stereo and monocular modes",
                                "describe stereo mode operation",
                                "describe monocular mode operation",
                                "introduce long-range point generation using multi-view stereo triangulation",
                                "classify features into three groups",
                                "triangulate long-range points using pseudo-baseline and static stereo baseline",
                                "introduce long-range point generation by multi-view stereo inverse depth filtering",
                                "model inverse depth uncertainty",
                                "design inverse depth filter for each new candidate",
                                "update filtered inverse depth distribution",
                                "introduce local bundle adjustment for multi-view stereo optimization",
                                "consider re-projection errors for both left and right images",
                                "derive Jacobian of rejection residual w.r.t. map point",
                                "define long range stereo odometry pipeline",
                                "introduce IMU tightly-coupled odometry calculation",
                                "derive cost function for stereo VO",
                                "formulate Levenberg-Marquardt iteration",
                                "define Jacobian and residual for stereo pose tracking",
                                "calculate 3D-2D reprojection error",
                                "derive Jacobian for 3D-2D reprojection error",
                                "introduce robust multi-sensor fusion based on stochastic cloning EKF",
                                "define EKF state estimator for multi-sensor loosely-coupled state estimation",
                                "describe IMU integration",
                                "model IMU measurements with Gaussian noise and bias terms",
                                "estimate angular rate and acceleration rate",
                                "model bias errors for angular rate and acceleration",
                                "define discrete IMU integral equations",
                                "derive EKF state definition",
                                "formulate Jacobians for EKF state",
                                "describe EKF update process",
                                "conclude EKF state estimation",
                                "define system state",
                                "derive system state dynamics",
                                "obtain Jacobian matrix for system dynamics",
                                "obtain Jacobian matrix for system noise",
                                "derive final Jacobians for state covariance propagation",
                                "augment system state with delayed pose",
                                "derive Jacobians for augmented state",
                                "define augmented state covariance",
                                "derive covariance propagation for augmented system",
                                "define initial system state covariance",
                                "define relative measurement model",
                                "derive Jacobians for relative translation",
                                "derive Jacobians for relative rotation",
                                "define VO relative measurement Jacobian",
                                "define measurement residual",
                                "update EKF state using VO measurement",
                                "update delayed pose and covariance",
                                "define GPS measurement model",
                                "derive GPS measurement Jacobian",
                                "define barometer measurement model",
                                "derive barometer measurement Jacobian",
                                "implement EKF using ring buffer",
                                "re-integrate IMU data for VO measurement",
                                "re-integrate IMU data for GPS and barometric measurements",
                                "utilize IMU pre-integral technique",
                                "conclude EKF implementation"
                            ],
                            "num_characters": 33066,
                            "outline_medium": [
                                "motivate long-range stereo odometry",
                                "derive stereo depth error equation",
                                "introduce multi-view stereo with dynamic pseudo baseline",
                                "describe key-frame-based VO technique",
                                "explain stereo mode for short-range points",
                                "explain monocular mode for long-range points",
                                "classify features for long-range point generation",
                                "triangulate long-range points using multi-view stereo",
                                "filter long-range points using inverse depth filtering",
                                "optimize multi-view stereo using local bundle adjustment",
                                "define long range stereo odometry pipeline",
                                "integrate IMU motion prior into stereo VO",
                                "formulate cost function for stereo VO",
                                "derive optimal solution for camera pose tracking",
                                "calculate 3D-2D reprojection error",
                                "define robust multi-sensor fusion based on stochastic cloning EKF",
                                "integrate IMU measurements into EKF state estimator",
                                "model IMU measurements with Gaussian noise and bias terms",
                                "define EKF state and Jacobians for discrete IMU integral equations",
                                "define system state",
                                "derive system state dynamics",
                                "compute Jacobian matrix for system dynamics",
                                "compute Jacobian matrix for system noise",
                                "define augmented system state",
                                "compute Jacobians for augmented system state",
                                "define relative measurement model",
                                "compute Jacobians for relative measurement",
                                "define measurement residual",
                                "update EKF state using relative measurement",
                                "update EKF state using absolute state measurements",
                                "define GPS measurement model",
                                "define barometer measurement model"
                            ],
                            "outline_short": [
                                "motivate long-range stereo odometry",
                                "describe pipeline structure",
                                "generate long-range points using multi-view stereo triangulation",
                                "generate long-range points by multi-view stereo inverse depth filtering",
                                "perform local bundle adjustment for multi-view stereo optimization",
                                "define long range stereo odometry pipeline",
                                "integrate IMU motion prior into stereo VO",
                                "describe robust multi-sensor fusion based on stochastic cloning EKF",
                                "integrate IMU measurements into EKF state estimation",
                                "define system state",
                                "derive system state dynamics",
                                "compute Jacobian matrices",
                                "augment system state with delayed pose",
                                "derive relative measurement model",
                                "update EKF state using absolute and relative measurements"
                            ]
                        }
                    ],
                    "outline_long": [
                        "introduce invention scope",
                        "motivate aerial vehicle application",
                        "describe system overview",
                        "introduce state estimation technique",
                        "describe system block diagram",
                        "motivate stochastic cloning EKF",
                        "describe VO system for low-altitude cases",
                        "describe VO system for high-altitude cases",
                        "introduce delayed pose and covariance",
                        "derive measurement Jacobian for VO",
                        "describe EKF state estimation system update",
                        "analyze covariance properties",
                        "introduce IMU integral state prediction",
                        "balance VO covariance with Q",
                        "describe Chi-square test for VO measurement",
                        "introduce long-range stereo VO pipeline",
                        "describe key-frame-based VO technique",
                        "summarize long-range depth generation approaches"
                    ],
                    "num_characters": 9187,
                    "outline_medium": [
                        "introduce invention scope",
                        "motivate state estimation technique",
                        "describe system architecture",
                        "explain stochastic cloning EKF state estimator",
                        "detail long-range stereo VO implementation",
                        "illustrate key-frame-based VO technique",
                        "explain short-range and long-range VO modes",
                        "describe long-range depth generation methods",
                        "illustrate inverse depth filtering"
                    ],
                    "outline_short": [
                        "introduce state estimation technique",
                        "describe system architecture",
                        "explain stochastic cloning EKF state estimator",
                        "detail long-range stereo VO implementation"
                    ]
                }
            ],
            "outline_long": [],
            "num_characters": 0,
            "outline_medium": [],
            "outline_short": []
        }
    ],
    "claims": [
        "1. A system for estimating the state of an aerial vehicle comprising:\none or more relative sensors, including at least an inertial measurement unit and a visual odometry unit;\none or more absolute sensors; and\na processor, running software for performing the functions of:\nkeeping a current state and current state covariance, the current state including at least a current position, a current orientation, a current velocity, a delayed position and a delayed orientation, the delayed position and delayed orientation being based on visual odometry from a previous current state;\npredicting an update of the current state and an update of the current state covariance based on an integration of a reading from the inertial measurement unit;\nreceiving visual odometry, updating the delayed position and orientation with the current position and orientation, updating the current position and orientation with the visual odometry;\nreceiving state information from an absolute sensor, updating the current state with the state information and covariance from the absolute sensor;\nrecalculating the covariance of the current state to give readings from the relative and absolute sensors a weight in the estimated state of the vehicle; and\nrepeating the functions performed by the software.",
        "2. The system of claim 1 wherein updating the current state and covariance is performed by an extended Kalman filter.",
        "3. The system of claim 2 wherein the current state includes covariances of each element included in the current state.",
        "4. The system of claim 3 wherein the one or more absolute sensors are selected from a group consisting of a global positioning system and a barometer.",
        "5. The system of claim 3 wherein the software performs the further functions of:\ncalculating an uncertainty factor between the covariance of the current position and orientation and the covariance of the delayed position and orientation; and\nadjusting the visual odometry covariance based on the uncertainty factor.",
        "6. The system of claim 3 wherein the function of receiving visual odometry includes:\nupdating the covariance of the visual odometry;\nverifying that the covariance of the visual odometry is lower than the covariance of the predicted updated state; and\nverifying that the covariance of the visual odometry is greater than a previous error covariance.",
        "7. The system of claim 3 wherein the function of receiving state information from an absolute sensor includes:\nverifying that the updated covariance of the position, orientation, delayed position and the delayed orientation have decreased with respect to their respective covariances prior to the receiving of state information from the absolute sensor; and\nverifying that the covariances of the current position and current orientation are higher than the covariances for the delayed position and delayed orientation.",
        "8. The system of claim 1 further comprising:\nfor the visual odometry unit, determining, based on the current stereo baseline-depth ratio, that short range stereo mode is no longer viable;\nswitching the visual odometry unit to monocular mode;\nmaintaining a local map consisting of 3D sparse map points generated by sparsely selected key-frames, the selected key-frames providing sufficient relative motion between the frames for long-range triangulation;\nidentifying new features visible in multiple selected key-frames and performing triangulation using a dynamic pseudo baseline formed by the relative pose of the features between neighboring key-frames.",
        "9. The system of claim 8 further comprising:\nfor new features that cannot be triangulated, inserting those features into a candidate queue; and\niteratively refining the feature depth in the subsequent key-frames by tracking stereo information with a multi-view inverse depth filter wherein the feature will be added to the map and used for camera pose tracking if the inverse depth variance is smaller than a given threshold.",
        "10. The system of claim 9 wherein, for each subsequent key-frame, the inverse depth observation distribution for the feature is calculated from the tracking frame static stereo matching or obtained by the dynamic pseudo baseline formed by the motion between the current tracking frame and a reference key-frame.",
        "11. The system of claim 8 wherein the integrated readings from the inertial measurement unit are used by the visual odometry unit for pose tracking between the selected key-frames.",
        "12. A method for estimating the state of an aerial vehicle comprising:\nkeeping a current state and current state covariance, the current state including at least a current position, a current orientation, a current velocity, a delayed position and a delayed orientation, the delayed position and delayed orientation being based on visual odometry from a previous current state;\npredicting an update of the current state and an update of the current state covariance based on an integration of a reading from an inertial measurement unit;\nreceiving visual odometry from a visual odometry unit, updating the delayed position and orientation with the current position and orientation, updating the current position and orientation with the visual odometry and recalculating the covariance of the current state;\nreceiving state information from an absolute sensor, updating the current state and with the state information and covariance from the absolute sensor and recalculating the covariance of the current state; and\nrepeating the functions performed by the software.",
        "13. The system of claim 12 wherein updating the current state and covariance is performed by an extended Kalman filter.",
        "14. The system of claim 13 wherein the current state includes covariances of each element included in the current state.",
        "15. The system of claim 13 wherein the one or more absolute sensors are selected from a group consisting of a global positioning system and a barometer.",
        "16. The system of claim 13 wherein the software performs the further functions of:\ncalculating an uncertainty factor between the covariance of the current position and orientation and the covariance of the delayed position and orientation; and\nadjusting the visual odometry covariance based on the uncertainty factor.",
        "17. The system of claim 13 wherein the function of receiving visual odometry includes:\nupdating the covariance of the visual odometry;\nverifying that the covariance of the visual odometry is lower than the covariance of the predicted updated state; and\nverifying that the covariance of the visual odometry is greater than a previous error covariance.",
        "18. The system of claim 13 wherein the function of receiving state information from an absolute sensor includes:\nverifying that the updated covariance of the position, orientation, delayed position and the delayed orientation have decreased with respect to their respective covariances prior to the receiving of state information from the absolute sensor; and\nverifying that the covariances of the current position and current orientation are higher than the covariances for the delayed position and delayed orientation."
    ]
}