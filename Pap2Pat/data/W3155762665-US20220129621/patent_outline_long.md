# DESCRIPTION

## TECHNICAL FIELD

- relate to machine-learning systems

## BACKGROUND

- introduce neural networks
- limitations of existing solutions
- application of AI techniques

## SUMMARY

- introduce BERT-based machine-learning tools
- embodiment of machine-learning model
- train machine-learning model

## DETAILED DESCRIPTION

- introduce BERT-based response prediction model
- describe response prediction engine
- explain encoding input text with BERT encoder
- combine encoded input text with encoded demographic data
- compute predicted emotional response score
- describe text-editing tool with BERT-based response prediction model
- provide editing interface with field for inputting text and selection elements for inputting demographics
- receive input text and demographic profile
- generate input text vector with BERT encoder
- encode demographic profile into input demographics vector
- compute emotional response scores with classification module
- display emotional response score in editing interface
- allow user to modify text to customize emotional response
- describe limitations of existing software tools
- explain how existing tools fail to account for demographically-based variations in language preferences
- describe how embodiments improve software tools
- introduce example of BERT-based machine-learning model
- describe computing environment for predicting empathy and distress
- introduce text processing system and training system
- describe BERT-based response prediction model
- explain user interface engine
- describe interaction data and emotion prediction
- introduce training system and training engine
- describe training data and trained model
- explain how training system provides trained model to text processing system
- describe user interface engine and graphical interface
- explain interaction data and emotion prediction
- describe how machine-learning tools improve conversational artificial intelligence tools
- explain how text processing system evaluates message and modifies it based on empathy score
- describe customizing text to different expected audiences
- explain how tools allow for demographic-specific lead identification
- introduce process for using BERT-based machine-learning tools
- describe providing input text to machine-learning model
- explain computing demographically-specific emotional response score
- describe encoding input text with BERT encoder
- explain generating emotional response score with classification module
- describe outputting emotional response score
- introduce BERT-based response prediction model for predicting empathy response and distress response
- describe components of BERT-based response prediction model
- describe classification module
- receive input from BERT encoder and demographic module
- determine predictive output relating to emotion
- illustrate architecture for implementing BERT-based response prediction model
- apply BERT encoder to input text
- tokenize text sequences into tokens
- output encoded version of input text
- provide output to concatenation module
- implement BERT encoder using multi-layer bidirectional transformer encoder
- generate sequence of hidden states from inputted text sequence
- output set of vectors corresponding to classification token and word tokens
- use final hidden state as aggregate sequence representation
- generate 768-dimensional hidden vector
- receive demographic information via user inputs
- train feed-forward neural network to encode demographic information
- combine independent demographic features into shared space
- omit feed-forward neural network in some embodiments
- receive demographic data and generate one-hot encoding vector
- generate combined vector representing encoded text and demographics information
- apply feed-forward network to input vectors
- perform concatenation operation on input vectors
- generate predictive outputs represented using probability distributions
- include multiple classification heads with shared BERT layers
- train classification heads to map text and input demographic information
- output probability distributions with probabilities for different output classes
- select output class having highest probability as predicted demographic
- select output class having highest probability as predicted distress response score
- select output class having highest probability as predicted empathy response score
- configure BERT-based response prediction model for predicting emotional responses
- adapt model to demographic preferences
- modify model for emotional response classification task
- iteratively perform training process and compute loss
- access training dataset with varied demographic attributes and labeled training text
- perform iterations to modify parameters of BERT encoder and classification heads
- select parameter value sets for BERT encoder and classification heads
- define BERT-based response prediction model
- describe training engine
- compute loss values
- identify desirable parameter values
- output trained BERT-based response prediction model
- describe alternative training
- compute single-task loss
- describe parallel training
- compute multi-task loss
- describe user interface engine
- generate user interface
- detect input text
- detect input demographic profile
- provide input to BERT-based response prediction model
- update user interface with emotional response score
- describe real-time updating of user interface
- describe architecture for BERT encoder
- describe multi-layer bidirectional Transformer encoder
- describe encoder layers
- describe attention function
- describe multi-head attention model
- describe tensor operation
- describe encoder layer
- describe multi-head self-attention network
- describe scaled dot-product attention block
- describe computing system
- describe processor
- describe memory device
- describe program code
- describe input/output interfaces
- describe bus
- describe input device
- describe presentation device
- describe network interface device
- describe data network
- describe user device
- describe training system
- describe text processing system
- describe BERT-based response prediction model
- describe user interface engine
- describe training engine
- describe computing system
- describe processor
- describe memory device
- describe program code
- describe input/output interfaces
- describe bus
- describe input device
- describe presentation device

### Experimental Results

- conduct experiment on empathy prediction
- pre-train BERT on Blog Authorship Corpus
- fine-tune BERT-based response prediction model
- use demographic attributes for empathy prediction
- report F1 and accuracy scores
- compare BERT-based models with Random Forest model
- compare BERT-based models with deep learning baselines
- show accuracies for gender-specific empathy prediction
- show accuracies for age, income, and education prediction
- indicate empathy dependence on author gender
- show results for empathy prediction using tBERT variants
- show performance of age and gender prediction with empathy-aware models
- indicate improvement of empathy-aware models over baselines
- discuss impact of demographic-aware models on affect predictions
- discuss general considerations for claimed subject matter
- define computing and processing terms
- describe system architecture and configuration
- discuss variations and equivalents of embodiments

