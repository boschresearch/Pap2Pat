# QCNN CIRCUIT MODEL

Convolutional neural networks (CNNs) provide a successful machine learning architecture for classification tasks such as image recognition 1,22,23 . A CNN generally consists of a sequence of different (interleaved) layers of image processing; in each layer, an intermediate 2D array of pixels, called a feature map, is produced from the previous one (Figure 1a) 24  i+a,j+b , where the weights w a,b form a w × w matrix. Pooling layers reduce feature map size, e.g. by taking the maximum value from a few contiguous pixels, and are often followed by application of a nonlinear (activation) function. Once the feature map size becomes sufficiently small, the final output is computed from a function that depends on all remaining pixels (fully connected layer). The weights and fully connected function are optimized by training on large datasets. In contrast, variables such as the number of convolution and pooling layers and the size w of the weight matrices (known as hyperparameters) are fixed for a specific CNN 1 . CNN's key properties are thus translationally invariant convolution and pooling layers, each characterized by a constant number of parameters (independent of system size), and sequential data size reduction (i.e., a hierarchical structure).

Motivated by this architecture we introduce a quantum circuit model extending these key properties to the quantum domain (Fig. 1b). The circuit's input is an unknown quantum state ρ in . A convolution layer applies a single quasi-local unitary (U i ) in a translationallyinvariant manner for finite depth. For pooling, a fraction of qubits are measured, and their outcomes determine unitary rotations (V j ) applied to nearby qubits. Hence, nonlinearities in QCNN arise from reducing the number of degrees of freedom. Convolution and pooling layers are performed until the system size is sufficiently small; then, a fully connected layer is applied as a unitary F on the remaining qubits. Finally, the outcome of the circuit is obtained by measuring a fixed number of output qubits. As in the classical case, circuit structures (i.e. QCNN hyperparameters) such as the number of convolution and pooling layers are fixed, and the unitaries themselves are learned.

A QCNN to classify N -qubit input states is thus characterized by O(log(N )) parameters. This corresponds to doubly exponential reduction compared to a generic quantum circuit-based classifier 12 and allows for efficient learning and implementation. For example, given classified training data {(|ψ α , y α ) : α = 1, ..., M }, where |ψ α are input states and y α = 0 or 1 are corresponding binary classification outputs, one could compute the mean-squared error

Here, f {Ui,Vj ,F } (|ψ α ) denotes the expected QCNN output value for input |ψ α . Learning then consists of initializing all unitaries and successively optimizing them until convergence, e.g. via gradient descent.

To gain physical insight into the mechanism underlying QCNNs and motivate their application to the problems under consideration, we now relate our circuit model to two well-known concepts in quantum information theory-the multiscale entanglement renormalization ansatz 25 (MERA) and quantum error correction (QEC). The MERA framework provides an efficient tensor network representation of many classes of interesting many-body wavefunctions, including those associated with critical systems [25][26][27] . A MERA can be understood as a quantum state generated by a sequence of unitary and isometry layers applied to an input state (e.g. |00 ). While each isometry layer introduces a set of new qubits in a predetermined state (e.g. |0 ) before applying unitary gates on nearby ones, unitary layers simply apply quasi-local unitary gates to the existing qubits (Figure 1c). This exponentially growing, hierarchical structure allows for the long-range correlations associated with critical systems. The QCNN circuit has similar structure, but runs in the reverse direction. Hence, for any given state |ψ with a MERA representation, there is always a QCNN that recognizes |ψ with deterministic measurement outcomes; one such QCNN is simply the inverse of the MERA circuit.

For input states other than |ψ , however, such a QCNN does not generally produce deterministic measurement outcomes. These additional degrees of freedom distinguish QCNN from MERA. Specifically, we can identify the measurements as syndrome measurements in QEC 28 , which determine error correction unitaries V j to apply to the remaining qubit(s). Thus, a QCNN circuit with multiple pooling layers can be viewed as a combination of MERA -an important variational ansatz for manybody wavefunctions -and nested QEC -a mechanism to detect and correct local quantum errors without collapsing the wavefunction. This makes QCNN a powerful architecture to classify input quantum states or devise novel QEC codes. In particular, for QPR, the QCNN can provide a MERA realization of a representative state |ψ 0 in the target phase. Other input states within the same phase can be viewed as |ψ 0 with local errors, which are repeatedly corrected by the QCNN in multiple layers. In this sense, the QCNN circuit can mimic renormalizationgroup (RG) flow, a methodology which successfully classifies many families of quantum phases 29 . For QEC optimization, the QCNN structure allows for simultaneous optimization of efficient encoding and decoding schemes with potentially rich entanglement structure.

# DETECTING A 1D SPT PHASE

We first demonstrate the potential of QCNN explicitly by applying it to QPR in a class of one-dimensional (red) to detect the SPT/paramagnet phase transition along h1 = 0.5J for N = 135 spins. The critical point is identified as h2/J = 0.423 using infinite size DMRG (bold line). Darkening colors show higher QCNN depth or shorter string lengths. In the shaded area, the correlation length exceeds the system size and finite-size effects can considerably affect our results. Inset:

The ratio of SOP sample complexity to QCNN sample complexity is plotted as a function of depth d on a logarithmic scale for h1/J = 0.3918. In the numerically accessible regime, this reduction of sample complexity scales exponentially as 1.73e 0.28d (trendline).

many-body systems. Specifically, we consider a Z 2 × Z 2 symmetry-protected topological (SPT) phase P, a phase containing the S = 1 Haldane chain 30 , and ground states {|ψ G } of a family of Hamiltonians on a spin-1/2 chain with open boundary conditions:

(2) X i , Z i are Pauli operators for the spin at site i, and the Z 2 × Z 2 symmetry is generated by X even(odd) = i∈even(odd) X i . Figure 2a shows the phase diagram as a function of (h 1 /J, h 2 /J). When h 2 = 0, the Hamiltonian is exactly solvable via Jordan-Wigner transformation 29 , confirming that P is characterized by nonlocal order parameters. When h 1 = h 2 = 0, all terms are mutually commuting, and a ground state is the 1D cluster state. Our goal is to identify whether an given, unknown ground state drawn from the phase diagram belongs to P.

As an example, we first present an exact, analytical QCNN circuit that recognizes P, see Figure 2b. The convolution layers involve controlled-phase gates as well as Toffoli gates with controls in the X-basis, and pooling layers perform phase-flips on remaining qubits when one adjacent measurement yields X = -1. This convolutionpooling unit is repeated d times, where d is the QCNN depth. The fully connected layer measures Z i-1 X i Z i+1 on the remaining qubits. Figure 2c shows the QCNN output for a system of N = 135 spins and d = 1, ..., 4 along h 2 = 0.5J, obtained using matrix product state simulations. As d is increased, the measurement outcomes show sharper changes around the critical point, and the output of a d = 2 circuit already reproduces the phase diagram with high accuracy (Figure 2a). This QCNN can also be used for other Hamiltonian models belonging to the same phase, such as the S = 1 Haldane chain 30 (see Methods).

## Sample Complexity

The performance of a QPR solver can be quantified by sample complexity 21 : what is the expected number of copies of the input state required to identify its quantum phase? We demonstrate that the sample complexity of our exact QCNN circuit is significantly better than that of conventional methods. In principle, P can be detected by measuring a nonzero expectation value of string order parameters (SOP) 31,32 such as

In practice, however, the expectation values of SOP vanish near the phase boundary due to diverging correlation length 32 ; since quantum projection noise is maximal in this vicinity, many experimental repetitions are required to affirm a nonzero expectation value. In contrast, the QCNN output is much sharper near the phase transition, so fewer repetitions are required. Quantitatively, given some |ψ in and SOP S, a projective measurement of S can be modeled as a (generalized) Bernoulli random variable, where the outcome is 1 with probability p = ( ψ in | S |ψ in + 1)/2 and -1 with probability 1-p (since S 2 = 1); after M binary measurements, we estimate p. p > p 0 = 0.5 signifies |ψ in ∈ P. We define the sample complexity M min as the minimum M to test whether p > p 0 with 95% confidence using an arcsine variance-stabilizing transformation 33 :

Similarly, the sample complexity for a QCNN can be determined by replacing ψ in | S |ψ in by the QCNN output expectation value in the expression for p.

Figure 2d shows the sample complexity for the QCNN at various depths and SOPs of different lengths. Clearly, QCNN requires substantially fewer input copies throughout the parameter regime, especially near criticality. More importantly, although the SOP sample complexity scales independently of string length, the QCNN sample complexity consistently improves with increasing depth and is only limited by finite size effects in our simulations. In particular, compared to SOPs, QCNN reduces sample complexity by a factor which scales exponentially with the QCNN's depth in numerically accessible regimes (inset). Such scaling arises from the iterative QEC performed at each depth and is not expected from any measurements of simple (potentially nonlocal) observables. We show in Methods that our QCNN circuit measures a multiscale string order parameter-a sum of products of exponentially many different SOPs which remains sharp up to the phase boundary.

## MERA and QEC

Additional insights into the QCNN's performance are revealed by interpreting it in terms of MERA and QEC. In particular, our QCNN is specifically designed to contain the MERA representation of the 1D cluster state (|ψ 0 )-the ground state of H with h 1 = h 2 = 0-such that it becomes a stable fixed point. When |ψ 0 is fed as input, each convolution-pooling unit produces the same state |ψ 0 with reduced system size in the unmeasured qubits, while yielding deterministic outcomes (X = 1) in the measured qubits. The fully connected layer measures  the SOP for |ψ 0 . When an input wavefunction is perturbed away from |ψ 0 , our QCNN corrects such "errors." For example, if a single X error occurs, the first pooling layer identifies its location, and controlled unitary operations correct the error propagated through the circuit (Fig. 3). Similarly, if an initial state has multiple, sufficiently separated errors (possibly in coherent superpositions), the error density after several iterations of convolution and pooling layers will be significantly smaller 34 . If the input state converges to the fixed point, our QCNN classifies it into the SPT phase with high fidelity. Clearly, this mechanism resembles the classification of quantum phases based on renormalization-group (RG) flow.

### Obtaining QCNN from Training Procedure

Having analytically illustrated the computational power of the QCNN circuit model, we now demonstrate how a QCNN for P can also be obtained using the learning procedure. In our example, the QCNN's hyperparameters are chosen such that there are four convo- This example illustrates how the QCNN structure avoids overfitting to training data with its exponentially reduced number of parameters.

While the training dataset for this particular QPR problem consists of solvable points, more generally, such a dataset can be obtained by using traditional methods (e.g. measuring SOPs) to classify representative states that can be efficiently generated either numerically or experimentally 36,37 .

#### OPTIMIZING QUANTUM ERROR CORRECTION

As seen in the previous example, the QCNN's architecture enables one to perform effective QEC. We next leverage this feature to design a new QEC code itself that is optimized for a given error model. More specifically, any QCNN circuit (and its inverse) can be viewed as a decoding (encoding) quantum channel between the physical input qubits and the logical output qubit. The encoding scheme introduces sets of new qubits in a predetermined state, e.g. |0 , while the decoding scheme performs measurements (Fig. 5a). Given a error channel N , our aim is therefore to maximize the recovery fidelity

where M q (M -1 q ) is the encoding (decoding) scheme generated by a QCNN circuit, and |±x, y, z are the ±1 eigenstates of the Pauli matrices. Thus, our method simultaneously optimizes both encoding and decoding schemes, while ensuring their efficient implementation in realistic systems. Importantly, the variational optimization can be carried out with a unknown N since f q can be evaluated experimentally.

To illustrate the potential of this procedure, we consider a two-layer QCNN with N = 9 physical qubits and 126 variational parameters (Figure 5a and Methods). This particular architecture includes the nested (classical) repetition codes and the 9-qubit Shor code 38 ; in the following, we compare our performance to the better of the two. We consider three different input error models: (1) independent single-qubit errors on all qubits with equal probabilities p µ for µ = X, Y , and Z errors or (2) anisotropic probabilities p x = p y = p z , and (3) independent single-qubit anisotropic errors with additional two-qubit correlated errors X i X i+1 with probability p xx .

Upon initializing all QCNN parameters to random values and numerically optimizing them to maximize f q , we find that our model produces the same logical error rate as known codes in case (1), but can reduce the error rate by a constant factor in case (2), depending on the specific input error probability ratios (e.g. 14% for p x = 1.8p y , or 50% for p x = 0.4p y -see Methods). More drastically, in case (3), the optimized QEC code performs significantly better than known codes (Figure 5b). Specifically, because the Shor code is only guaranteed to correct arbitrary single-qubit errors, it performs even worse than using no error correction, while the optimized QEC code performs much better. This example demonstrates the power of using QCNNs to obtain and optimize new QEC codes for realistic, a priori unknown error models.

# EXPERIMENTAL REALIZATIONS

Our QCNN architecture can be efficiently implemented on several state-of-the-art experimental platforms. The key ingredients for realizing QCNNs include the efficient preparation of quantum many-body input states, the application of two-qubit gates at various length scales, and projective measurements 39 . These capabilities have already been demonstrated in multiple programmable quantum simulators consisting of N ≥ 50 qubits based on trapped neutral atoms and ions, or superconducting qubits [40][41][42][43] .

As an example, we present a feasible protocol for nearterm implementation of our exact cluster model QCNN circuit via neutral Rydberg atoms 40,44 , where long-range dipolar interactions allow high fidelity entangling gates 45 among distant qubits in a variable geometric arrangement. The qubits can be encoded in the hyperfine ground states, where one of the states can be coupled to the Rydberg level to perform efficient entangling operations via the Rydberg-blockade mechanism 45 ; an explicit implementation scheme for every gate in Fig. 2b is provided in Methods. Our QCNN at depth d with N input qubits requires at most 7N 2 (1 -3 1-d ) + N 3 1-d multi-qubit operations and 4d single-qubit rotations. For a realistic effective coupling strength Ω ∼ 2π ×10-100 MHz and singlequbit coherence time τ ∼ 200 µs limited by the Rydberg state lifetime, approximately Ωτ ∼ 2π × 10 3 -10 4 multiqubit operations can be performed, and a d = 4 QCNN on N ∼ 100 qubits feasible. These estimates are reasonably conservative as we have not considered advanced control techniques such as pulse-shaping 46 , or potentially parallelizing independent multi-qubit operations.

# OUTLOOK

These considerations indicate that QCNNs provide a promising quantum machine learning paradigm. Sev-eral interesting generalizations and future directions can be considered. First, while we have only presented the QCNN circuit structure for recognizing 1D phases, it is straightforward to generalize the model to higher dimensions, where phases with intrinsic topological order such as the toric code are supported 47,48 . Such studies could potentially identify nonlocal order parameters with low sample complexity for lesser-understood phases such as quantum spin liquids 49 or anyonic chains 50 . To recognize more exotic phases, we could also relax the translationinvariance constraints, resulting in O(N ) parameters for system size N , or use ancilla qubits to implement parallel feature maps following traditional CNN architecture. Further extensions can incorporate optimizations for fault-tolerant operations on QEC code spaces. Finally, while we have used a finite-difference scheme to compute gradients in our learning demonstrations, the structural similarity of QCNN with its classical counterpart motivates adoption of more efficient schemes such as backpropagation 1 .

## Methods

### Phase Diagram and QCNN Circuit Simulations

The phase diagram in the main text (Fig. 2a) was numerically obtained using the infinite size density-matrix renormalization group (DMRG) algorithm. We generally follow the method outlined in Ref. 51 with the maximum bond dimension 150. To extract each data point in Fig. 2a, we numerically obtain the ground state energy density as a function of h 2 for fixed h 1 and computed its second order derivative. The phase boundary points are identified from sharp peaks.

The simulation of our QCNN in Fig. 2b also utilizes matrix product state representations. We first obtain the input ground state wavefunction using finite-size DMRG 51 with bond dimension D = 130 for a system of N = 135 qubits. Then, the circuit operations are performed by sequentially applying SWAP and two-qubit gates on nearest neighboring qubits 52 . Each three-qubit gate is decomposed into two-qubit unitaries 53 . We find that increasing bond dimension to D = 150 does not lead to any visible changes in our main figures, confirming a reasonable convergence of our method. The color plot in Fig. 2a is similarly generated for a system of N = 45 qubits.

### QCNN for the S = 1 Haldane Chain

As discussed in the main text, the (spin-1/2) 1D cluster state belongs to an SPT phase protected by Z 2 × Z 2 symmetry, a phase which also contains the celebrated S = 1 Haldane chain 30 . It is thus natural to ask whether this circuit can be used to detect the phase transition between the Haldane phase and an S = 1 paramagnetic phase, which we numerically demonstrate here. The one-parameter family of Hamiltonians we con-sider for the Haldane phase is defined on a onedimensional chain of N spin-1 particles with open boundary conditions 30 :

In this equation, S j denotes the vector of S = 1 spin operators at site j. The system is protected by a Z 2 × Z 2 symmetry generated by global π-rotations of every spin around the X and Y axes: R x = j e iπS x j , R y = e iπS y j . When ω is zero or small compared to J, the ground state belongs to the SPT phase, but when ω/J is sufficiently large, the ground state becomes paramagnetic 30 .

To apply our QCNN circuit to this Haldane phase, we must first identify a quasi-local isometric map U between the two models, because their representations of the symmetry group are distinct. More specifically, since the cluster model has a Z 2 × Z 2 symmetry generated by X even(odd) = i∈even(odd) X i , we require U R x U † = X odd and U R y U † = X even . Such a map can be constructed following Ref. 54. Intuitively, it extends the local Hilbert space of a spin-1 particle by introducing a spin singlet state |s and mapping it to a pair of spin-1/2 particles:

Here, |± denote the ±1 eigenstates of the (spin-1/2) Pauli matrix X. |µ denotes a spin-1 state defined by R ν |µ = (-1) δµ,ν +1 |µ (µ, ν ∈ {x, y, z}). The QCNN circuit for the Haldane chain thus consists of applying U followed by the circuit presented in the main text.

Figure 7 shows the QCNN output for an input system of N = 54 spin-1 particles at depths d = 1, ..., 4, obtained using matrix product state simulations with bond dimension D = 160. For this system size, we numerically identified the critical point as ω/J = 1.035 ± 0.005, by using DMRG to obtain the second derivative of energy density as a function of ω and J. The QCNN provides accurate identification of the phase transition.

### Multiscale String Order Parameters

We examine the final operator measured by our circui that recognizes the SPT phase in the Heisenberg picture. Although a QCNN performs non-unitary measurements in the pooling layers, similar to QEC circuits 28 , one can postpone all measurements to the end and replace pooling layers by unitary controlled gates acting on both measured and unmeasured qubits. In this way, the QCNN is equivalent to measuring a non-local observable

where i is the index of the measured qubit in the final layer and U (l)

CP is the unitary corresponding to the convolution-pooling unit at depth l. A more explicit expression of O can be obtained by commuting U CP with the Pauli operators, which yields recursive relations:

ĩ enumerates every qubit at depth l -1, including those measured in the pooling layer (Fig. 8a). It follows that an SOP of the form ZXX...XZ at depth l transforms into a weighted linear combination of 16 products of SOPs at depth l -1. Thus, instead of measuring a single SOP, our QCNN circuit measures a sum of products of exponentially many different SOPs (Fig. 8b):

O can be viewed as a multiscale string order parameter with coefficients computed recursively in d using Eqs. (8,9). This allows the QCNN to produce a sharp classification output even when the correlation length is as long as 3 d . 

### Demonstration of Learning Procedure for QPR

To perform our learning procedure in a QPR problem, we choose the hyperparameters for the QCNN as shown in Fig. 9. This hyperparameter structure can be used for generic (1D) phases, and is characterized by a single integer n that determines the reduction of system size in each convolution-pooling layer, L → L/n. (Fig. 9 shows the special case where n = 3). The first convolution layer involves (n+1)-qubit unitaries starting on every n th qubit. This is followed by n layers of n-qubit unitaries arranged as shown in Fig. 9. The pooling layer measures n -1 out of every contiguous block of n qubits; each of these is associated with a unitary V j applied to the remaining qubit, depending on the measurement outcome. This set of convolution and pooling layers is repeated d times, where d is the QCNN depth. Finally, the fully connected layer consists of an arbitrary unitary on the remaining N/n d qubits, and the classification output is given by the measurement output of the middle qubit (or any fixed choice of one of them). For our example, we choose n = 3 because the Hamiltonian in Eq. ( 2) involves three-qubit terms.

In our simulations, we consider only N = 15 spins and depth d = 1, because simulating quantum circuits on classical computers requires a large amount of resources. We parameterize unitaries as exponentials of generalized a × a Gell-Mann matrices {Λ i }, where a = 2 w and w is the number of qubits involved in the unitary 55 

This parameterization is used directly for the unitaries in the convolution layers C 2 -C 4 , the pooling layer, and the fully connected layer. For the first convolution layer C 1 , we restrict the choice of U 1 to a product of six two-qubit unitaries between each possible pair of qubits: U 1 = U (23) U (24) U (13) U (14) U (12) U (34) , where U (αβ) is a two-qubit unitary acting on qubits indexed by α and β. Such a decomposition is useful when considering ex-perimental implementation.

In the QCNN learning procedure, all parameters c µ are set to random values between 0 and 2π for the unitaries {U i , V j , F }. In every iteration of gradient descent, we compute the derivative of the mean-squared error function (Eq. ( 1) in the main text) to first order with respect to each of these coefficients c µ by using the finitedifference method:

∂cµ , where η is the learning rate for that iteration. We compute the learning rate using the bold driver technique from machine learning, where η is increased by 5% if the error has decreased from the previous iteration, and decreased by 50% otherwise 56 . We repeat the gradient descent procedure until the error function changes on the order of 10 -5 between successive iterations. In our simulations, we use = 10 -4 for the gradient computation, and begin with an initial learning rate of η 0 = 10.

### Construction of QCNN Circuit

To construct the exact QCNN circuit in Fig. 2b, we followed the guidelines discussed in the main text. Specifically, we designed the convolution and pooling layers to satisfy the following two important properties:

1. Fixed-point criterion: If the input is a cluster state |ψ 0 of L spins, the output of the convolutionpooling layers is a cluster state |ψ 0 of L/3 spins, with all measurements deterministically yielding |0 .

2. QEC criterion: If the input is not |ψ 0 but instead differs from |ψ 0 at one site by an error which commutes with the global symmetry, the output should still be a cluster state of L/3 spins, but at least one of the measurements will result in the state |1 .

These two properties are desirable for any quantum circuit implementation of RG flow for performing QPR.

In the specific case of our Hamiltonian, the ground state (1D cluster state) is a graph state, which can be efficiently obtained by applying a sequence of controlled phase gates to a product state. This significantly simplifies the construction of the MERA representation for the fixed-point criterion. To satisfy the QEC criterion, we treat the ground state manifold of the unperturbed Hamiltonian H = -J i Z i X i+1 Z i+2 as the code space of a stabilizer code with stabilizers {Z i X i+1 Z i+2 }. The remaining degrees of freedom in the QCNN convolution and pooling layers are then specified such that the circuit detects and corrects the error (i.e. measures at least one |1 and prevents propagation to the next layer) when a single-qubit X error is present.  

### QCNN for General QPR Problems

Our interpretation of QCNNs in terms of MERA and QEC motivates their application for recognizing more generic quantum phases. For any quantum phase P whose RG fixed-point wavefunction |ψ 0 (P) has a tensor network representation in isometric or G-isometric form 58 (Fig. 10a), one can systematically construct a corresponding QCNN circuit. This family of quantum phases includes all 1D SPT and 2D string-net phases 48,58,59 . In these cases, one can explicitly construct a commuting parent Hamiltonian for |ψ 0 (P) and a MERA structure in which |ψ 0 (P) is a fixed-point wavefunction (Fig. 10a for 1D systems). tThe diagrammatic proof of this fixed-point property is given in Fig. 10b. Furthermore, any "local error" perturbing an input state away from |ψ 0 (P) can be identified by measuring a fraction of terms in the parent Hamiltonian, similar to syndrome measurements in stabilizer-based QEC 28 . Then, a QCNN for P simply consists of the MERA for |ψ 0 (P) and a nested QEC scheme in which an input state with error density below the QEC threshold 60 "flows" to the RG fixed point. Such a QCNN can be optimized via our learning procedure.

While our generic learning protocol begins with completely random unitaries, as in the classical case 1 , this initialization may not be the most efficient for gradient descent. Instead, motivated by deep learning techniques such as pre-training 1 , a better initial parameterization would consist of a MERA representation of |ψ 0 (P) and one choice of nested QEC. With such an initialization, the learning procedure serves to optimize the QEC scheme, expanding its threshold to the target phase boundary (Fig. 10c).

### Experimental Resource Analysis

To compute the gate depth of the cluster model QCNN circuit in a Rydberg atom implementation, we analyze each gate shown in Figure 2b. By postponing pooling layer measurements to the end of the circuit, the multiqubit gates required are

By using Rydberg blockade-mediated controlled gates 57 , it is straightforward to implement C z Z ij and C z C z Z ijk = e iπ(-1+Zi)(-1+Zj )(-1+Z k )/8 . The desired C x Z ij and C x C x X ijk gates can then be obtained by conjugating C z Z ij and C z C z Z ijk by single-qubit rotations. For input size of N spins, the k th convolution-pooling unit thus applies 4N /3 k-1 C z Z ij gates, N/3 k-1 C x C x X ijk gates, and 2N /3 k-1 layers of C x Z ij gates. The depth of single-qubit rotations required is 4d, as these rotations can be implemented in parallel on all N qubits. Finally, the fully connected layer consists of N 3 1-d C z Z ij gates. Thus, the total number of multi-qubit operations required for a QCNN of depth d operating on N spins is 7N 2 (1-3 1-d )+N 3 1-d . Note that we need not use SWAP gates since the Rydberg interaction is long-range.

### Demonstration of Learning Procedure for QEC

To obtain the QEC code considered in the main text, we consider a QCNN with N = 9 input physical qubits and simulate the circuit evolution of its 2 N × 2 N density matrix exactly. Strictly speaking, our QCNN has three layers: a three-qubit convolution layer U 1 , a 3-to-1 pooling layer, and a 3-to-1 fully connected layer U 2 . Without loss of generality, we may ignore the optimization over the pooling layer by absorbing its effect into the first convolution layer, leading to the effective two-layer structure shown in Fig. 5a. The generic three-qubit unitary operations U 1 and U 2 are parameterized using 63 Gell-Mann coefficients each.

As discussed in the main text, we consider three different error models: (1) independent single-qubit errors on all qubits with equal probabilities p µ for µ = X, Y , and Z errors, (2) independent single-qubit errors on all qubits, with anisotropic probabilities p x = p y = p z , and (3) independent single-qubit anisotropic errors with additional two-qubit correlated errors X i X i+1 with probability p xx . More specifically, the first two error models are realized by applying a (generally anisotropic) depolarization quantum channel to each of the nine physical qubits:

with Pauli matrices σ µ i for i ∈ {1, 2, . . . , 9} (the qubit indices are defined from bottom to top in Fig. 5a). For the anisotropic case, we trained the QCNN on various different error models with the same total error probability p x + p y + p z = 0.001, but different relative ratios; the resulting ratio between the logical error probability of the Shor code and that of the QCNN code is plotted as a function of anisotropy in Fig. 11. For strongly anisotropic models, the QCNN outperforms the Shor code, while for nearly isotropic models, the Shor code is optimal and QCNN can achieve the same logical error rate.

For the correlated error model, we additionally apply a quantum channel:

for pairs of nearby qubits, i.e. i ∈ {1, 2, 4, 5, 7, 8}. Such a geometrically local correlation is motivated from experimental considerations. In this case, we train our QCNN circuit on a specific error model with parameter choices p x = 5.8 × 10 -3 , p y = p z = 2 × 10 -3 , p xx = 2 × 10 -4 and evaluate the logical error probabilities for various physical error models with the same relative ratios, but different total error per qubit p x + p y + p z + p xx . In general, for an anisotropic logical error model with probabilities p µ for σ µ logical errors, the overlap f q is (1 -2 µ p µ /3), since ±ν| σ µ |±ν = (-1) δµ,ν +1 . Becuase of this, we compute the total logical error probability from f q as 1.5(1f q ). Hence, our goal is to maximize the logical state overlap f q defined in Eq. ( 5). If we naively apply the gradient descent method based on f q directly to both U 1 and U 2 , we find that the optimization is easily trapped in a local optimum. Instead, we optimize two unitaries U 1 and U 2 sequentially, similar to the layer-bylayer optimization in backpropagation for conventional CNN 1 .

A few remarks are in order. First, since U 1 is optimized prior to U 2 , one needs to devise an efficient cost function C 1 that is independent of U 2 . In particular, simply maximizing f q with an assumption U 2 = 1 may not be ideal, since such choice does not capture a potential interplay between U 1 and U 2 . Second, because U 1 captures arbitrary single qubit rotations, the definition of C 1 should be basis independent. Finally, we note that the tree structure of our circuit allows one to view the first layer as an independent quantum channel:

where tr a [•] denotes tracing over the ancilla qubits that are measured in the intermediate step. From this perspective, M U1 describes an effective error model to be corrected by the second layer. With these considerations, we optimize U 1 such that the effective error model M U1 becomes as classical as possible, i.e. M U1 is dominated by a "flip" error along a certain axis with a strongly suppressed "phase" error. Only then, the remant, simpler errors will be corrected by the second layer. More specifically, one may represent M U1 using a map M U1 : r → M r + c, where r ∈ R 3 is the Bloch vector for a qubit state ρ ≡ 1 2 1 + r • σ 53 . The singular values of the real matrix M encode the probabilities p 1 ≥ p 2 ≥ p 3 for three different types of errors. We choose our cost function for the first layer as C 1 = p 2 1 + p 2 + p 3 , which is relatively more sensitive to p 2 and p 3 than p 1 and ensure that the resultant, optimized channel M U1 is dominated by one type of error (with probability p 1 ). We note that M can be efficiently evaluated from a quantum device without knowing N , by performing quantum process tomography for a single logical qubit. Once U 1 is optimized, we use gradient decent to find an optimal U 2 to maximize the fidelity f q . As with QPR, gradients are computed via the finitedifference method, and the learning rate is determined by the bold driver technique 1 .

