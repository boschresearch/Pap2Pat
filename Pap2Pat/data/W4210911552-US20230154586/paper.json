{
    "id": "https://semopenalex.org/work/W4210911552",
    "authors": [
        "Xue Feng",
        "J. Castle",
        "Jingwei Duan",
        "Quan Chen"
    ],
    "title": "Development of a virtual source model for Monte Carlo\u2010based independent dose calculation for varian linac",
    "date": "2022-02-09",
    "abstract": "Monte Carlo (MC) independent dose calculations are often based on phase-space files (PSF), as they can accurately represent particle characteristics. PSF generally are large and create a bottleneck in computation time. In addition, the number of independent particles is limited by the PSF, preventing further reduction of statistical uncertainty. The purpose of this study is to develop and validate a virtual source model (VSM) to address these limitations. Particles from existing PSF for the Varian TrueBeam medical linear accelerator 6X, 6XFFF, 10X, and 10XFFF beam configurations were tallied, analyzed, and used to generate a dual-source photon VSM that includes electron contamination. The particle density distribution, kinetic energy spectrum, particle direction, and the correlations between characteristics were computed. The VSM models for each beam configuration were validated with water phantom measurements as well as clinical test cases against the original PSF. The new VSM requires 67 MB of disk space for each beam configuration, compared to 50 GB for the PSF from which they are based and effectively remove the bottleneck set by the PSF. At 3% MC uncertainty, the VSM approach reduces the calculation time by a factor of 14 on our server. MC doses obtained using the VSM approach were compared against PSF-generated doses in clinical test cases and measurements in a water phantom using a gamma index analysis. For all tests, the VSMs were in excellent agreement with PSF doses and measurements (>90% passing voxels between doses and measurements). Results of this study indicate the successful derivation and implementation of a VSM model for Varian Linac that significantly saves computation time without sacrificing accuracy for independent dose calculation.",
    "sections": [
        {
            "title": "Introduction",
            "paragraphs": [
                "Monte Carlo (MC) simulation is regarded as the gold standard for estimating the amount of energy deposited into a medium by ionizing radiation. 1 ,  2  The clinical utility of using MC simulations for independent dose calculations is often hindered by the computational resources and time required to run these simulations. 3 ,  4  Often, MC simulations begin with phase\u2010space files (PSF), which are derived from full simulations of primary electron interactions within the treatment head and store the resulting particles at a reference surface a set distance from the treatment head. Given an accurate representation of the geometries of the treatment head, PSF will contain the most accurate description of the resulting beam. MC dose calculations must be run with a large number of simulated particles to achieve clinically acceptable accuracy. This, in turn, requires input PSF that contain a large (\u223cbillions), but finite, number of particles that take up significant amounts of disk space to store (\u223cGB). A major bottleneck in MC calculations arises from the input/output (I/O) time required for reading large PSF from the disk. Hard disk drives (HDDs) have buffered file read rates up to \u223c150\u00a0MB/s, while solid state drives (SSDs) have buffered file read rates up to \u223c500\u00a0MB/s. Even with the increased read rate for an SSD, a best\u2010case scenario for reading a 50 GB PSF will take \u223c100 s just to load the file. This I/O burden becomes more significant with methods that use multicore processing, as the multiple processes will compete over the same I/O bandwidth.",
                "A common solution to ease the I/O burden is to develop so\u2010called virtual source models (VSMs), 5 ,  6 ,  7 ,  8 ,  9 ,  10 ,  11 ,  12 ,  13 ,  14 ,  15 ,  16 ,  17 ,  18 ,  19 ,  20 ,  21  which approximate the behavior of particles at the phase\u2010space surface. VSMs have two distinct advantages: they take up significantly less disk space and allow for infinite sampling. Particle parameters from the PSF must be modeled precisely for the VSM to yield quality simulations. Numerous studies have been performed to generate VSM for a wide variety of radiotherapy treatment options; each was derived using either experimental measurements 7 ,  9  or previously\u2010generated PSF files. 5 ,  6 ,  8 ,  10 ,  11 ,  12 ,  13 ,  14 ,  15 ,  16 ,  17 ,  18 ,  19 ,  20 ,  21",
                "In this study, a generalized method to derive VSM from International Atomic Energy Agency (IAEA)\u2010compliant PSF is introduced. Several VSMs were generated from PSF for the Varian (Varian Medical Systems, Palo Alto, CA) TrueBeam medical linear accelerator (Linac) for varying electron beam energies and treatment beam flattening configurations. Each VSM utilizes a dual\u2010source approach to model photons and includes electron contamination. The validity of this method is demonstrated in three studies. First, comparisons were made between PSF\u2010 and VSM\u2010sampled particles at the phase\u2010space surface and at the treatment isocenter to validate the VSM sampling method. Next, test patient cases were copied and delivered to a solid water phantom from which 2D coronal dose distributions were measured. MC doses obtained using the VSM method were compared to measured doses to validate the MC algorithm. Last, comparisons between the VSM\u2010 and PSF\u2010generated MC doses in clinical test cases were made to further validate the VSM method as well as to illustrate the computation time savings afforded by the VSM."
            ],
            "subsections": []
        },
        {
            "title": "Methods",
            "paragraphs": [],
            "subsections": [
                {
                    "title": "Varian Psf",
                    "paragraphs": [
                        "We obtained IAEA\u2010compliant PSF from Varian for 6 MV (6X) and 10 MV (10X) electron beam energies. For 6X and 10X beam energies, separate PSF were obtained for the flattening\u2010filter\u2010free (FFF) operation mode (6XFFF and 10XFFF, respectively). The PSF contain roughly 2.5 billion particles (photons, electrons, and positrons) per beam configuration. These PSF correspond to \u201cversion 2\u2033 from Varian. 22 ,  23  In short, these files were generated by first simulating electron beams in the accelerator using the code package Parmela 24  and then transporting through the bending magnet. The electron beam exiting the bend magnet parametrized energy spectrum, spot size, and beam divergence using Gaussian distributions, which were tuned to reference gold beam data. 22 ,  23  The resulting electrons were then passed to the code package Geant4 25  to simulate transport through the treatment head.",
                        "The results of the Geant4 simulation were tallied at a distance of 73.3\u00a0cm from the isocenter (26.7\u00a0cm from the focal spot) and saved in a format recommended by the IAEA. 26  The files contain six parameters for each particle: particle type (photon, electron, or positron), kinetic energy, crossplane, and inplane positions (X\u00a0and Y, respectively), and crossplane and inplane direction cosines (U and V, respectively). The third direction cosine W (Z) was set to 1 for all particles."
                    ],
                    "subsections": []
                },
                {
                    "title": "Dual\u2010Source Treatment Of Photons",
                    "paragraphs": [
                        "We assume that photons in the PSF arise from two sources. We consider \u201cprimary photons\u201d as those that originated from the Bremsstrahlung radiation in the treatment head. We consider \u201csecondary\u201d or \u201cscattered photons\u201d as photons that have scattered from interactions in the collimator or in the flattening filter, if present. The PSF do not contain information on the origin of the photons. To come up with a criterion to discriminate between primary and scattered photons, we analyzed the distributions of the position of photons at the focal spot by reverse transporting photons to the focal spot plane (Z=0). Given that the electron beam spot size entering the tungsten target is parameterized by a Gaussian, we performed Gaussian fits to the X and Y profiles around X=Y=0. Using the means and standard deviations from these fits, we defined a primary photon as a photon that has a position at the focal spot plane within the window X=\u03bcx\u00b13\u03c3x and Y=\u03bcy\u00b13\u03c3y. All photons outside this window were considered scattered photons. The fraction of primary to scattered photons was saved for downstream sampling in MC simulations. The means and standard deviations of these fits are adjustable parameters in our final model in case additional fine tuning is needed."
                    ],
                    "subsections": []
                },
                {
                    "title": "Vsm",
                    "paragraphs": [
                        "Particles were scored at the phase\u2010space surface (Z=26.7\u00a0cm) and split into groups based on particle type. Photons were split into two groups based on primary/scatter classification, while electrons and positrons were grouped together and considered purely scatter to maximize count statistics, as\u00a0>99% of PSF particles are photons. For each of the three groups, histograms were used to generate probability density functions for the following parameters: particle X position, particle Y position based on X position, particle kinetic energy based on radial position (R), particle U based on X position, and particle V based on Y position. The following subsections outline exactly how each parameter is modeled."
                    ],
                    "subsections": [
                        {
                            "title": "Particle Crossplane And Inplane Positions",
                            "paragraphs": [
                                "The X positions for each particle were counted separately for primary photons, scattered photons, and electrons/positrons. Histograms for photons used a bin width of 0.1\u00a0cm, while the electron/positron histogram had a bin width of 0.2\u00a0cm to reduce noise. The Y positions of each particle were counted in histograms using the exact grouping and binning as particle X positions. Further, Y position histograms were generated for every X bin to preserve the correlation between particle X and Y position."
                            ],
                            "subsections": []
                        },
                        {
                            "title": "Particle Kinetic Energy",
                            "paragraphs": [
                                "The kinetic energies of each particle were counted separately for primary photons, scattered photons, and electrons/positrons. Histograms for photons used a bin width of 0.02 MeV, while the electron/positron histogram had a bin width of 0.05 MeV to reduce noise. Further, separate kinetic energy histograms were counted based on radial position. A kinetic energy histogram was generated every 0.5\u00a0cm in R up to R=5.5\u00a0cm. Particles with R>5.5\u00a0cm were counted in a single histogram."
                            ],
                            "subsections": []
                        },
                        {
                            "title": "Particle Crossplane And Inplane Directions",
                            "paragraphs": [
                                "The U and V direction cosines for each particle were counted separately for primary photons, scattered photons, and electrons/positrons. Instead of counting U and V values directly, we counted the quantities U\u2032\u2212U and V\u2032\u2212V, where U\u2032\u2261X/Z and V\u2032\u2261Y/Z. Our rationale was that most particles direction will, on average, follow their geometric position with respect to the origin at the treatment head with some fluctuations around that vector. This is indeed relevant for primary photons, where such histograms show a peak around 0 with very small Gaussian spread. The relationship is less relevant for scattered photons and electrons/positrons, as the scattering processes do not preserve information on particle origin. Histograms for direction cosine difference used a bin width of 0.0005 to capture the small fluctuation behavior, while the electron/positron histograms used a bin width of 0.02 to reduce noise. Further, U\u2032\u2212U histograms were generated for every X bin, and V\u2032\u2212V histograms were generated for every Y bin, as fluctuation size was dependent on distance from the origin."
                            ],
                            "subsections": []
                        }
                    ]
                },
                {
                    "title": "Simulation For Independent Dose Verification",
                    "paragraphs": [
                        "This study is an extension of a previously\u2010established, cloud\u2010based tool for MC independent dose calculation. 27  In short, this tool uses a modified version of the PENELOPE MC software 28  to include a message\u2010passing\u2010interface for parallel computing. 29  Transport in the jaws and multi\u2010leaf collimators (MLC) were modeled using first\u2010order approximations following the Siebers\u2013Keall method. 30  Specifically, only attenuation and first Compton interactions were considered for primary photons, and only attenuation was considered for scattered photons. Clinical cases used in this study were delivered using a machine with the Varian Millennium 120 MLC, the leaf tips of which are rounded with an 11.3\u00b0 tip angle; however, within the MC framework, MLC leaf tips are modeled as simply rounded without the tip angle, as illustrated in Figure\u00a01.",
                        "To reduce the I/O stress from reading in the large PSF, the histograms for particle X and Y position, kinetic energy, and U and V direction cosines described above were converted into cumulative distribution functions (CDF). As a result, the reading of particle parameters from the PSF was replaced by inverse transform sampling from these CDF. The procedure for sampling particles is illustrated in a flow chart in Figure\u00a02 and is briefly explained here. First, seven random uniform numbers are generated (U0\u2026U6). Random numbers U0 and U1 are used to determine particle species and (if a photon is selected) primary/scatter classification, respectively. This information is used to determine from which inverse CDF to sample for the remaining particles. Random number U2 is used to sample particle X position, which is then used to determine from which Y position and U\u2032\u2212U CDF to sample. Random number U3 is used to sample particle Y position, which is then used to determine from which V\u2032\u2212V CDF to sample. Random numbers U4 and U5, in conjunction with particle X and Y position, are used to sample the U and V direction cosines, respectively. Lastly, random number U6, in conjunction with particle X and Y position, is used to sample particle kinetic energy. The set of particle species, position, kinetic energy, and direction is used in downstream analysis to transport through the jaws, MLC, and the patient volume.",
                        "Previously, the MC independent dose calculation tool read in the PSF directly and implemented a rotational augmentation to re\u2010use the particle to save I/O overhead. Each particle read was rotated by a random angle four times, which reduced uncertainty in the phase\u2010space surface by a factor of two at all points except near the central axis. With this new VSM, the rotational augmentation is no longer necessary and results in a uniform statistical uncertainty."
                    ],
                    "subsections": []
                },
                {
                    "title": "Vsm Validation Data",
                    "paragraphs": [
                        "Radiotherapy cases were collected from the clinical practice at the University of Kentucky Department of Radiation Medicine. The cases used for testing comprise patients treated at University of Kentucky between 2015 and 2021 using a Varian TrueBeam Linac. Radiotherapy plan data sets were generated using the Eclipse V15.6 (Varian Medical System, Palo Alto, CA 94304)\u00a0TPS. The imaging data sets for each patient were acquired using computed tomography (CT) systems (GE Healthcare, Waukesha, Wisconsin) with 120\u00a0kV tube voltage and 2\u20133\u00a0mm slice reconstruction under an in\u2010house imaging protocol. All data were anonymized to remove the protected health information of human subjects."
                    ],
                    "subsections": []
                },
                {
                    "title": "Vsm Validation",
                    "paragraphs": [
                        "The VSM approach was validated in three studies. First, particles were simulated using the VSM outside of the MC dose framework and transported to distances 0, 30, 50, 70, and 100\u00a0cm from the phase\u2010space surface. Global distributions of particle X and Y were generated for each transport distance. In addition, since particle U, V, and kinetic energy do not vary with transport distance, a single global distribution was generated for each. Similar distributions were generated for particles read from the PSF. The two distributions were compared using a \u03c72test for two histograms 31  at the phase\u2010space surface (Z\u00a0=\u00a026.7\u00a0cm) and at the isocenter (\u224870\u00a0cm transported from the phase\u2010space surface). A p\u2010value less than 0.05 indicates significant differences between the VSM and PSF histograms.",
                        "For the second study, five patient plans were selected for each beam configuration and were copied to a solid water phantom using a TPS for a total of 20 cases. The OCTAVIUS II (PTW, Frieburg, Germany) dose verification system was used. Patient plans were delivered to the water phantom, and measurements of the 2D coronal dose distribution were obtained. The same patient plans and phantom CT images were exported to our MC framework for second check simulation using a 3% statistical uncertainty using the VSM. The CT, TPS dose, and measured dose images are read in DICOM files. Prior to simulation, all dose grids are resampled to have the same grid size and resolution as the CT image. To conserve memory, all images are then downsized to a 256\u00a0\u00d7\u00a0256 axial grid. The MC dose is then calculated using the CT volume. This ensures that all comparisons between doses are using the same resolution. Two\u2010dimensional slices corresponding to the coronal measurement plane from the MC calculation were exported to the MapCheck software (SunNuclear), which performed a 2D gamma analysis using 3%/3\u00a0mm criteria. In both studies, a gamma index passing rate above 90% for voxels receiving greater than 10% of the prescription dose was considered passing in the comparison between the MC and measured doses, which follows the clinical quality assurance procedures at the University of Kentucky.",
                        "For the last study, five patient plans, from different patients from previous study, were selected for each beam configuration for a total of 20 test cases. Plans were exported to our MC framework for second check simulation using a 3% statistical uncertainty using both the PSF and VSM models. The CT, TPS dose, and measured dose images are read in DICOM files. Prior to simulation, all dose grids are resampled to have the same grid size and resolution as the CT image. To conserve memory, all images are then downsized to a 256\u00a0\u00d7\u00a0256 axial grid. The MC dose is then calculated using the CT volume. This ensures that all comparisons between doses are using the same resolution. VSM doses were compared against PSF doses through a 3D gamma analysis using 3%/3\u00a0mm criteria, which are common criteria used in clinical practice. 32 ,  33  Three dimensional gamma index passing rates were calculated using the \u201cgamma\u201d function from the python module PyMedPhys. 34  The computation time between the two MC methods was also assessed. Tests were run on a server with 64 gigabytes (GB) of random access memory (RAM) and a 2.3\u00a0GHz central processing unit (CPU). Files were read from an HDD with a buffered disk read rate of \u2248250\u00a0megabytes per second (MB/s) and a cached memory read rate of \u224810,000\u00a0MB/s. The speed of PSF calculations is highly dependent on whether files were read from the disk or were cached from a previous simulation using the same PSF. Calculations for each case were run five times to determine the mean computation time for both cached and non\u2010cached reads and illustrate best\u2010 and worst\u2010case scenarios, respectively. The same number of threads (12) was used in parallel computations for both the VSM and PSF calculations. In addition, the rotational augmentation in the old PSF implementation was removed to allow for a direct comparison between the two methods. Completion times for each case using the VSM method were compared against raw and cached PSF completion times over all cases using paired t\u2010tests. Here, a p\u2010value less than 0.05 indicates a significant difference in the mean computation time between approaches (VSM vs. raw PSF calculation time and VSM vs. cached PSF calculation time)."
                    ],
                    "subsections": []
                }
            ]
        },
        {
            "title": "Results And Discussion",
            "paragraphs": [],
            "subsections": [
                {
                    "title": "Vsm",
                    "paragraphs": [
                        "Using the information stored within the Varian PSF, VSMs were generated for four beam configurations. Inverse CDF were stored as binary files containing floating\u2010point precision lookup tables using probability bin widths of 0.00005. For each beam configuration, the collection of inverse CDF lookup tables uses \u223c67\u00a0MB of disk space, compared to \u223c50 GB for respective PSF. This \u223c1000 times reduction in disk space usage is well below the standard I/O disk read rates for HDD and SSD and significantly eases latency in MC calculations. Particles generated from these VSM are sampled in a field\u2010independent region and do not depend on the positions of the jaws and MLC leaves.",
                        "The greatest distinction between the VSMs outlined in this paper with other VSM in the literature is its binned approach to modeling PSF behavior. No fits are performed to the histograms that score particle behavior at the phase\u2010space surface, rather the histograms are used directly to sample particles for each MC simulation. Compared with most VSM that use functional approaches, 5 ,  6 ,  7 ,  8 ,  9 ,  10 ,  11 ,  12 ,  16 ,  18 ,  20  our VSM provide a simplified approach that is easy to implement and requires little tuning and commissioning; however, this approach is limited in that it is fully dependent on the results of full simulations of the treatment head. If the PSF resulting from the full simulation do not describe the treatment machine well, neither will our VSM, and new simulations will need to be performed or new PSF will need to be obtained from the IAEA or vendor. Further, we model our VSM using two sources for photons, whereas other VSM may use one 19 ,  20  or three sources. 21  Our dual\u2010source approach is a tradeoff between model complexity and accuracy that are observed in single\u2010source and triple\u2010source models, respectively."
                    ],
                    "subsections": []
                },
                {
                    "title": "Primary Photon Classification",
                    "paragraphs": [
                        "This method utilizes a dual\u2010source approach for modeling photons as either primary, resulting from the Bremsstrahlung radiation generated in the treatment head, or scattered, resulting from interactions in the collimator or in the flattening filter. The crossplane and inplane positions of photons reverse\u2010transported to the treatment head are illustrated in Figure\u00a03 for the 6X beam configuration. A prominent Gaussian peak is observed around X=Y=0. This behavior is observed for all beam energies. The PSF do not contain information on the origin of the photons, so we assume this Gaussian peak arises from the shape of the beam focal spot on the target. Therefore, to classify photons as either primary or scattered, Gaussian fits were performed to these central regions. A photon was classified as primary if its position at the treatment head was within a window of three standard deviations of the Gaussian peak (X=\u03bcx\u00b13\u03c3x and Y=\u03bcy\u00b13\u03c3y). All remaining photons were considered as scattered. Primary and scattered photons parameters were scored separately at the phase\u2010space surface. Following these criteria, the fraction of primary to scattered photons was also obtained. The results of the Gaussian fit parameters and primary photon fraction are shown in Table\u00a01."
                    ],
                    "subsections": []
                },
                {
                    "title": "Vsm Sampling Method Validation",
                    "paragraphs": [
                        "The VSMs were first validated by simulating 100 million particles and comparing the particle distributions at the phase\u2010space surface (Z=26.7\u00a0cm) and isocenter (Z=100\u00a0cm) from the VSM to the particle distributions read directly from the PSF at the same locations. These tests were run outside of the MC dose framework to independently verify the quality of the simulated particles. We chose to model particle X and Y position directly over particle R with a random azimuthal angle because we observed that the particle density at the phase\u2010space surface was square for all beam configurations. Sampling X and Y position using the radial position with a random azimuthal angle did not capture this behavior. The results of the particle distribution comparisons for each beam configuration are shown in Table\u00a02. Here, the p\u2010values for particle position at the phase\u2010space surface were larger than 0.05, but all other particle parameters had p\u2010values <2.2\u00d710\u221216, indicating significant deviations between the VSM and PSF distributions. Particle position and direction are illustrated in Figures\u00a04 and\u00a05 for the 10X and 10XFFF beam configurations, respectively, and particle energy density versus radial position is illustrated in Figure\u00a06 for the 6XFFF beam configuration. We performed an analysis of the residuals between the respective VSM and PSF histograms, as seen in Figures\u00a04, 5, 6, and found that the most significant deviations occurred at the tails of each distribution, or where the distribution is rapidly changing. These deviations, while small in magnitude (\u223c2%), were statistically significant. To find the regions, which were consistent between the two methods, we truncated each distribution and performed \u03c72 tests using the truncated distributions. The truncation points and fractional probability density remaining for each parameter are outlined in Table\u00a03. The results of the truncated histogram comparisons for each beam configuration are shown in Table\u00a04. Here, we see that for all particle parameters \u03c72 test p\u2010values are well above 0.05, indicating agreement between the VSM and PSF distributions.",
                        "Overall, we see excellent agreement between the VSM and PSF approaches in the central regions for each particle distribution (>90% of the probability density) and deviations toward the tails of each distribution. Despite their statistical significance, the magnitude of these deviations is small and will not have a significant effect on the final dose. Further, for particle position and direction, it is likely that the small fraction of particles sampled with these extreme values will be blocked by the Linac jaws and/or MLC, and deviations to the final dose will be negligible. Particle energy distributions agree for\u00a0>99% of the probability density and particles sampled with these extreme values will also have a negligible effect on the final dose. The results of the following studies will confirm these assertions."
                    ],
                    "subsections": []
                },
                {
                    "title": "Vsm Mc Dose Versus Measurement Validation",
                    "paragraphs": [
                        "With the quality of the simulated particles established, the VSM were then implemented into the MC dose framework to evaluate their performance against measurements in a water phantom. Five water phantom cases were used to validate each beam configuration for a total of 20 test cases. For each case, an MC dose was calculated using the VSM method and was compared to 2D measurements in a water phantom using a gamma index analysis (3%/3\u00a0mm). The gamma index passing rates between MC and measured doses, as well as between the TPS and measured dose, for each case are shown in Table\u00a05. Each case exhibited a gamma index pass rate\u00a0>97%, indicating excellent agreement between simulation and measurement. Further, The VSM MC dose performed similarly, and occasionally better, than the TPS dose to capture the measured dose for all cases. Sample reports comparing MC dose with measurements from the MapCheck software for each case are provided in the supplemental material."
                    ],
                    "subsections": []
                },
                {
                    "title": "Vsm Versus Psf Method Performance Comparison",
                    "paragraphs": [
                        "With the validity of the VSM established from water phantom measurements, studies were performed to compare the performance of the VSM method against the PSF method in speed and accuracy. Five clinical test cases were used to assess each beam configuration for a total of 20 test cases. For each case, an MC dose was calculated using both the VSM and the PSF methods, and doses were compared against each other using a 3D gamma index analysis (3%/3\u00a0mm). In addition, we performed timing tests to evaluate how the reduced file size of the VSM improved simulation time. The results of these studies are shown in Table\u00a06. Here, it is seen there is a dramatic decrease in computation time for the VSM compared to the raw PSF reads, which were on average \u223c14 times faster than the raw PSF reads, (mean time difference \u0394t=\u22121534 s, p<2.2\u00d710\u221216). Compared to cached memory reads of the PSF, the computation time of the VSM was \u223c1.9 times slower (mean time difference \u0394t=57 s, p<2.2\u00d710\u221216). This result is not unexpected, as in this situation, the overhead from repeatedly sampling particle parameters is competing with the immense speed of cached memory reads. Further, the fully cached scenario will be extremely improbable in practice, given the large PSF size and other processes sharing resources on the machine. Future studies will be directed toward further optimizing the sampling process.",
                        "A visual comparison between MC doses obtained using the VSM and PSF implementations for the 6X beam configuration (\u201cclinical 6X\u20103\u2033 in Table\u00a06) is shown in Figure\u00a07 for a clinical test case. One dimensional normalized dose profiles along the beam axis were generated for each case as well, an example of which is shown in Figure\u00a08 for the same 6X clinical test case as in Figure\u00a07. As expected, the MC doses calculated using the VSM and PSF implementations are very similar. Gamma index passing rates were used to quantify deviations between the two methods and were\u00a0>90% for all cases, which indicates excellent agreement between the two methods. In addition, we performed an analysis of the residuals between the respective VSM and PSF doses, as seen in the fourth column of Figure\u00a07. For cases with gamma index passing rates closer to 90%, we found that the largest discrepancies occurred near the edges of the dose distributions and near sharp changes in the dose distributions. For specific cases, discrepancies also occurred in very low\u2010density regions (e.g., lungs or airways). We believe that the discrepancies near the dose distribution edges arise from the oversimplification of the MLC leaf tips in our MC framework. 27  Further, the discrepancies at sharp changes in the dose distributions could arise from how we model primary and scattered photons. It should be noted that there are still some primary photons outside the 3\u03c3 window at the treatment head (although\u00a0<0.3%), and there are some scattered photons within the 3\u03c3 window (<2% based on the fits shown in Figure\u00a03). The model can be tuned by choosing a different window (e.g., 2.5\u03c3), but we have found that 3\u03c3 window produced the best results. Future studies will be directed toward improving the primary photon classification of our VSM. MC dose distributions overlaid with patient CT, and 1D dose profiles for all clinical test cases are available in the supplemental materials."
                    ],
                    "subsections": []
                }
            ]
        },
        {
            "title": "Conclusions",
            "paragraphs": [
                "We have developed a new method for deriving VSM from IAEA PSF for Varian TrueBeam Linacs. This method is easy to implement and replace preexisting code that utilizes PSF. Extensive validation shows that the VSM sampling method, and the MC doses that arise from sampled particles, is robust and provides significant savings in both disk space usage and computation time without loss of quality results. Future studies will be directed toward further optimizing the sampling method and extending the method to more treatment machines, like Elekta (Elekta AB, Stockholm, Sweden) Linacs and Varian Halcyon."
            ],
            "subsections": []
        },
        {
            "title": "Conflict Of Interest",
            "paragraphs": [
                "James R. Castle and Xue Feng are employed by Carina Medical LLC. Quan Chen is a shareholder of Carina Medical LLC."
            ],
            "subsections": []
        },
        {
            "title": "Author Contributions",
            "paragraphs": [
                "Xue Feng directed the study. Quan Chen provided water phantom and clinical test cases. Jingwei Duan and Quan Chen performed gamma index analyses and measurements for water phantom test cases. Quan Chen, Xue Feng, and James R. Castle developed and refined the MC dose calculation framework. James R. Castle developed, validated, and implemented the virtual source model. Xue Feng, Quan Chen, and Jingwei Duan provided valuable insight, interpretations, and advice. James R. Castle wrote the manuscript with inputs from the other authors. All authors read and approved the final manuscript."
            ],
            "subsections": []
        }
    ]
}