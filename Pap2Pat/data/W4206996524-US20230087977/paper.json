{
    "id": "https://semopenalex.org/work/W4206996524",
    "authors": [
        "Yong Fan",
        "Hongming Li"
    ],
    "title": "MDReg\u2010Net: Multi\u2010resolution diffeomorphic image registration using fully convolutional networks with deep self\u2010supervision",
    "date": "2022-01-24",
    "abstract": "We present a diffeomorphic image registration algorithm to learn spatial transformations between pairs of images to be registered using fully convolutional networks (FCNs) under a self-supervised learning setting. Particularly, a deep neural network is trained to estimate diffeomorphic spatial transformations between pairs of images by maximizing an image-wise similarity metric between fixed and warped moving images, similar to those adopted in conventional image registration algorithms. The network is implemented in a multi-resolution image registration framework to optimize and learn spatial transformations at different image resolutions jointly and incrementally with deep self-supervision in order to better handle large deformation between images. A spatial Gaussian smoothing kernel is integrated with the FCNs to yield sufficiently smooth deformation fields for diffeomorphic image registration. The spatial transformations learned at coarser resolutions are utilized to warp the moving image, which is subsequently used as input to the network for learning incremental transformations at finer resolutions. This procedure proceeds recursively to the full image resolution and the accumulated transformations serve as the final transformation to warp the moving image at the finest resolution. Experimental results for registering high-resolution 3D structural brain magnetic resonance (MR) images have demonstrated that image registration networks trained by our method obtain robust, diffeomorphic image registration results within seconds with improved accuracy compared with state-of-the-art image registration algorithms.",
    "sections": [
        {
            "title": "Introduction",
            "paragraphs": [
                "Medical image registration plays an important role in many medical image analysis tasks (Sotiras, Davatzikos, & Paragios,\u00a02013; Viergever et al.,\u00a02016). To solve the medical image registration problem, the most commonly used strategy is to seek a spatial transformation that establishes pixel/voxel correspondence between a pair of fixed and moving images in an optimization framework, by maximizing a surrogate measure of the spatial correspondence between images, such as image intensity correlation between the images to be registered (Ashburner,\u00a02007; Avants et al.,\u00a02011; Fan, Jiang, & Evans,\u00a02002; S. Klein, Staring, Murphy, Viergever, & Pluim,\u00a02010; Rueckert et al.,\u00a01999). Conventional medical image registration algorithms typically solve the image registration optimization problem using iterative optimization algorithms, making the medical image registration computationally expensive and time\u2010consuming.",
                "Recent medical image registration studies have leveraged deep learning techniques to improve the computational efficiency of conventional medical image registration algorithms, in addition to learning image features for the image registration using stacked autoencoders (Wu, Kim, Wang, Munsell, & Shen,\u00a02016). In particular, deep learning techniques have been used to build prediction models of spatial transformations for achieving image registration under a supervised learning framework (Krebs et al.,\u00a02017; Roh\u00e9, Datar, Heimann, Sermesant, & Pennec,\u00a02017; Sokooti et al.,\u00a02017; Yang, Kwitt, Styner, & Niethammer,\u00a02017). Different from the conventional image registration algorithms, the deep learning\u2010based image registration algorithms formulate the image registration as a multi\u2010output regression problem (Krebs et al.,\u00a02017; Roh\u00e9 et al.,\u00a02017; Sokooti et al.,\u00a02017; Yang et al.,\u00a02017). They are designed to predict a spatial relationship between image pixel/voxels from a pair of images based on their image patches. The learned prediction model can then be applied to images pixel/voxel\u2010wisely to achieve the image registration.",
                "The prediction\u2010based image registration algorithms typically adopt convolutional neural networks (CNNs) to learn informative image features and a mapping between the learned image features and spatial transformations that register images in a training dataset, consisting of deformation fields and images that can be registered by the deformation fields (Krebs et al.,\u00a02017; Roh\u00e9 et al.,\u00a02017; Sokooti et al.,\u00a02017; Yang et al.,\u00a02017). Similar to most deep learning tasks, the quality of training data plays an important role in the prediction\u2010based image registration, and a variety of strategies have been proposed to build training data, specifically the spatial transformations that register images in a training dataset (Krebs et al.,\u00a02017; Roh\u00e9 et al.,\u00a02017; Sokooti et al.,\u00a02017; Yang et al.,\u00a02017). Particularly, synthetic deformation fields can be simulated and applied to a set of images to generate new images so that the synthetic deformation fields can be used as training data to build a prediction model (Sokooti et al.,\u00a02017). However, the synthetic deformation fields may not effectively capture spatial correspondences between real images. Spatial transformations that register pairs of images can also be estimated using conventional image registration algorithms (Krebs et al.,\u00a02017; Yang et al.,\u00a02017). However, a prediction\u2010based image registration model built upon such a training dataset is limited to estimating spatial transformations captured by the adopted conventional image registration algorithms. The estimation of spatial transformations that register pairs of images can also be guided by shape matching (Roh\u00e9 et al.,\u00a02017). However, a large dataset of medical images with manual segmentation labels is often not available for training an image registration model.",
                "The training data scarcity problem in deep learning\u2010based image registration could be overcome using unsupervised or self\u2010supervised learning techniques. A variety of deep learning algorithms have adopted deep CNNs, in conjunction with spatial transformer network (STN; Jaderberg, Simonyan, & Zisserman,\u00a02015), to learn prediction models for image registration of pairs of fixed and moving images in an unsupervised learning fashion (A. V. Dalca, Balakrishnan, Guttag, & Sabuncu,\u00a02019; de Vos et al.,\u00a02019; Eppenhof, Lafarge, Veta, & Pluim,\u00a02019; Hering, van Ginneken, & Heldmann,\u00a02019; Kim et al.,\u00a02019; Krebs, Delingette, Mailh\u00e9, Ayache, & Mansi,\u00a02019; Kuang & Schmah,\u00a02019; Lei et al.,\u00a02020; Li & Fan,\u00a02017, 2018; Liu, Hu, Zhu, & Heng,\u00a02019; Mansilla, Milone, & Ferrante,\u00a02020; T. C. Mok & Chung,\u00a02020a, 2020b; Yoo, Hildebrand, Tobin, Lee, & Jeong,\u00a02017; Yu et al.,\u00a02020; Zhang, Liu, Zheng, & Shi,\u00a02020; Zhao, Lau, Luo, Chang, & Xu,\u00a02019). Particularly, fully convolutional networks (FCNs) that facilitate voxel\u2010to\u2010voxel learning (Long, Shelhamer, & Darrell,\u00a02015) are adopted to predict the deformation field (A. V. Dalca et al.,\u00a02019; Kim et al.,\u00a02019; Kuang & Schmah,\u00a02019; Li & Fan,\u00a02017, 2018; Mansilla et al.,\u00a02020; Yoo et al.,\u00a02017; Zhao et al.,\u00a02019) using moving and fixed images as the input to deep learning networks. The optimization of the image registration networks is driven by image similarity measures between the fixed image and the warped moving image based on either image intensity (A. V. Dalca et al.,\u00a02019; Kim et al.,\u00a02019; Kuang & Schmah,\u00a02019; Li & Fan,\u00a02017, 2018; Mansilla et al.,\u00a02020; Zhao et al.,\u00a02019) or contextual features (Yoo et al.,\u00a02017). The deformation field can be modeled by sufficiently smooth velocity fields to facilitate diffeomorphic image registration (Ashburner,\u00a02007; Avants et al.,\u00a02011), and such a strategy has been adopted in deep learning\u2010based image registration methods to favor diffeomorphic properties of the transformation including preservation of topology and invertible mapping (A. V. Dalca et al.,\u00a02019; T. C. Mok & Chung,\u00a02020a; Zhang et al.,\u00a02020). Although physically plausible deformation and promising accuracy has been obtained, these registration methods are carried out at a single spatial scale and might be trapped by local optima, especially when registering images with large anatomical variability. Inspired by conventional image registration methods, multi\u2010stage and multi\u2010resolution registration techniques are incorporated into deep learning\u2010based registration methods using cascaded networks (de Vos et al.,\u00a02019; Hering et al.,\u00a02019; Kim et al.,\u00a02019; Zhao et al.,\u00a02019) and deep supervision (Eppenhof et al.,\u00a02019; Hering et al.,\u00a02019; Krebs et al.,\u00a02019; Lei et al.,\u00a02020; Liu et al.,\u00a02019), yielding improved performance compared with one\u2010stage or single\u2010scale image registration. However, they are not equipped to achieve diffeomorphic registration. A deep Laplacian pyramid image registration network (T. C. Mok & Chung,\u00a02020b) has been recently proposed for diffeomorphic image registration in a multi\u2010resolution manner, demonstrating promising image registration performance.",
                "In this study, we propose an end\u2010to\u2010end learning framework to optimize and learn diffeomorphic spatial transformations between pairs of images to be registered in a multi\u2010resolution diffeomorphic image registration framework, referred to as MDReg\u2010Net. In particular, our method trains FCNs to estimate voxel\u2010to\u2010voxel velocity fields of spatial transformations for registering images by maximizing their image\u2010wise similarity metric, similar to conventional image registration algorithms. To account for potential large deformations between images, a multi\u2010resolution strategy is adopted to jointly optimize and learn vocity fields for spatial transformations at different spatial resolutions progressively in an end\u2010to\u2010end learning framework. The velocity fields estimated at lower resolutions are used to warp the moving image and the warped moving image is used as the input to the subsequent sub\u2010network to estimate the residual velocity fields for spatial transformations at higher resolutions. The image similarity measures between the fixed and warped moving images are evaluated at different image resolutions to serve as deep self\u2010supervision so that FCNs at different spatial resolutions are jointly learned. A spatial Gaussian smoothing kernel is integrated with the FCNs to yield sufficiently smooth deformation fields to achieve diffeomorphic image registration. Our method has been evaluated based on 3D structural brain magnetic resonance (MR) images and obtained diffeomorphic image registration with better performance than state\u2010of\u2010the\u2010art image registration algorithms."
            ],
            "subsections": []
        },
        {
            "title": "Methods",
            "paragraphs": [],
            "subsections": [
                {
                    "title": "Image Registration By Optimizing An Image Similarity Metric",
                    "paragraphs": [
                        "Given a pair of fixed image If and moving image Im, the task of image registration is to seek a spatial transformation that establishes pixel/voxel\u2010wise spatial correspondence between the two images. The spatial correspondence can be gauged with a surrogate measure, such as an image intensity similarity measure between the fixed and transformed moving images, and therefore the image registration problem can be solved in an optimization framework by optimizing a spatial transformation that maximizes the image similarity measure between the fixed image and transformed moving image. For nonrigid image registration, the spatial transformation is often characterized by a dense deformation field D that encodes displacement vectors between spatial coordinates of If and their counterparts in Im. For mono\u2010modality image registration, mean squared intensity difference and normalized correlation coefficient (NCC) are often adopted as the surrogate measures of image similarity.",
                        "As the image registration problem is an ill\u2010posed problem, regularization techniques are usually adopted in image registration algorithms to obtain a spatially smooth and physically plausible deformation field (Sotiras et al.,\u00a02013; Viergever et al.,\u00a02016). In general, the optimization\u2010based image registration problem is formulated as \\[\\min\\limits_{D} - S\\left( {{I_{f}(x)},{I_{m}\\left( {D \\circ x} \\right)}} \\right) + \\mathit{\\lambda R}(D),\\] where D is the deformation field to be optimized, x represents spatial coordinates of pixel/voxels in If, D\u2218x represents deformed spatial coordinates of pixel/voxels by D in Im, SI1I2 is an image similarity measure, RD is a regularizer on the deformation field, and \u03bb controls the trade\u2010off between the image similarity measure and the regularization on the deformation field.",
                        "The regularization is typically adopted to encourage the deformation field to be spatially smooth by minimizing magnitude of derivatives of the spatial transformation, such as square L2\u2010norm, total variation, and learning\u2010based regularizer (Niethammer, Kwitt, & Vialard,\u00a02019; Vishnevskiy, Gass, Szekely, Tanner, & Goksel,\u00a02017). To facilitate diffeomorphic image registration, the deformation field can be represented by integration of velocity fields v, that is, D=\u03a6v (Ashburner,\u00a02007; Avants et al.,\u00a02011), and the regularization is directly applied to the velocity fields to obtain spatially smooth velocity fields and diffeomorphic deformation fields accordingly.",
                        "The image registration optimization problem can be solved by gradient descent based methods (Sotiras et al.,\u00a02013; Viergever et al.,\u00a02016). However, such an optimization\u2010based image registration task is typically computational expensive and time consuming. Instead of optimizing D directly, the deformation field can be predicted using FCNs under an unsupervised setting (Li & Fan,\u00a02017, 2018). However, the estimated deformation field may not be fold\u2010free or invertible even a large smooth regularization term is adopted (A. V. Dalca et al.,\u00a02019; T. C. Mok & Chung,\u00a02020a; Zhang et al.,\u00a02020)."
                    ],
                    "subsections": []
                },
                {
                    "title": "Multi\u2010Resolution Diffeomorphic Image Registration With Deep Self\u2010Supervision",
                    "paragraphs": [
                        "We adopt a multi\u2010resolution image registration procedure to estimate the velocity and deformation fields progressively from coarse to fine spatial resolutions for its effectiveness for handling large deformation between images, as demonstrated in conventional image registration algorithms (Sotiras et al.,\u00a02013; Viergever et al.,\u00a02016). The overall framework of our multi\u2010resolution image registration method is illustrated in Figure\u00a01a, with three different resolutions involved. Particularly, the velocity fields are estimated incrementally from coarse to fine resolutions with L levels (l=1 and l=L refer to the coarsest and finest spatial resolutions, respectively), which are optimized jointly and formulated as \\[\\min\\limits_{v^{l}}\\sum\\limits_{l = 1}^{L} - S\\left( {{I_{f}^{l}(x)},{I_{m}^{l}\\left( {\\Phi\\left( {\\overset{\\sim}{v}}^{l} \\right) \\circ x} \\right)}} \\right) + \\mathit{\\lambda R}\\left( v^{l} \\right),\\] where Ifl and Iml denote fixed and moving images at resolution level l, vl is the incremental velocity fields at level l, and v~l is the accumulated velocity fields of the deformation field at level l, computed as \\[{\\overset{\\sim}{v}}^{l} = \\sum\\limits_{i = 1}^{l}v^{i}\\ \\text{if}\\ l > 1\\ \\text{and}\\ {\\overset{\\sim}{v}}^{1} = v^{1}.\\] For the deformation field \u03a6v1 at the coarsest resolution (l=1), a sub\u2010network S1 with a U\u2010Net (Ronneberger, Fischer, & Brox,\u00a02015) architecture is utilized to estimate velocity fields v1 and a moving image to be registered to a fixed image are concatenated with the fixed image as a two\u2010channel input to sub\u2010network S1. For the deformation field at a finer resolution (l>1), a dedicated sub\u2010network Sl is adopted to estimate the velocity field increment vl using a concatenation of the warped moving image and the fixed image as an input to the sub\u2010network. Particularly, the moving image is warped by the deformation field \u03a6v~l obtained at its coarser resolution. The sub\u2010network Sl is optimized to learn the deformation field that captures the residual variation between the warped moving image and the fixed image after deformation at all preceding coarser resolutions. Finally, the accumulated velocity fields v~L over all the resolutions are utilized to obtain the deformation field at the finest resolution.",
                        "Similar to the conventional multi\u2010resolution image registration algorithms, the similarity of registered images at different resolutions is maximized in our network to serve as deep supervision (Chen\u2010Yu, Saining, Patrick, Zhengyou, & Zhuowen,\u00a02014), but without relying on any supervised information of the deformation fields. Such a supervised learning with surrogate supervised information is referred to as self\u2010supervision in this study. As it is capable of obtaining both deformation and inverse deformation fields for the moving and fixed images from the velocity fields under the diffeomorphic image registration setting, our multi\u2010resolution image registration model is formulated to optimize both the deformation and inverse deformation fields jointly \\[\\min\\limits_{v^{l}}\\sum\\limits_{l = 1}^{L} - S\\left( {{I_{f}^{l}(x)},{I_{m}^{l}\\left( {\\Phi\\left( {\\overset{\\sim}{v}}^{l} \\right) \\circ x} \\right)}} \\right) - S\\left( {{I_{m}^{l}(x)},{I_{f}^{l}\\left( {\\Phi^{-}\\left( {\\overset{\\sim}{v}}^{l} \\right) \\circ x} \\right)}} \\right) + \\mathit{\\lambda R}\\left( v^{l} \\right),\\] where normalized cross\u2010correlation (NCC) is adopted as the image similarity measure SIfIm, Rv=\u2211n=1N\u2207vn1, N is the number of pixel/voxels in the velocity field, and \u03bb is the hyper\u2010parameter to balance the image similarity and deformation regularization terms.",
                        "Different from conventional multi\u2010resolution image registration algorithms that perform multi\u2010stage optimization with their deformation fields at coarse resolutions used as initialization inputs to the image registration at a finer resolution, our deep learning\u2010based method jointly optimizes deformation fields at all spatial resolutions with an end\u2010to\u2010end deep learning setting. As the optimization of the loss function proceeds, the parameters within the network will be updated through the feedforward computation and backpropagation procedure, leading to improved prediction of deformation fields."
                    ],
                    "subsections": []
                },
                {
                    "title": "Network Architecture For Estimating The Velocity Fields",
                    "paragraphs": [
                        "In our multi\u2010resolution image registration network, one dedicated sub\u2010network is designed to estimate the velocity fields or the velocity field increment at each spatial resolution. The sub\u2010network at the coarsest spatial resolution is optimized to learn the velocity fields to capture large deformation, while the sub\u2010networks at finer resolutions are optimized to learn residual deformation to achieve an accurate image registration.",
                        "In this study, stationary velocity fields (SVFs) v are adopted to represent the deformation field as \\[\\frac{\\partial D^{(t)}}{\\partial t} = v\\ \\left( D^{(t)} \\right),\\] where D is the deformation field, D0=Id is the identity transformation, and t=0,1 is time. The integration of SVFs \u03a6v using scaling and squaring method (Ashburner,\u00a02007; A. V. Dalca et al.,\u00a02019) is adopted to compute the deformation field D numerically. Particularly, the sub\u2010network used at each resolution in our study is specified as one U\u2010Net with both encoder and decoder paths, as illustrated in Figure\u00a01b. The encoder path of all the sub\u2010networks share the same structure, consisting of one convolutional layer with 16 filters, followed by three convolutional layers with 32 filters, and all have a stride of 2. The decoder path of the sub\u2010networks from coarse to fine resolutions has one, two, and three deconvolutional layers, each with 32 filters and a stride of 2, followed by two convolution layers with 32 and 16 filters, respectively, and one output convolutional layer to predict the SVFs at three different spatial resolutions. For a particular sub\u2010net, the predicted SVF is integrated using the scaling and squaring operation to obtain the deformation field at different spatial resolutions. LeakyReLu activation is used for all the convolutional and deconvolutional layers except the output layer. The number of output channels d is 3, corresponding to the spatial dimensionality of the input images. The kernel size in all layers are set to 3\u00d73\u00d73. The multi\u2010resolution images used for computing the image similarity in the loss function at different resolutions are obtained using average pooling. Specifically, the original image serves as the image at the finest (full) resolution, and images at reduced resolutions are obtained by applying average pooling to the original image recursively with a kernel size of 3\u00d73\u00d73 and a stride of 2.",
                        "In the present study, SVFs are learned at 18, 14, and 12 resolutions to reduce the computational memory consumption, and the SVFs at the full resolution are obtained from the output of the 12 resolution using linear interpolation. The deformation field is computed from the SVFs with the number of time steps set to 7 (A. V. Dalca et al.,\u00a02019). A spatial smoothing layer, implemented as Gaussian kernel smoothing, is adopted as part of our deep learning network to smooth the deformation fields at the finest resolution in the end\u2010to\u2010end learning framework as illustrated in Figure\u00a01a. The integration of the spatial smoothing in our deep learning model facilitates the interaction between the learning of deformation fields and spatial smoothing to favor the diffeomorphic image registration. The spatial smoothing operation is applied to the deformation field at the finest resolution, as used in ANTs (Avants et al.,\u00a02011).",
                        "Our image registration model is implemented using Tensorflow (Abadi et al.,\u00a02016). Adam optimization technique (Kingma & Ba,\u00a02014) is adopted to train the networks. Once the training procedure is finished, the trained network can be directly used to register new images with feedforward computation."
                    ],
                    "subsections": []
                }
            ]
        },
        {
            "title": "Evaluation And Experimental Settings",
            "paragraphs": [],
            "subsections": [
                {
                    "title": "Image Datasets",
                    "paragraphs": [
                        "We evaluated our method based on two public brain imaging datasets with manual segmentations of fine\u2010grained brain structures, including (a) MICCAI 2012 Multi\u2010Atlas Labelling Challenge (MALC) dataset consisting of T1 brain MR images from 30 subjects with fine\u2010grained whole\u2010brain annotation for 134 structures (Landman & Warfield,\u00a02012), and (b) Mindboggle\u2010101 dataset consisting of T1 brain MR images from 101 healthy subjects with 50 manual annotated cortical structures (A. Klein & Tourville,\u00a02012). These images were used for testing only.",
                        "T1 brain MR images of 901 young subjects from PING dataset (Jernigan et al.,\u00a02016) were adopted to train our image registration model. Particular, images of 801 subjects were used for training, and images of the remaining 100 subjects were used for tuning the hyper\u2010parameter \u03bb. In addition, T1 brain MR images of 809 old subjects from ADNI 1 cohort (http://adni.loni.usc.edu) were adopted for training a second image registration model from scratch to investigate the influences of different training data to the image registration performance. It is worth noting that our training and testing datasets were obtained from different cohorts and sites to evaluate our method's generalization performance.",
                        "All the images for model training and testing were preprocessed using FreeSurfer (Fischl,\u00a02012), including skull\u2010stripping, intensity normalization and spatial alignment using affine registration. All the images were resampled with a spatial resolution of 1\u00d71\u00d71 mm3 and cropped with a size of 176\u00d7192\u00d7176. Segmentation labels with 30 brain structures were also obtained using FreeSurfer for each subject from PING dataset, which were adopted to tune the hyper\u2010parameter \u03bb."
                    ],
                    "subsections": []
                },
                {
                    "title": "Evaluation Metrics",
                    "paragraphs": [
                        "As it is nontrivial to obtain the ground truth deformation between any pair of images, we adopted the similarity of the anatomical segmentations of the fixed image and warped moving image as a surrogate metric of registration accuracy (Rohlfing,\u00a02011). Particularly, the trained registration model was applied to register all the testing images to one random selected template image, and the generated deformation fields were used to warp their corresponding segmentation labels. Dice score between the warped segmentation and the template segmentation images was used to evaluate the registration performance. Although Dice score between anatomical structures is a reliable surrogate measure to quantify image registration accuracy, higher Dice score alone does not necessarily mean biologically plausible image registration as a deformation field with folding voxels could also lead to image registration with high regional Dice score. Therefore, we also evaluated the diffeomorphic property of the obtained deformation in addition to Dice score. Particularly, we calculated the Jacobian determinant J\u03a6 of the deformation field \u03a6 obtained and counted all the voxels v whose J\u03a6v is non\u2010positive within the brain region. We have also evaluated the registration performance on images registered with the deformation fields computed in the opposite direction, that is, registering fixed images to moving images, based on the same velocity fields."
                    ],
                    "subsections": []
                },
                {
                    "title": "Network Training",
                    "paragraphs": [
                        "We trained pairwise registration models by randomly selecting one pair of images as the input to the network. Given a set of n images, we obtained n2 pairs of fixed and moving images, including pairs of the same images, such that every image can serve as the fixed image.",
                        "The learning rate was set to 0.0001 and batch size was set to 1. The networks were trained on one NVIDIA TITAN Xp GPU, and 150,000 iterations were adopted for the training. We have trained our registration model with different hyper\u2010parameter \u03bb values (\u03bb\u22080.1,0.2,0.35,0.5,0.75,1) using the PING training dataset and selected the \u03bb values that obtained the highest Dice score on the PING validation dataset using the FreeSurfer segmentation labels while no voxels with non\u2010positive J\u03a6v existed in the obtained deformation fields. For the Gaussian kernel smoothing, the \u03c3 of the Gaussian kernel was set to 1.732 voxels and the kernel size was set to 3\u00d73\u00d73, according to the default value used in ANTs (Avants et al.,\u00a02011)."
                    ],
                    "subsections": []
                },
                {
                    "title": "Comparison With State\u2010Of\u2010The\u2010Art Image Registration Algorithms And Ablation Studies",
                    "paragraphs": [
                        "We compared our method with representative medical image registration algorithms, including NiftyReg (Modat et al.,\u00a02010), ANTs (Avants et al.,\u00a02011), VoxelMorph (Adrian V Dalca, Balakrishnan, Guttag, & Sabuncu,\u00a02018), ProbMultilayer network (Liu et al.,\u00a02019), and LapIRN (T. C. Mok & Chung,\u00a02020b), based on the two testing datasets. Particularly, the default setting of NiftyReg was adopted. For ANTs based image registration, two configurations with different spatial smoothing regularization parameters were adopted with following command: ANTS 3 \u2010m CC[fixed,moving,1,2] \u2010t SyN[0.25] \u2010r Gauss[9,0.2] (or \u2010r Gauss[3,1.0]) \u2010o output \u2010i 201x201x201 \u2010\u2010number\u2010of\u2010affine\u2010iterations 100x100x100 \u2010\u2010use\u2010Histogram\u2010Matching 0. The configuration with the small smoothing size is referred to as ANTs\u2010c1, and the one with the larger smoothing size is referred to as ANTs\u2010c2. For the VoxelMorph model, bi\u2010directional image similarity based loss was adopted, and the number of time steps was set to 7 for computing the deformation field from the velocity field. The VoxelMorph model shared the same training strategy and setting as the proposed method, and its hyper\u2010parameters were also optimized to obtain the highest Dice scores based on the PING validation dataset. For the ProbMultilayer model and LapIRN model, the default setting was adopted, and they shared the same training strategy as the proposed method.",
                        "The comparison with VoxelMorph serves as an ablation study to evaluate if the multi\u2010resolution strategy could improve the image registration. As an additional ablation study, we also investigated the performance of our method without the spatial smoothing layer by optimizing \u03bb to obtain the diffeomorphic image registration on the PING validation dataset."
                    ],
                    "subsections": []
                }
            ]
        },
        {
            "title": "Experimental Results",
            "paragraphs": [],
            "subsections": [
                {
                    "title": "Optimal Parameter Setting",
                    "paragraphs": [
                        "Figure\u00a02 shows the average Dice score and number of voxels with non\u2010positive J\u03a6v in the obtained deformation fields for the PING validation dataset with different values of hyper\u2010parameter \u03bb. It can be observed that the Dice scores reached the maximum when \u03bb was around 0.35, while all the voxels had positive J\u03a6v in the obtained deformation fields when \u03bb was equal to or larger than 0.35. We adopted the registration model with \u03bb=0.35 for all the following evaluation unless specified otherwise."
                    ],
                    "subsections": []
                },
                {
                    "title": "Quantitative Performance Of Image Registration Algorithms Under Comparison",
                    "paragraphs": [
                        "The average Dice scores calculated over all anatomical structures and subjects obtained by different registration methods for two testing datasets are summarized in Table\u00a01. All the deformable registration methods obtained significantly higher Dice scores than the affine image registration (p<4\u00d710\u22127, Wilcoxon signed rank test), and our method obtained deformation fields with the minimal number of voxels with non\u2010positive Jacobian determinant among all the methods under comparison. Our method also obtained Dice scores close to those obtained by ANTs\u2010c1 and both of them ranked top in the deformable registration methods under comparison. Figures\u00a03 and 4 show Dice scores of individual anatomical structures of MALC and Mindboggle\u2010101 datasets respectively, where the structures are presented in ascending order by their volumetric sizes (from small to large regions), and the Dice scores of the same anatomical structure from left and right brain hemispheres are combined. Our method was comparable to ANTs\u2010c1 in terms of Dice score for most structures and outperformed the VoxelMorph, LapIRN, and ProbMultilayer model for most structures across both data sets with either coarse\u2010grained (Mindboggle\u2010101 dataset) or fine\u2010grained (MALC dataset) structures. Example images before and after the image registration by different methods and their corresponding anatomical segmentations on two testing datasets are demonstrated in Figures\u00a05a,b and 6a,b.",
                        "Example deformation fields and their corresponding Jacobian determinant maps for each dataset obtained by ANTs\u2010c1, VoxelMorph, LapIRN, ProbMultilayer, and our method are shown in Figures\u00a05c,d and 6c,d, respectively. While there were several localized clusters of voxels with non\u2010positive Jacobian determinant in the deformation fields obtained by ANTs\u2010c1 and LapIRN, nearly all voxels in the deformation fields obtained by VoxelMorph, ProbMultilayer, and our method were with positive Jacobian determinant, preserving good diffeomorphic property. As shown in Table\u00a01, the average number of voxels with non\u2010positive Jacobian determinant in the deformation fields obtained by our method (~0.1) was substantially smaller than those obtained by all other methods under comparison, including ANTs\u2010c1 (~9,000), LapIRN (~3,000), VoxelMorph (~5), and ProbMultilayer (~0.4). These results indicate that incorporating the spatial smoothing layer in our method largely eliminated folding voxels in the deformation fields without sacrificing registration accuracy. Although the folding voxels in the deformation fields obtained by ANTs could be eliminated by increasing the spatial smoothing during the registration, over\u2010smoothing inevitably leads to degraded registration accuracy. As summarized in Table\u00a01, ANTs\u2010c2 obtained image registration with a much smaller number of folding voxels compared with that obtained by ANTs\u2010c1, but its Dice score decreased dramatically.",
                        "The average time used to register one pair of images by different registration methods are presented in Table\u00a02. Our method, ProbMultilayer, and VoxelMorph took about 4.67, 4.29, and 3.82\u00a0s respectively when run on an NIVIDIA TITAN Xp GPU, and LapIRN took about 6.46\u00a0s when run on an NVIDIA TITAN RTX GPU, much faster than NiftyReg and ANTs which took about 257 and 1,071\u00a0s on average when run on an Intel Xeon E5\u20102660 CPU. On CPUs, our method took about 74.07\u00a0s to register one pair of images, faster than NiftyReg and ANTs.",
                        "As a deep learning\u2010based image registration model, the performance of the proposed method might be affected by the datasets used for training the image registration model due to the anatomical variations in different datasets. Therefore, we further trained image registration models using the proposed method, VoxelMorph, LapIRN, and ProbMultilayer on an image dataset from ADNI 1 cohort with the same training procedure as described previously and evaluated their performance on the two testing datasets. As summarized in Table\u00a01, the image registration models trained on different datasets by our method had more stable and better image registration performance than those trained by VoxelMorph, LapIRN, and ProbMultilayer, demonstrating that our method is robust and capable of learning anatomical variations from different images.",
                        "Without the spatial smoothing layer, larger regularization parameter \u03bb was required to achieve diffeomorphic image registration. We trained image registration models without the spatial smoothing layer with different \u03bb values on the PING training dataset to identify \u03bb value capable of generating deformation fields free of voxels with non\u2010positive Jacobian determinant on the PING validation dataset. As shown in Figure\u00a07a, \u03bb=1.0 produced an image registration model that registered the images of the PING validation dataset without any folding voxels, while \u03bb=0.5 produced an image registration model that registered the images of the PING validation dataset with the maximal Dice score that was estimated based on the brain structures labeled by FreeSurfer. Figure\u00a07b shows numbers of voxels with non\u2010positive Jacobian determinant of the ADNI1 images that were registered by the image registration models trained on the PING dataset with and without the spatial smoothing layer, respectively. Specifically, the average number of voxels with non\u2010positive Jacobian determinant in the deformation fields obtained by MDReg\u2010Net with the spatial smoothing layer was significantly less than that obtained by MDReg\u2010Net without the spatial smoothing layer though a larger regularization parameter was used (p=3.59\u00d710\u22127, Wilcoxon signed rank test). At the subject level, the deformation fields of 31 out of 809 images obtained by MDReg\u2010Net with the spatial smoothing layer contained voxels with non\u2010positive Jacobian determinant, while 88 had deformation fields containing voxels with non\u2010positive Jacobian determinant out of 809 images registered by MDReg\u2010Net without the spatial smoothing layer. In terms of image registration accuracy measured by Dice scores on brain structures labeled by FreeSufer, MDReg\u2010Net with and without the spatial smoothing layer obtained Dice scores of 0.782\u00b10.115(mean \u00b1 standard deviation) and 0.777\u00b10.116, respectively (p<1\u00d710\u221210, Wilcoxon signed rank test).",
                        "The image registration accuracy of MDReg\u2010Net image registration models with and without the spatial smoothing layer on the two testing datasets is summarized in Table\u00a03. Particularly, two MDReg\u2010Net image registration models without the spatial smoothing layer were obtained with \u03bb set to 0.5 and 1.0, respectively. Not surprisingly, MDReg\u2010Net without the spatial smoothing layer could obtain better image registration accuracy than MDReg\u2010Net with the spatial smoothing layer when \u03bb=0.5 at the cost of sacrificing the diffeomorphism. In contrast, MDReg\u2010Net with the spatial smoothing layer could achieve diffeomorphic, albeit not perfect, image registration without sacrificing the image registration accuracy too much, compared with MDReg\u2010Net without the spatial smoothing layer but with a larger regularization (when \u03bb=1.0). Moreover, the predicted velocity field performed well in the opposite direction\u2010based image registration. As summarized in Table\u00a03, no significant differences were observed in the registration performance between the two opposite directions for registering images, demonstrating the good inverse consistency of our method."
                    ],
                    "subsections": []
                }
            ]
        },
        {
            "title": "Discussion And Conclusions",
            "paragraphs": [
                "We present an end\u2010to\u2010end deep learning framework for diffeomorphic image registration. Our method trains FCNs to estimate voxel\u2010to\u2010voxel velocity fields of diffeomorphic spatial transformations for registering images by maximizing their image\u2010wise similarity metric, similar to conventional image registration algorithms. To facilitate learning of large diffeomorphic deformations between images, a multi\u2010resolution strategy is adopted to jointly optimize and estimate velocity fields of spatial transformations at different spatial resolutions incrementally with an integrated spatial Gaussian smoothing kernel. The experimental results based on 3D structural brain MR images have demonstrated that our method could obtain diffeomorphic image registration with better performance than state\u2010of\u2010the\u2010art image registration algorithms, including those built upon multi\u2010stage and multi\u2010resolution image registration strategies (Avants et al.,\u00a02011; Liu et al.,\u00a02019; T. C. Mok & Chung,\u00a02020b).",
                "In order to achieve accurate image registration, multi\u2010stage and multi\u2010resolution image registration strategies have been adopted in deep learning\u2010based image registration methods. Particularly, deep learning methods have been developed to perform coarse\u2010to\u2010fine image registration to account for large anatomical variations (de Vos et al.,\u00a02019; Hering et al.,\u00a02019; Zhao et al.,\u00a02019). The multi\u2010stage and multi\u2010resolution image registration methods are typically implemented with multiple sub\u2010networks, each of them being trained separately with the preceding sub\u2010networks fixed (de Vos et al.,\u00a02019; Hering et al.,\u00a02019); Cascaded networks are utilized to achieve an end\u2010to\u2010end multi\u2010stage image registration, with all sub\u2010networks being focusing on images at a single image resolution (Zhao et al.,\u00a02019). Moreover, these deep learning\u2010based image registration methods are not equipped to achieve diffeomorphic image registration. To achieve the diffeomorphic image registration, deep supervision has been used to optimize image similarity at different spatial resolutions in recent studies (Krebs et al.,\u00a02019; Liu et al.,\u00a02019). However, these methods learn the deformations at different resolutions separately. In contrast, our method learns deformation velocity fields at multiple spatial resolutions jointly to optimize the image registration spatial transformations from coarse to fine resolutions incrementally, with the velocity fields estimated at a coarse resolution being used to warp the moving image to generate an input image for subsequent sub\u2010networks to estimate residual velocity fields for spatial transformations at finer resolutions. Comparison results have demonstrated that our method achieved better diffeomorphic image registration performance than the most successful conventional and deep learning\u2010based multi\u2010resolution image registration algorithms (Avants et al.,\u00a02011; Liu et al.,\u00a02019; T. C. Mok & Chung,\u00a02020b), indicating that the incremental, multiple\u2010resolution image registration strategy creates a competitive advantage for multi\u2010resolution image registration.",
                "We have evaluated our method using different brain structural image datasets with manually labeled anatomical segmentations available. These segmentations contains fine\u2010grained anatomical structures, which are favored over brain tissue segmentation or coarse\u2010grained segmentation for the evaluation of registration accuracy as suggested in literature (Rohlfing,\u00a02011). Given that high region overlap\u2010based accuracy (such as Dice score) does not necessarily indicate biologically plausible deformations as folding voxels within regions could also result in high overlap index, we have also investigated the diffeomorphic property of the deformations obtained by different methods. As summarized in Table\u00a01, our method obtained registration accuracy comparable to that obtained by ANTs, which is one top ranked diffeomorphic registration method, while our method obtained deformation fields with a much smaller number of folding voxels than those obtained by ANTs and other methods under comparison. As summarized in Table\u00a02, deep learning methods on GPUs were much faster than conventional image registration algorithms on CPUs to register brain images, and our method was also faster than conventional registration algorithms when run on CPUs, attributed to its nature of learning\u2010based registration method. All these results indicated that deep learning\u2010based image registration methods can achieve faster image registration on GPUs than the conventional iterative optimization\u2010based image registration algorithms that are not optimized for GPU\u2010based computation. It merits further investigation to explore if the neural network architecture adopted in the deep learning\u2010based image registration algorithms can be optimized to improve both the image registration accuracy and the computational efficiency.",
                "Our method obtained improved accuracy compared with VoxelMorph, which is a state\u2010of\u2010the\u2010art deep learning\u2010based diffeomorphic registration model with similar deformation regularity and computational efficiency. This indicates that our incremental learning strategy could facilitate a better characterization of deformation between images. Compared with VoxelMorph, our method obtained more stable and accurate image registration models based on different brain image datasets with substantially different age distributions (younger than 20 vs. older than 60\u2009years), indicating that our method is not sensitive to the training data though the age distributions of the subjects from the PING cohort and the ADNI cohort are different. Our method also obtained improved accuracy compared with ProbMultilayer network that adopts a multi\u2010layer network structure to capture spatial transformation at different spatial resolutions, demonstrating the effectiveness of our incremental learning strategy. Our method also obtained improved accuracy compared with LapIRN that adopts a similar multi\u2010resolution strategy as our model. However, LapIRN's network architecture is quite different from ours and it also incorporates auto\u2010context and skip connections into its registration network, which makes it difficult to interpret what modules contribute to the performance gains without ablation results. LapIRN could obtain improved registration accuracy for brain subcortical structures, but not for those in cerebral cortex (T. C. Mok & Chung,\u00a02020b), consistent with our findings in the present study (Figures\u00a05b and 6b).",
                "Due to anatomical differences between images to be registered, the diffeomorphic image registration is often achieved at the cost of sacrificing the image registration accuracy in the current image registration framework which relies on regularization to produce spatially smooth and plausible deformation fields (Sotiras et al.,\u00a02013; Viergever et al.,\u00a02016). Although larger regularization parameters produced image registration models that could register images with smoother deformation fields, those producing image registration models to achieve the diffeomorphic image registration for the training data did not necessarily yield diffeomorphic image registration for the testing data and the discrepancy was prominent for the models trained without the spatial smoothing layer, as indicated by the results shown in Figures\u00a02 and 7a as well as in Tables\u00a01 and 3. This is because the regularization parameter could adjust the network parameters during the network training to yield spatially smooth deformation fields but does not directly regularize the deformation fields for registering testing image pairs during inference. The regularization effect is likely to vanish when there exists large discrepancy in morphometry and appearance between the testing and training data. In contrast, the spatial smoothing layer always carries out the smoothing operation in the same way no matter when applied to training or testing images. As indicated by the results summarized in Table\u00a01, the MDReg\u2010Net model with the spatial smoothing layer trained on the PING dataset achieved perfect diffeomorphic image registration on the Mindboggle\u2010101 dataset without sacrificing the image registration accuracy, compared with alternative state\u2010of\u2010the\u2010art image registration algorithms, including ANTs and VoxelMorph. Compared with the MDReg\u2010Net models without the spatial smoothing layer, the MDReg\u2010Net models with the spatial smoothing layer achieved better image registration accuracy and close to perfect diffeomorphic image registration, as indicated by the results summarized in Table\u00a03. Moreover, the results summarized in Table\u00a03 also demonstrated that the predicted velocity fields performed well in the opposite direction\u2010based image registration and no significant differences were observed in the registration performance between the two opposite directions for registering images, demonstrating the good inverse consistency of our method. All these results indicated that the spatial smoothing layer could enhance diffeomorphic image registration.",
                "While registration accuracy (such as Dice score) and diffeomorphism reflect the registration performance in different aspects, their priorities may be dependent on different applications. Although a more accurate (measured in terms of Dice score) image registration is achievable without persevering the diffeomorphism as demonstrated in image registration results summarized in Table\u00a03, the diffeomorphic image registration is desired for applications where image topology has to be preserved, such as accurately localizing cortical areas in neuroimaging studies of neuropsychiatric disorders that do not change the brain structures dramatically as tumors. Particularly, it is desired to register cortical structures of different subjects without folding or distortion, as the topological and geometrical properties of cortical structures may be inherently associated with behaviors and neuropsychiatric disorders (Luders et al.,\u00a02004; Madan & Kensinger,\u00a02016; Nicastro et al.,\u00a02020). Our method achieved nearly perfect diffeomorphic brain image registration with comparable Dice scores to ANT\u2010c1. While loosening the constraint of absolute diffeomorphism, an image registration model trained with a smaller smooth regularization parameter obtained similar Dice scores as ANT\u2010c1, but with much less negative Jacobian voxels, as shown in Table\u00a03. On the other hand, the Dice scores of ANTs decreased significantly with a larger regularization parameter (ANT\u2010c2), and the number of voxels with non\u2010positive Jacobian determinant were much larger than that obtained by our method, indicating that our method could achieve improved Dice scores when the diffeomorphic properties are at the same level. It has been demonstrated that surface\u2010based image registration methods achieved substantially better performance than conventional volume\u2010based image registration methods (Coalson, Van Essen, & Glasser,\u00a02018). Our method provides an alternative means to achieve fast, accurate, and nearly perfect diffeomorphic brain image registration, facilitating computationally efficient brain image registration and brain mapping in large scale neuroimaging studies of brain development and neuropsychiatric disorders.",
                "The present framework for diffeomorphic image registration could obtain image registration results within seconds with higher accuracy than state\u2010of\u2010the\u2010art image registration algorithms without diffeomorphism violation, however, potential refinements in the following aspects may further improve the registration performance. First, the architecture and parameter setting of the networks used could be further optimized. Second, stationary velocity fields were adopted to model spatial transformations currently, which may have inferior performance for charactering large deformations that are needed in certain scenarios, such as modeling morphology of developing and aging brains. Using time\u2010varying velocity fields (Beg, Miller, Trouv\u00e9, & Younes,\u00a02005) to model spatial transformations merits investigation. Finally, the regularization\u2010based image registration framework may be replaced with a constrained optimization framework to train a deep learning model with diffeomorphic image registration constraints for gaining further improvement.",
                "In summary, we have developed a deep learning method, referred to as MDReg\u2010Net, for diffeomorphic image registration, and experimental results have demonstrated MDReg\u2010Net could obtain robust, diffeomorphic, albeit not perfect, brain image registration for different datasets."
            ],
            "subsections": []
        },
        {
            "title": "Conflict Of Interest",
            "paragraphs": [
                "The authors have declared no conflicts of interest for this article."
            ],
            "subsections": []
        },
        {
            "title": "Ethics Statement",
            "paragraphs": [
                "This research study was conducted retrospectively using human subject data made available in open access. IRB approval was obtained to carry out the reported study."
            ],
            "subsections": []
        }
    ]
}