# DESCRIPTION

## CROSS REFERENCES

- claim priority

## TECHNICAL FIELD

- define technical field

## BACKGROUND

- motivate document summarization

## DETAILED DESCRIPTION

- define network and module
- motivate document summarization model
- describe bottom-up representation generation
- describe top-down representation generation
- explain cross-attention between representations
- describe top-level representation pooling
- illustrate document summarization method
- describe local self-attention layers
- describe full self-attention layers
- describe top-down inference for token representations
- describe output summary generation
- describe document summarization system
- compute bottom-up inferred token representations
- pool bottom-up inferred token representations
- update top-level representations with full self-attention
- update bottom-up inferred token representations with cross-attention
- generate summary output
- describe computing device architecture
- describe memory storage
- describe processor and memory arrangement
- describe non-transitory machine-readable media
- describe summarization module
- describe bottom-up inference module
- describe top-down inference module
- describe cross-attention module
- describe example summarization datasets
- describe model evaluation
- describe model architecture
- describe model training
- describe model performance on scientific articles
- describe model performance on CNN-DailyMail
- describe model performance on SummScreen
- describe model performance on BookSum Chapter Level
- describe model performance on BookSum Book Level
- describe differences from other models
- provide disclaimer

