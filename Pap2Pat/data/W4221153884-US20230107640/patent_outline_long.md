# DESCRIPTION

## CROSS REFERENCES

- claim priority

## TECHNICAL FIELD

- define technical field

## BACKGROUND

- motivate document summarization

## DETAILED DESCRIPTION

- define network
- define module
- motivate document summarization model
- describe bottom-up representation
- describe local self-attention
- describe top-down representation
- describe full self-attention
- describe top-level representation
- describe pooling methods
- describe importance tagger
- describe ADAPool
- describe FIG. 1
- describe local self-attention layers
- describe bottom-up representation
- describe pooling
- describe initial top-level representation
- describe full self-attention
- describe top-level representation
- describe top-down inference
- describe token self-attention
- describe token-segment cross-attention
- describe feed-forward
- describe output summary
- describe document summarization system
- compute bottom-up inferred token representations
- pool bottom-up inferred token representations
- update top-level representations with full self-attention
- update bottom-up inferred token representations with cross-attention
- generate summary output
- describe computing device architecture
- describe memory storage
- describe processor and memory arrangement
- describe non-transitory machine-readable media
- describe summarization module
- describe bottom-up inference module
- describe top-down inference module
- describe cross-attention module
- illustrate summarization datasets
- describe PubMed dataset
- describe arXiv dataset
- describe CNN-Dailymail dataset
- describe SummScreen dataset
- describe BookSum dataset
- describe model architecture
- describe encoder-decoder architecture
- describe encoder layers
- describe decoder layers
- describe model initialization
- describe model evaluation
- describe ROUGE scores
- illustrate model performance on scientific articles
- describe Pegasus model
- describe Dancer model
- describe TLM-I+E model
- describe SSN-DM model
- describe BigBird model
- describe Longformer model
- describe LSH model
- illustrate model performance on CNN-DailyMail
- illustrate model performance on SummScreen
- illustrate model performance on BookSum Chapter Level
- describe divide-and-conquer approach
- describe top-down transformer training
- describe recursive summarization
- describe GPT-3 model
- illustrate model performance on BookSum Book Level
- describe model differences
- describe limitations of GPT-3 model
- describe advantages of described model
- provide disclaimer
- describe scope of disclosure
- describe modifications and variations
- describe claims scope

